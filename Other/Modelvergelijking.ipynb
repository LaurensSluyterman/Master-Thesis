{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "import numpy\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.utils import normalize, to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setting up tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_run_logdir(): \n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() \n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Messing around with tfp stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Normal 'Normal/' batch_shape=[] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = tfd.Normal(loc=0., scale=1.)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026782611"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.sample().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.linspace(-10,10,1000)\n",
    "y=np.exp(n.log_prob(x).numpy())\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Bernoulli 'Bernoulli/' batch_shape=[] event_shape=[] dtype=int32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tfd.Bernoulli(probs=0.7)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=58, shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(b.log_prob(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag/' batch_shape=[] event_shape=[2] dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd = tfd.MultivariateNormalDiag(loc=[0., 10.], scale_diag=[1., 4.])\n",
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-052dd025d70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mprepended\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_sample_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_call_sample_n\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0;31m# work, it is imperative that this is the last modification to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       \u001b[0;31m# returned result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbijector_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_sample_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \"\"\"\n\u001b[0;32m--> 933\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m_call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_injective\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No caching for non-injective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m       \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m_lookup\u001b[0;34m(self, x, y, kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m       \u001b[0;31m# We removed x at caching time. Add it back if we lookup successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m       \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m       \u001b[0;31m# We removed y at caching time. Add it back if we lookup successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mweak_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHashableWeakRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeakKeyDefaultDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0;31m# This is the \"DefaultDict\" part.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;31m# Note: The following logic can never be reached by the public API because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# the bijector base class always calls `convert_to_tensor` before accessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\n\u001b[1;32m    712\u001b[0m         (g is None or g._building_function)):  # pylint: disable=protected-access\n\u001b[0;32m--> 713\u001b[0;31m       raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\u001b[0m\u001b[1;32m    714\u001b[0m                       \"Instead, use tensor.experimental_ref() as the key.\")\n\u001b[1;32m    715\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key."
     ]
    }
   ],
   "source": [
    "nd.sample().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPG example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code in the first part of this example comes from: https://www.tensorflow.org/tutorials/keras/basic_regression. I used the methods developed by googles tensorflow probability team and adapted some of their example code. The definitions of the priors and posteriors is not my own work. The gaussian process part is also largely copied from their example codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download and preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly copied from the example code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download and examine a standard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurens/.keras/datasets/auto-mpg.data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('Origin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>USA</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  USA  Europe  Japan  \n",
       "393          82  1.0     0.0    0.0  \n",
       "394          82  0.0     1.0    0.0  \n",
       "395          82  1.0     0.0    0.0  \n",
       "396          82  1.0     0.0    0.0  \n",
       "397          82  1.0     0.0    0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cylinders</th>\n",
       "      <td>314.0</td>\n",
       "      <td>5.477707</td>\n",
       "      <td>1.699788</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Displacement</th>\n",
       "      <td>314.0</td>\n",
       "      <td>195.318471</td>\n",
       "      <td>104.331589</td>\n",
       "      <td>68.0</td>\n",
       "      <td>105.50</td>\n",
       "      <td>151.0</td>\n",
       "      <td>265.75</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horsepower</th>\n",
       "      <td>314.0</td>\n",
       "      <td>104.869427</td>\n",
       "      <td>38.096214</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.25</td>\n",
       "      <td>94.5</td>\n",
       "      <td>128.00</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>314.0</td>\n",
       "      <td>2990.251592</td>\n",
       "      <td>843.898596</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>2256.50</td>\n",
       "      <td>2822.5</td>\n",
       "      <td>3608.00</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acceleration</th>\n",
       "      <td>314.0</td>\n",
       "      <td>15.559236</td>\n",
       "      <td>2.789230</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.20</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Year</th>\n",
       "      <td>314.0</td>\n",
       "      <td>75.898089</td>\n",
       "      <td>3.675642</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.624204</td>\n",
       "      <td>0.485101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.383413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.398712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min      25%     50%  \\\n",
       "Cylinders     314.0     5.477707    1.699788     3.0     4.00     4.0   \n",
       "Displacement  314.0   195.318471  104.331589    68.0   105.50   151.0   \n",
       "Horsepower    314.0   104.869427   38.096214    46.0    76.25    94.5   \n",
       "Weight        314.0  2990.251592  843.898596  1649.0  2256.50  2822.5   \n",
       "Acceleration  314.0    15.559236    2.789230     8.0    13.80    15.5   \n",
       "Model Year    314.0    75.898089    3.675642    70.0    73.00    76.0   \n",
       "USA           314.0     0.624204    0.485101     0.0     0.00     1.0   \n",
       "Europe        314.0     0.178344    0.383413     0.0     0.00     0.0   \n",
       "Japan         314.0     0.197452    0.398712     0.0     0.00     0.0   \n",
       "\n",
       "                  75%     max  \n",
       "Cylinders        8.00     8.0  \n",
       "Displacement   265.75   455.0  \n",
       "Horsepower     128.00   225.0  \n",
       "Weight        3608.00  5140.0  \n",
       "Acceleration    17.20    24.8  \n",
       "Model Year      79.00    82.0  \n",
       "USA              1.00     1.0  \n",
       "Europe           0.00     1.0  \n",
       "Japan            0.00     1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builing 4 models (probabilistic, dropout, and classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, rv_y: -rv_y.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): #probabilistic\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(2),\n",
    "    tfp.layers.DistributionLambda(\n",
    "      lambda t: tfd.Normal(loc=t[..., :1],\n",
    "                           scale=1e-3 + tf.math.softplus(0.05 * t[...,1:]))),\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss=negloglik,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(): #classical, this is the model given in the original script\n",
    "  model2 = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(2),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model2.compile(loss='mse',\n",
    "                optimizer='adam',\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "  return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 251 samples, validate on 63 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  normed_train_data, train_labels,\n",
    "  epochs=100, validation_split = 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251 samples, validate on 63 samples\n",
      "Epoch 1/400\n",
      "251/251 [==============================] - 0s 871us/sample - loss: 548.5415 - mean_absolute_error: 22.1948 - mean_squared_error: 548.5415 - val_loss: 542.0012 - val_mean_absolute_error: 22.0418 - val_mean_squared_error: 542.0011\n",
      "Epoch 2/400\n",
      "251/251 [==============================] - 0s 74us/sample - loss: 503.4158 - mean_absolute_error: 21.2069 - mean_squared_error: 503.4158 - val_loss: 487.8756 - val_mean_absolute_error: 20.8355 - val_mean_squared_error: 487.8756\n",
      "Epoch 3/400\n",
      "251/251 [==============================] - 0s 64us/sample - loss: 450.5630 - mean_absolute_error: 19.9817 - mean_squared_error: 450.5630 - val_loss: 421.1383 - val_mean_absolute_error: 19.2455 - val_mean_squared_error: 421.1383\n",
      "Epoch 4/400\n",
      "251/251 [==============================] - 0s 69us/sample - loss: 383.4750 - mean_absolute_error: 18.3004 - mean_squared_error: 383.4750 - val_loss: 336.6750 - val_mean_absolute_error: 17.0270 - val_mean_squared_error: 336.6750\n",
      "Epoch 5/400\n",
      "251/251 [==============================] - 0s 62us/sample - loss: 299.2066 - mean_absolute_error: 15.9851 - mean_squared_error: 299.2066 - val_loss: 238.7164 - val_mean_absolute_error: 13.9970 - val_mean_squared_error: 238.7164\n",
      "Epoch 6/400\n",
      "251/251 [==============================] - 0s 54us/sample - loss: 203.5090 - mean_absolute_error: 12.8561 - mean_squared_error: 203.5090 - val_loss: 141.1697 - val_mean_absolute_error: 10.3228 - val_mean_squared_error: 141.1697\n",
      "Epoch 7/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 116.1069 - mean_absolute_error: 9.2844 - mean_squared_error: 116.1069 - val_loss: 70.6916 - val_mean_absolute_error: 7.2490 - val_mean_squared_error: 70.6916\n",
      "Epoch 8/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 61.4868 - mean_absolute_error: 6.4404 - mean_squared_error: 61.4868 - val_loss: 47.3429 - val_mean_absolute_error: 5.7538 - val_mean_squared_error: 47.3428\n",
      "Epoch 9/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 42.9817 - mean_absolute_error: 5.3696 - mean_squared_error: 42.9817 - val_loss: 46.1219 - val_mean_absolute_error: 5.4597 - val_mean_squared_error: 46.1219\n",
      "Epoch 10/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 36.6062 - mean_absolute_error: 4.9565 - mean_squared_error: 36.6062 - val_loss: 37.8470 - val_mean_absolute_error: 4.7766 - val_mean_squared_error: 37.8470\n",
      "Epoch 11/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 28.9374 - mean_absolute_error: 4.2689 - mean_squared_error: 28.9374 - val_loss: 28.9005 - val_mean_absolute_error: 4.2044 - val_mean_squared_error: 28.9005\n",
      "Epoch 12/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 23.5991 - mean_absolute_error: 3.7499 - mean_squared_error: 23.5991 - val_loss: 24.9289 - val_mean_absolute_error: 4.0036 - val_mean_squared_error: 24.9290\n",
      "Epoch 13/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 20.7982 - mean_absolute_error: 3.5231 - mean_squared_error: 20.7982 - val_loss: 22.9789 - val_mean_absolute_error: 3.8905 - val_mean_squared_error: 22.9789\n",
      "Epoch 14/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 19.0821 - mean_absolute_error: 3.3997 - mean_squared_error: 19.0821 - val_loss: 21.6141 - val_mean_absolute_error: 3.7583 - val_mean_squared_error: 21.6141\n",
      "Epoch 15/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 17.6431 - mean_absolute_error: 3.2707 - mean_squared_error: 17.6431 - val_loss: 20.0481 - val_mean_absolute_error: 3.6094 - val_mean_squared_error: 20.0481\n",
      "Epoch 16/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 16.5143 - mean_absolute_error: 3.1668 - mean_squared_error: 16.5143 - val_loss: 18.5778 - val_mean_absolute_error: 3.4476 - val_mean_squared_error: 18.5778\n",
      "Epoch 17/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 15.5232 - mean_absolute_error: 3.0637 - mean_squared_error: 15.5232 - val_loss: 17.3943 - val_mean_absolute_error: 3.3161 - val_mean_squared_error: 17.3943\n",
      "Epoch 18/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 14.7044 - mean_absolute_error: 2.9771 - mean_squared_error: 14.7044 - val_loss: 16.1901 - val_mean_absolute_error: 3.2039 - val_mean_squared_error: 16.1901\n",
      "Epoch 19/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 13.9033 - mean_absolute_error: 2.8859 - mean_squared_error: 13.9033 - val_loss: 15.0087 - val_mean_absolute_error: 3.0933 - val_mean_squared_error: 15.0087\n",
      "Epoch 20/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 13.2084 - mean_absolute_error: 2.8021 - mean_squared_error: 13.2084 - val_loss: 14.1714 - val_mean_absolute_error: 3.0189 - val_mean_squared_error: 14.1714\n",
      "Epoch 21/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 12.5692 - mean_absolute_error: 2.7300 - mean_squared_error: 12.5692 - val_loss: 13.4805 - val_mean_absolute_error: 2.9278 - val_mean_squared_error: 13.4805\n",
      "Epoch 22/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 12.1441 - mean_absolute_error: 2.6821 - mean_squared_error: 12.1441 - val_loss: 12.9773 - val_mean_absolute_error: 2.8592 - val_mean_squared_error: 12.9773\n",
      "Epoch 23/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 11.5388 - mean_absolute_error: 2.6075 - mean_squared_error: 11.5388 - val_loss: 12.4370 - val_mean_absolute_error: 2.8117 - val_mean_squared_error: 12.4370\n",
      "Epoch 24/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 11.1598 - mean_absolute_error: 2.5497 - mean_squared_error: 11.1598 - val_loss: 11.7958 - val_mean_absolute_error: 2.7220 - val_mean_squared_error: 11.7958\n",
      "Epoch 25/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 10.8410 - mean_absolute_error: 2.4931 - mean_squared_error: 10.8410 - val_loss: 11.4312 - val_mean_absolute_error: 2.6863 - val_mean_squared_error: 11.4312\n",
      "Epoch 26/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 10.4686 - mean_absolute_error: 2.4531 - mean_squared_error: 10.4686 - val_loss: 11.1239 - val_mean_absolute_error: 2.6333 - val_mean_squared_error: 11.1239\n",
      "Epoch 27/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 10.2306 - mean_absolute_error: 2.4251 - mean_squared_error: 10.2306 - val_loss: 10.7816 - val_mean_absolute_error: 2.5707 - val_mean_squared_error: 10.7816\n",
      "Epoch 28/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 9.9351 - mean_absolute_error: 2.3807 - mean_squared_error: 9.9351 - val_loss: 10.4709 - val_mean_absolute_error: 2.5446 - val_mean_squared_error: 10.4709\n",
      "Epoch 29/400\n",
      "251/251 [==============================] - 0s 52us/sample - loss: 9.7405 - mean_absolute_error: 2.3382 - mean_squared_error: 9.7405 - val_loss: 10.3290 - val_mean_absolute_error: 2.5335 - val_mean_squared_error: 10.3290\n",
      "Epoch 30/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 9.5054 - mean_absolute_error: 2.3019 - mean_squared_error: 9.5054 - val_loss: 10.0990 - val_mean_absolute_error: 2.5011 - val_mean_squared_error: 10.0990\n",
      "Epoch 31/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 9.3938 - mean_absolute_error: 2.2972 - mean_squared_error: 9.3938 - val_loss: 9.9998 - val_mean_absolute_error: 2.4601 - val_mean_squared_error: 9.9998\n",
      "Epoch 32/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 9.1217 - mean_absolute_error: 2.2546 - mean_squared_error: 9.1217 - val_loss: 9.6775 - val_mean_absolute_error: 2.4254 - val_mean_squared_error: 9.6775\n",
      "Epoch 33/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 8.9974 - mean_absolute_error: 2.2267 - mean_squared_error: 8.9974 - val_loss: 9.5131 - val_mean_absolute_error: 2.4063 - val_mean_squared_error: 9.5131\n",
      "Epoch 34/400\n",
      "251/251 [==============================] - 0s 56us/sample - loss: 8.8304 - mean_absolute_error: 2.1998 - mean_squared_error: 8.8304 - val_loss: 9.4307 - val_mean_absolute_error: 2.4024 - val_mean_squared_error: 9.4307\n",
      "Epoch 35/400\n",
      "251/251 [==============================] - 0s 53us/sample - loss: 8.7161 - mean_absolute_error: 2.1735 - mean_squared_error: 8.7161 - val_loss: 9.4361 - val_mean_absolute_error: 2.3879 - val_mean_squared_error: 9.4361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/400\n",
      "251/251 [==============================] - 0s 58us/sample - loss: 8.6235 - mean_absolute_error: 2.1652 - mean_squared_error: 8.6235 - val_loss: 9.4147 - val_mean_absolute_error: 2.3598 - val_mean_squared_error: 9.4147\n",
      "Epoch 37/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 8.5173 - mean_absolute_error: 2.1563 - mean_squared_error: 8.5173 - val_loss: 9.1980 - val_mean_absolute_error: 2.3180 - val_mean_squared_error: 9.1980\n",
      "Epoch 38/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 8.4230 - mean_absolute_error: 2.1358 - mean_squared_error: 8.4230 - val_loss: 9.1637 - val_mean_absolute_error: 2.3253 - val_mean_squared_error: 9.1637\n",
      "Epoch 39/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 8.2975 - mean_absolute_error: 2.1044 - mean_squared_error: 8.2975 - val_loss: 9.2255 - val_mean_absolute_error: 2.3305 - val_mean_squared_error: 9.2255\n",
      "Epoch 40/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 8.2228 - mean_absolute_error: 2.1068 - mean_squared_error: 8.2228 - val_loss: 9.2197 - val_mean_absolute_error: 2.3201 - val_mean_squared_error: 9.2197\n",
      "Epoch 41/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 8.1620 - mean_absolute_error: 2.1044 - mean_squared_error: 8.1620 - val_loss: 8.9867 - val_mean_absolute_error: 2.2840 - val_mean_squared_error: 8.9867\n",
      "Epoch 42/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 8.0077 - mean_absolute_error: 2.0774 - mean_squared_error: 8.0077 - val_loss: 9.0133 - val_mean_absolute_error: 2.2995 - val_mean_squared_error: 9.0133\n",
      "Epoch 43/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 7.9770 - mean_absolute_error: 2.0512 - mean_squared_error: 7.9770 - val_loss: 9.0941 - val_mean_absolute_error: 2.3111 - val_mean_squared_error: 9.0941\n",
      "Epoch 44/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 7.8692 - mean_absolute_error: 2.0368 - mean_squared_error: 7.8692 - val_loss: 9.0615 - val_mean_absolute_error: 2.2954 - val_mean_squared_error: 9.0615\n",
      "Epoch 45/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 7.7679 - mean_absolute_error: 2.0331 - mean_squared_error: 7.7679 - val_loss: 9.0719 - val_mean_absolute_error: 2.2697 - val_mean_squared_error: 9.0719\n",
      "Epoch 46/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 7.7959 - mean_absolute_error: 2.0454 - mean_squared_error: 7.7959 - val_loss: 9.0308 - val_mean_absolute_error: 2.2733 - val_mean_squared_error: 9.0308\n",
      "Epoch 47/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 7.6906 - mean_absolute_error: 2.0170 - mean_squared_error: 7.6906 - val_loss: 9.0759 - val_mean_absolute_error: 2.2854 - val_mean_squared_error: 9.0759\n",
      "Epoch 48/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 7.6341 - mean_absolute_error: 1.9967 - mean_squared_error: 7.6341 - val_loss: 9.0766 - val_mean_absolute_error: 2.2935 - val_mean_squared_error: 9.0766\n",
      "Epoch 49/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 7.6614 - mean_absolute_error: 2.0177 - mean_squared_error: 7.6614 - val_loss: 8.9145 - val_mean_absolute_error: 2.2636 - val_mean_squared_error: 8.9145\n",
      "Epoch 50/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 7.5050 - mean_absolute_error: 1.9805 - mean_squared_error: 7.5050 - val_loss: 8.9093 - val_mean_absolute_error: 2.2880 - val_mean_squared_error: 8.9093\n",
      "Epoch 51/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 7.4436 - mean_absolute_error: 1.9684 - mean_squared_error: 7.4436 - val_loss: 8.9022 - val_mean_absolute_error: 2.2738 - val_mean_squared_error: 8.9022\n",
      "Epoch 52/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 7.4305 - mean_absolute_error: 1.9631 - mean_squared_error: 7.4305 - val_loss: 8.9685 - val_mean_absolute_error: 2.2800 - val_mean_squared_error: 8.9685\n",
      "Epoch 53/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 7.3361 - mean_absolute_error: 1.9565 - mean_squared_error: 7.3361 - val_loss: 8.9502 - val_mean_absolute_error: 2.2597 - val_mean_squared_error: 8.9502\n",
      "Epoch 54/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 7.3282 - mean_absolute_error: 1.9677 - mean_squared_error: 7.3282 - val_loss: 8.9002 - val_mean_absolute_error: 2.2508 - val_mean_squared_error: 8.9002\n",
      "Epoch 55/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 7.2716 - mean_absolute_error: 1.9497 - mean_squared_error: 7.2716 - val_loss: 8.8810 - val_mean_absolute_error: 2.2688 - val_mean_squared_error: 8.8810\n",
      "Epoch 56/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 7.2289 - mean_absolute_error: 1.9354 - mean_squared_error: 7.2289 - val_loss: 8.8043 - val_mean_absolute_error: 2.2647 - val_mean_squared_error: 8.8043\n",
      "Epoch 57/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 7.1992 - mean_absolute_error: 1.9243 - mean_squared_error: 7.1992 - val_loss: 8.8767 - val_mean_absolute_error: 2.2833 - val_mean_squared_error: 8.8767\n",
      "Epoch 58/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 7.1315 - mean_absolute_error: 1.9133 - mean_squared_error: 7.1315 - val_loss: 8.8360 - val_mean_absolute_error: 2.2515 - val_mean_squared_error: 8.8360\n",
      "Epoch 59/400\n",
      "251/251 [==============================] - 0s 53us/sample - loss: 7.0977 - mean_absolute_error: 1.9232 - mean_squared_error: 7.0977 - val_loss: 8.8833 - val_mean_absolute_error: 2.2423 - val_mean_squared_error: 8.8833\n",
      "Epoch 60/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 7.0653 - mean_absolute_error: 1.9172 - mean_squared_error: 7.0653 - val_loss: 8.8085 - val_mean_absolute_error: 2.2444 - val_mean_squared_error: 8.8085\n",
      "Epoch 61/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 7.0326 - mean_absolute_error: 1.9013 - mean_squared_error: 7.0326 - val_loss: 8.7996 - val_mean_absolute_error: 2.2560 - val_mean_squared_error: 8.7996\n",
      "Epoch 62/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 7.0207 - mean_absolute_error: 1.8960 - mean_squared_error: 7.0207 - val_loss: 8.8715 - val_mean_absolute_error: 2.2428 - val_mean_squared_error: 8.8715\n",
      "Epoch 63/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 6.9894 - mean_absolute_error: 1.8976 - mean_squared_error: 6.9894 - val_loss: 8.7344 - val_mean_absolute_error: 2.2445 - val_mean_squared_error: 8.7344\n",
      "Epoch 64/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 6.9169 - mean_absolute_error: 1.8860 - mean_squared_error: 6.9169 - val_loss: 8.7666 - val_mean_absolute_error: 2.2405 - val_mean_squared_error: 8.7666\n",
      "Epoch 65/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 6.8813 - mean_absolute_error: 1.8803 - mean_squared_error: 6.8813 - val_loss: 8.8046 - val_mean_absolute_error: 2.2410 - val_mean_squared_error: 8.8046\n",
      "Epoch 66/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.8768 - mean_absolute_error: 1.8798 - mean_squared_error: 6.8768 - val_loss: 8.7820 - val_mean_absolute_error: 2.2451 - val_mean_squared_error: 8.7820\n",
      "Epoch 67/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 6.8379 - mean_absolute_error: 1.8642 - mean_squared_error: 6.8379 - val_loss: 8.8365 - val_mean_absolute_error: 2.2492 - val_mean_squared_error: 8.8365\n",
      "Epoch 68/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 6.8008 - mean_absolute_error: 1.8673 - mean_squared_error: 6.8008 - val_loss: 8.9025 - val_mean_absolute_error: 2.2239 - val_mean_squared_error: 8.9025\n",
      "Epoch 69/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 6.7840 - mean_absolute_error: 1.8684 - mean_squared_error: 6.7840 - val_loss: 8.7973 - val_mean_absolute_error: 2.2376 - val_mean_squared_error: 8.7973\n",
      "Epoch 70/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 6.7281 - mean_absolute_error: 1.8529 - mean_squared_error: 6.7281 - val_loss: 8.7842 - val_mean_absolute_error: 2.2435 - val_mean_squared_error: 8.7842\n",
      "Epoch 71/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 6.7270 - mean_absolute_error: 1.8514 - mean_squared_error: 6.7270 - val_loss: 8.7158 - val_mean_absolute_error: 2.2283 - val_mean_squared_error: 8.7158\n",
      "Epoch 72/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 6.6697 - mean_absolute_error: 1.8464 - mean_squared_error: 6.6697 - val_loss: 8.7827 - val_mean_absolute_error: 2.2366 - val_mean_squared_error: 8.7827\n",
      "Epoch 73/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 6.7057 - mean_absolute_error: 1.8455 - mean_squared_error: 6.7057 - val_loss: 8.7779 - val_mean_absolute_error: 2.2519 - val_mean_squared_error: 8.7779\n",
      "Epoch 74/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 6.6308 - mean_absolute_error: 1.8278 - mean_squared_error: 6.6308 - val_loss: 8.7450 - val_mean_absolute_error: 2.2325 - val_mean_squared_error: 8.7450\n",
      "Epoch 75/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 6.7042 - mean_absolute_error: 1.8679 - mean_squared_error: 6.7042 - val_loss: 8.8680 - val_mean_absolute_error: 2.2149 - val_mean_squared_error: 8.8680\n",
      "Epoch 76/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 6.6819 - mean_absolute_error: 1.8335 - mean_squared_error: 6.6819 - val_loss: 8.8195 - val_mean_absolute_error: 2.2632 - val_mean_squared_error: 8.8195\n",
      "Epoch 77/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 6.5640 - mean_absolute_error: 1.8134 - mean_squared_error: 6.5640 - val_loss: 8.7898 - val_mean_absolute_error: 2.2432 - val_mean_squared_error: 8.7898\n",
      "Epoch 78/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 6.6061 - mean_absolute_error: 1.8385 - mean_squared_error: 6.6061 - val_loss: 8.7822 - val_mean_absolute_error: 2.2065 - val_mean_squared_error: 8.7822\n",
      "Epoch 79/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 6.5241 - mean_absolute_error: 1.8356 - mean_squared_error: 6.5241 - val_loss: 8.6829 - val_mean_absolute_error: 2.2197 - val_mean_squared_error: 8.6829\n",
      "Epoch 80/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 6.4653 - mean_absolute_error: 1.8063 - mean_squared_error: 6.4653 - val_loss: 8.7091 - val_mean_absolute_error: 2.2351 - val_mean_squared_error: 8.7091\n",
      "Epoch 81/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 6.4708 - mean_absolute_error: 1.8002 - mean_squared_error: 6.4708 - val_loss: 8.7058 - val_mean_absolute_error: 2.2403 - val_mean_squared_error: 8.7058\n",
      "Epoch 82/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 6.4528 - mean_absolute_error: 1.8105 - mean_squared_error: 6.4528 - val_loss: 8.6978 - val_mean_absolute_error: 2.2065 - val_mean_squared_error: 8.6978\n",
      "Epoch 83/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 6.4068 - mean_absolute_error: 1.8036 - mean_squared_error: 6.4068 - val_loss: 8.7485 - val_mean_absolute_error: 2.2180 - val_mean_squared_error: 8.7485\n",
      "Epoch 84/400\n",
      "251/251 [==============================] - 0s 56us/sample - loss: 6.3996 - mean_absolute_error: 1.7982 - mean_squared_error: 6.3996 - val_loss: 8.7463 - val_mean_absolute_error: 2.2296 - val_mean_squared_error: 8.7463\n",
      "Epoch 85/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 6.3907 - mean_absolute_error: 1.7960 - mean_squared_error: 6.3907 - val_loss: 8.6980 - val_mean_absolute_error: 2.2179 - val_mean_squared_error: 8.6980\n",
      "Epoch 86/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 6.3712 - mean_absolute_error: 1.7918 - mean_squared_error: 6.3712 - val_loss: 8.7342 - val_mean_absolute_error: 2.2228 - val_mean_squared_error: 8.7342\n",
      "Epoch 87/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 6.3476 - mean_absolute_error: 1.7804 - mean_squared_error: 6.3476 - val_loss: 8.6799 - val_mean_absolute_error: 2.2161 - val_mean_squared_error: 8.6799\n",
      "Epoch 88/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 6.3810 - mean_absolute_error: 1.8093 - mean_squared_error: 6.3810 - val_loss: 8.6727 - val_mean_absolute_error: 2.2113 - val_mean_squared_error: 8.6727\n",
      "Epoch 89/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 6.3346 - mean_absolute_error: 1.7798 - mean_squared_error: 6.3346 - val_loss: 8.7312 - val_mean_absolute_error: 2.2298 - val_mean_squared_error: 8.7312\n",
      "Epoch 90/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 6.3249 - mean_absolute_error: 1.7770 - mean_squared_error: 6.3249 - val_loss: 8.6904 - val_mean_absolute_error: 2.1994 - val_mean_squared_error: 8.6904\n",
      "Epoch 91/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.2622 - mean_absolute_error: 1.7729 - mean_squared_error: 6.2622 - val_loss: 8.7106 - val_mean_absolute_error: 2.2130 - val_mean_squared_error: 8.7106\n",
      "Epoch 92/400\n",
      "251/251 [==============================] - 0s 72us/sample - loss: 6.3232 - mean_absolute_error: 1.7731 - mean_squared_error: 6.3232 - val_loss: 8.6842 - val_mean_absolute_error: 2.2459 - val_mean_squared_error: 8.6842\n",
      "Epoch 93/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.1796 - mean_absolute_error: 1.7566 - mean_squared_error: 6.1796 - val_loss: 8.7165 - val_mean_absolute_error: 2.1980 - val_mean_squared_error: 8.7165\n",
      "Epoch 94/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 6.2519 - mean_absolute_error: 1.7858 - mean_squared_error: 6.2519 - val_loss: 8.6903 - val_mean_absolute_error: 2.2125 - val_mean_squared_error: 8.6903\n",
      "Epoch 95/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 6.2447 - mean_absolute_error: 1.7861 - mean_squared_error: 6.2447 - val_loss: 8.5523 - val_mean_absolute_error: 2.2000 - val_mean_squared_error: 8.5523\n",
      "Epoch 96/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.1737 - mean_absolute_error: 1.7639 - mean_squared_error: 6.1737 - val_loss: 8.6699 - val_mean_absolute_error: 2.2240 - val_mean_squared_error: 8.6699\n",
      "Epoch 97/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 6.1608 - mean_absolute_error: 1.7430 - mean_squared_error: 6.1608 - val_loss: 8.6447 - val_mean_absolute_error: 2.2083 - val_mean_squared_error: 8.6447\n",
      "Epoch 98/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 6.1585 - mean_absolute_error: 1.7599 - mean_squared_error: 6.1585 - val_loss: 8.5668 - val_mean_absolute_error: 2.2005 - val_mean_squared_error: 8.5668\n",
      "Epoch 99/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 6.1017 - mean_absolute_error: 1.7466 - mean_squared_error: 6.1017 - val_loss: 8.6282 - val_mean_absolute_error: 2.2143 - val_mean_squared_error: 8.6282\n",
      "Epoch 100/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 6.1453 - mean_absolute_error: 1.7647 - mean_squared_error: 6.1453 - val_loss: 8.6586 - val_mean_absolute_error: 2.2012 - val_mean_squared_error: 8.6586\n",
      "Epoch 101/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 6.0701 - mean_absolute_error: 1.7376 - mean_squared_error: 6.0701 - val_loss: 8.6896 - val_mean_absolute_error: 2.2191 - val_mean_squared_error: 8.6896\n",
      "Epoch 102/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 6.1279 - mean_absolute_error: 1.7365 - mean_squared_error: 6.1279 - val_loss: 8.6391 - val_mean_absolute_error: 2.2298 - val_mean_squared_error: 8.6391\n",
      "Epoch 103/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 6.0689 - mean_absolute_error: 1.7340 - mean_squared_error: 6.0689 - val_loss: 8.5815 - val_mean_absolute_error: 2.1878 - val_mean_squared_error: 8.5815\n",
      "Epoch 104/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 6.0309 - mean_absolute_error: 1.7528 - mean_squared_error: 6.0309 - val_loss: 8.6829 - val_mean_absolute_error: 2.1939 - val_mean_squared_error: 8.6829\n",
      "Epoch 105/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 6.0648 - mean_absolute_error: 1.7316 - mean_squared_error: 6.0648 - val_loss: 8.6113 - val_mean_absolute_error: 2.2284 - val_mean_squared_error: 8.6113\n",
      "Epoch 106/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 40us/sample - loss: 6.0167 - mean_absolute_error: 1.7184 - mean_squared_error: 6.0167 - val_loss: 8.6488 - val_mean_absolute_error: 2.2000 - val_mean_squared_error: 8.6488\n",
      "Epoch 107/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.0570 - mean_absolute_error: 1.7577 - mean_squared_error: 6.0570 - val_loss: 8.5381 - val_mean_absolute_error: 2.1702 - val_mean_squared_error: 8.5381\n",
      "Epoch 108/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 5.9530 - mean_absolute_error: 1.7340 - mean_squared_error: 5.9530 - val_loss: 8.5747 - val_mean_absolute_error: 2.2086 - val_mean_squared_error: 8.5747\n",
      "Epoch 109/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 6.0285 - mean_absolute_error: 1.7205 - mean_squared_error: 6.0285 - val_loss: 8.6212 - val_mean_absolute_error: 2.2363 - val_mean_squared_error: 8.6212\n",
      "Epoch 110/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 6.0083 - mean_absolute_error: 1.7348 - mean_squared_error: 6.0083 - val_loss: 8.5928 - val_mean_absolute_error: 2.1812 - val_mean_squared_error: 8.5928\n",
      "Epoch 111/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.9818 - mean_absolute_error: 1.7292 - mean_squared_error: 5.9818 - val_loss: 8.5810 - val_mean_absolute_error: 2.2142 - val_mean_squared_error: 8.5810\n",
      "Epoch 112/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.9358 - mean_absolute_error: 1.7054 - mean_squared_error: 5.9358 - val_loss: 8.6239 - val_mean_absolute_error: 2.2356 - val_mean_squared_error: 8.6239\n",
      "Epoch 113/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.9078 - mean_absolute_error: 1.7164 - mean_squared_error: 5.9078 - val_loss: 8.5705 - val_mean_absolute_error: 2.1863 - val_mean_squared_error: 8.5705\n",
      "Epoch 114/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.9289 - mean_absolute_error: 1.7327 - mean_squared_error: 5.9289 - val_loss: 8.5703 - val_mean_absolute_error: 2.1802 - val_mean_squared_error: 8.5703\n",
      "Epoch 115/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.9631 - mean_absolute_error: 1.6979 - mean_squared_error: 5.9631 - val_loss: 8.6055 - val_mean_absolute_error: 2.2404 - val_mean_squared_error: 8.6055\n",
      "Epoch 116/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.8631 - mean_absolute_error: 1.6929 - mean_squared_error: 5.8631 - val_loss: 8.5834 - val_mean_absolute_error: 2.1944 - val_mean_squared_error: 8.5834\n",
      "Epoch 117/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.8694 - mean_absolute_error: 1.7110 - mean_squared_error: 5.8694 - val_loss: 8.6041 - val_mean_absolute_error: 2.1988 - val_mean_squared_error: 8.6041\n",
      "Epoch 118/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.8320 - mean_absolute_error: 1.6950 - mean_squared_error: 5.8320 - val_loss: 8.6286 - val_mean_absolute_error: 2.2138 - val_mean_squared_error: 8.6286\n",
      "Epoch 119/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.8571 - mean_absolute_error: 1.6959 - mean_squared_error: 5.8571 - val_loss: 8.6232 - val_mean_absolute_error: 2.2188 - val_mean_squared_error: 8.6232\n",
      "Epoch 120/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.9089 - mean_absolute_error: 1.7001 - mean_squared_error: 5.9089 - val_loss: 8.4875 - val_mean_absolute_error: 2.1933 - val_mean_squared_error: 8.4875\n",
      "Epoch 121/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.8840 - mean_absolute_error: 1.7146 - mean_squared_error: 5.8840 - val_loss: 8.5516 - val_mean_absolute_error: 2.1959 - val_mean_squared_error: 8.5516\n",
      "Epoch 122/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.7693 - mean_absolute_error: 1.6871 - mean_squared_error: 5.7693 - val_loss: 8.5414 - val_mean_absolute_error: 2.2169 - val_mean_squared_error: 8.5414\n",
      "Epoch 123/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.8397 - mean_absolute_error: 1.6925 - mean_squared_error: 5.8397 - val_loss: 8.6481 - val_mean_absolute_error: 2.2265 - val_mean_squared_error: 8.6481\n",
      "Epoch 124/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.8093 - mean_absolute_error: 1.6702 - mean_squared_error: 5.8093 - val_loss: 8.4866 - val_mean_absolute_error: 2.2205 - val_mean_squared_error: 8.4866\n",
      "Epoch 125/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.7510 - mean_absolute_error: 1.6772 - mean_squared_error: 5.7510 - val_loss: 8.5259 - val_mean_absolute_error: 2.1804 - val_mean_squared_error: 8.5259\n",
      "Epoch 126/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.7895 - mean_absolute_error: 1.6951 - mean_squared_error: 5.7895 - val_loss: 8.5447 - val_mean_absolute_error: 2.2049 - val_mean_squared_error: 8.5447\n",
      "Epoch 127/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 5.7844 - mean_absolute_error: 1.6979 - mean_squared_error: 5.7844 - val_loss: 8.5169 - val_mean_absolute_error: 2.1975 - val_mean_squared_error: 8.5169\n",
      "Epoch 128/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.9759 - mean_absolute_error: 1.6967 - mean_squared_error: 5.9759 - val_loss: 8.6763 - val_mean_absolute_error: 2.2463 - val_mean_squared_error: 8.6763\n",
      "Epoch 129/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.7373 - mean_absolute_error: 1.6667 - mean_squared_error: 5.7373 - val_loss: 8.5437 - val_mean_absolute_error: 2.1823 - val_mean_squared_error: 8.5437\n",
      "Epoch 130/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.7130 - mean_absolute_error: 1.6925 - mean_squared_error: 5.7130 - val_loss: 8.5475 - val_mean_absolute_error: 2.2084 - val_mean_squared_error: 8.5475\n",
      "Epoch 131/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.6822 - mean_absolute_error: 1.6684 - mean_squared_error: 5.6822 - val_loss: 8.6035 - val_mean_absolute_error: 2.2255 - val_mean_squared_error: 8.6035\n",
      "Epoch 132/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.6839 - mean_absolute_error: 1.6546 - mean_squared_error: 5.6839 - val_loss: 8.5817 - val_mean_absolute_error: 2.2123 - val_mean_squared_error: 8.5817\n",
      "Epoch 133/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.6665 - mean_absolute_error: 1.6671 - mean_squared_error: 5.6665 - val_loss: 8.5090 - val_mean_absolute_error: 2.1970 - val_mean_squared_error: 8.5090\n",
      "Epoch 134/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.6763 - mean_absolute_error: 1.6572 - mean_squared_error: 5.6763 - val_loss: 8.4720 - val_mean_absolute_error: 2.2026 - val_mean_squared_error: 8.4720\n",
      "Epoch 135/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.6785 - mean_absolute_error: 1.6510 - mean_squared_error: 5.6785 - val_loss: 8.4987 - val_mean_absolute_error: 2.2234 - val_mean_squared_error: 8.4987\n",
      "Epoch 136/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 5.7824 - mean_absolute_error: 1.6916 - mean_squared_error: 5.7824 - val_loss: 8.5973 - val_mean_absolute_error: 2.1821 - val_mean_squared_error: 8.5973\n",
      "Epoch 137/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.5911 - mean_absolute_error: 1.6626 - mean_squared_error: 5.5911 - val_loss: 8.5866 - val_mean_absolute_error: 2.2408 - val_mean_squared_error: 8.5866\n",
      "Epoch 138/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.6356 - mean_absolute_error: 1.6408 - mean_squared_error: 5.6356 - val_loss: 8.5545 - val_mean_absolute_error: 2.2324 - val_mean_squared_error: 8.5545\n",
      "Epoch 139/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.5800 - mean_absolute_error: 1.6444 - mean_squared_error: 5.5800 - val_loss: 8.5776 - val_mean_absolute_error: 2.2034 - val_mean_squared_error: 8.5776\n",
      "Epoch 140/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 5.6484 - mean_absolute_error: 1.6835 - mean_squared_error: 5.6484 - val_loss: 8.4736 - val_mean_absolute_error: 2.1792 - val_mean_squared_error: 8.4736\n",
      "Epoch 141/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.6270 - mean_absolute_error: 1.6487 - mean_squared_error: 5.6270 - val_loss: 8.4493 - val_mean_absolute_error: 2.2228 - val_mean_squared_error: 8.4493\n",
      "Epoch 142/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.5627 - mean_absolute_error: 1.6411 - mean_squared_error: 5.5627 - val_loss: 8.4645 - val_mean_absolute_error: 2.1898 - val_mean_squared_error: 8.4645\n",
      "Epoch 143/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.7186 - mean_absolute_error: 1.6885 - mean_squared_error: 5.7186 - val_loss: 8.4859 - val_mean_absolute_error: 2.1772 - val_mean_squared_error: 8.4859\n",
      "Epoch 144/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.7043 - mean_absolute_error: 1.6478 - mean_squared_error: 5.7043 - val_loss: 8.5733 - val_mean_absolute_error: 2.2528 - val_mean_squared_error: 8.5733\n",
      "Epoch 145/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.5779 - mean_absolute_error: 1.6368 - mean_squared_error: 5.5779 - val_loss: 8.4948 - val_mean_absolute_error: 2.1756 - val_mean_squared_error: 8.4948\n",
      "Epoch 146/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.5634 - mean_absolute_error: 1.6572 - mean_squared_error: 5.5634 - val_loss: 8.3575 - val_mean_absolute_error: 2.1916 - val_mean_squared_error: 8.3575\n",
      "Epoch 147/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.5793 - mean_absolute_error: 1.6327 - mean_squared_error: 5.5793 - val_loss: 8.5434 - val_mean_absolute_error: 2.2221 - val_mean_squared_error: 8.5434\n",
      "Epoch 148/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.5747 - mean_absolute_error: 1.6440 - mean_squared_error: 5.5747 - val_loss: 8.4230 - val_mean_absolute_error: 2.1684 - val_mean_squared_error: 8.4230\n",
      "Epoch 149/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.5294 - mean_absolute_error: 1.6400 - mean_squared_error: 5.5294 - val_loss: 8.3975 - val_mean_absolute_error: 2.2161 - val_mean_squared_error: 8.3975\n",
      "Epoch 150/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.5428 - mean_absolute_error: 1.6257 - mean_squared_error: 5.5428 - val_loss: 8.3620 - val_mean_absolute_error: 2.1790 - val_mean_squared_error: 8.3620\n",
      "Epoch 151/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.5787 - mean_absolute_error: 1.6564 - mean_squared_error: 5.5787 - val_loss: 8.3978 - val_mean_absolute_error: 2.1726 - val_mean_squared_error: 8.3978\n",
      "Epoch 152/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.5002 - mean_absolute_error: 1.6259 - mean_squared_error: 5.5002 - val_loss: 8.5327 - val_mean_absolute_error: 2.2285 - val_mean_squared_error: 8.5327\n",
      "Epoch 153/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.4982 - mean_absolute_error: 1.6223 - mean_squared_error: 5.4982 - val_loss: 8.4659 - val_mean_absolute_error: 2.2051 - val_mean_squared_error: 8.4659\n",
      "Epoch 154/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.4313 - mean_absolute_error: 1.6111 - mean_squared_error: 5.4313 - val_loss: 8.3663 - val_mean_absolute_error: 2.1845 - val_mean_squared_error: 8.3663\n",
      "Epoch 155/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.5084 - mean_absolute_error: 1.6441 - mean_squared_error: 5.5084 - val_loss: 8.3272 - val_mean_absolute_error: 2.1629 - val_mean_squared_error: 8.3272\n",
      "Epoch 156/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.4812 - mean_absolute_error: 1.6215 - mean_squared_error: 5.4812 - val_loss: 8.5495 - val_mean_absolute_error: 2.2357 - val_mean_squared_error: 8.5495\n",
      "Epoch 157/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.4640 - mean_absolute_error: 1.6209 - mean_squared_error: 5.4640 - val_loss: 8.4148 - val_mean_absolute_error: 2.1888 - val_mean_squared_error: 8.4148\n",
      "Epoch 158/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.4783 - mean_absolute_error: 1.6416 - mean_squared_error: 5.4783 - val_loss: 8.4994 - val_mean_absolute_error: 2.2139 - val_mean_squared_error: 8.4994\n",
      "Epoch 159/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.4192 - mean_absolute_error: 1.6043 - mean_squared_error: 5.4192 - val_loss: 8.4456 - val_mean_absolute_error: 2.2122 - val_mean_squared_error: 8.4456\n",
      "Epoch 160/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.4449 - mean_absolute_error: 1.6051 - mean_squared_error: 5.4449 - val_loss: 8.3200 - val_mean_absolute_error: 2.1885 - val_mean_squared_error: 8.3200\n",
      "Epoch 161/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.4072 - mean_absolute_error: 1.6283 - mean_squared_error: 5.4072 - val_loss: 8.4031 - val_mean_absolute_error: 2.1679 - val_mean_squared_error: 8.4031\n",
      "Epoch 162/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.4487 - mean_absolute_error: 1.6352 - mean_squared_error: 5.4487 - val_loss: 8.3795 - val_mean_absolute_error: 2.1922 - val_mean_squared_error: 8.3795\n",
      "Epoch 163/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.4277 - mean_absolute_error: 1.5970 - mean_squared_error: 5.4277 - val_loss: 8.4348 - val_mean_absolute_error: 2.2159 - val_mean_squared_error: 8.4348\n",
      "Epoch 164/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.4042 - mean_absolute_error: 1.6058 - mean_squared_error: 5.4042 - val_loss: 8.3407 - val_mean_absolute_error: 2.1761 - val_mean_squared_error: 8.3407\n",
      "Epoch 165/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 5.4055 - mean_absolute_error: 1.6289 - mean_squared_error: 5.4055 - val_loss: 8.3779 - val_mean_absolute_error: 2.1941 - val_mean_squared_error: 8.3779\n",
      "Epoch 166/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 5.3490 - mean_absolute_error: 1.5960 - mean_squared_error: 5.3490 - val_loss: 8.3240 - val_mean_absolute_error: 2.2071 - val_mean_squared_error: 8.3240\n",
      "Epoch 167/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.3885 - mean_absolute_error: 1.6064 - mean_squared_error: 5.3885 - val_loss: 8.3535 - val_mean_absolute_error: 2.1780 - val_mean_squared_error: 8.3535\n",
      "Epoch 168/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.3894 - mean_absolute_error: 1.6130 - mean_squared_error: 5.3894 - val_loss: 8.4549 - val_mean_absolute_error: 2.2019 - val_mean_squared_error: 8.4549\n",
      "Epoch 169/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.4054 - mean_absolute_error: 1.6150 - mean_squared_error: 5.4054 - val_loss: 8.3453 - val_mean_absolute_error: 2.1905 - val_mean_squared_error: 8.3453\n",
      "Epoch 170/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.3326 - mean_absolute_error: 1.5957 - mean_squared_error: 5.3326 - val_loss: 8.3987 - val_mean_absolute_error: 2.2009 - val_mean_squared_error: 8.3987\n",
      "Epoch 171/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.3186 - mean_absolute_error: 1.5942 - mean_squared_error: 5.3186 - val_loss: 8.4336 - val_mean_absolute_error: 2.1917 - val_mean_squared_error: 8.4336\n",
      "Epoch 172/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.3248 - mean_absolute_error: 1.5930 - mean_squared_error: 5.3248 - val_loss: 8.3383 - val_mean_absolute_error: 2.1974 - val_mean_squared_error: 8.3383\n",
      "Epoch 173/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.4524 - mean_absolute_error: 1.6294 - mean_squared_error: 5.4524 - val_loss: 8.4146 - val_mean_absolute_error: 2.1741 - val_mean_squared_error: 8.4146\n",
      "Epoch 174/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.4635 - mean_absolute_error: 1.5949 - mean_squared_error: 5.4635 - val_loss: 8.4933 - val_mean_absolute_error: 2.2324 - val_mean_squared_error: 8.4933\n",
      "Epoch 175/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 5.7229 - mean_absolute_error: 1.6518 - mean_squared_error: 5.7229 - val_loss: 8.3710 - val_mean_absolute_error: 2.1511 - val_mean_squared_error: 8.3710\n",
      "Epoch 176/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 44us/sample - loss: 5.3210 - mean_absolute_error: 1.5981 - mean_squared_error: 5.3210 - val_loss: 8.5758 - val_mean_absolute_error: 2.2535 - val_mean_squared_error: 8.5758\n",
      "Epoch 177/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.3322 - mean_absolute_error: 1.5819 - mean_squared_error: 5.3322 - val_loss: 8.2775 - val_mean_absolute_error: 2.1798 - val_mean_squared_error: 8.2775\n",
      "Epoch 178/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.4081 - mean_absolute_error: 1.6280 - mean_squared_error: 5.4081 - val_loss: 8.3423 - val_mean_absolute_error: 2.1570 - val_mean_squared_error: 8.3423\n",
      "Epoch 179/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.5167 - mean_absolute_error: 1.6077 - mean_squared_error: 5.5167 - val_loss: 8.4242 - val_mean_absolute_error: 2.2273 - val_mean_squared_error: 8.4242\n",
      "Epoch 180/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.4193 - mean_absolute_error: 1.6192 - mean_squared_error: 5.4193 - val_loss: 8.2692 - val_mean_absolute_error: 2.1446 - val_mean_squared_error: 8.2692\n",
      "Epoch 181/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.5060 - mean_absolute_error: 1.5995 - mean_squared_error: 5.5060 - val_loss: 8.3208 - val_mean_absolute_error: 2.2108 - val_mean_squared_error: 8.3208\n",
      "Epoch 182/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.3003 - mean_absolute_error: 1.5954 - mean_squared_error: 5.3003 - val_loss: 8.2448 - val_mean_absolute_error: 2.1474 - val_mean_squared_error: 8.2448\n",
      "Epoch 183/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.3669 - mean_absolute_error: 1.6417 - mean_squared_error: 5.3669 - val_loss: 8.3956 - val_mean_absolute_error: 2.1788 - val_mean_squared_error: 8.3956\n",
      "Epoch 184/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.5936 - mean_absolute_error: 1.6025 - mean_squared_error: 5.5936 - val_loss: 8.5531 - val_mean_absolute_error: 2.2441 - val_mean_squared_error: 8.5531\n",
      "Epoch 185/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.4403 - mean_absolute_error: 1.6350 - mean_squared_error: 5.4403 - val_loss: 8.3075 - val_mean_absolute_error: 2.1315 - val_mean_squared_error: 8.3075\n",
      "Epoch 186/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.3516 - mean_absolute_error: 1.5955 - mean_squared_error: 5.3516 - val_loss: 8.3192 - val_mean_absolute_error: 2.2042 - val_mean_squared_error: 8.3192\n",
      "Epoch 187/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 5.2363 - mean_absolute_error: 1.5670 - mean_squared_error: 5.2363 - val_loss: 8.3476 - val_mean_absolute_error: 2.1760 - val_mean_squared_error: 8.3476\n",
      "Epoch 188/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 5.2357 - mean_absolute_error: 1.5892 - mean_squared_error: 5.2357 - val_loss: 8.3128 - val_mean_absolute_error: 2.1818 - val_mean_squared_error: 8.3128\n",
      "Epoch 189/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.2145 - mean_absolute_error: 1.5621 - mean_squared_error: 5.2145 - val_loss: 8.2925 - val_mean_absolute_error: 2.1950 - val_mean_squared_error: 8.2925\n",
      "Epoch 190/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.2073 - mean_absolute_error: 1.5756 - mean_squared_error: 5.2073 - val_loss: 8.3556 - val_mean_absolute_error: 2.1738 - val_mean_squared_error: 8.3556\n",
      "Epoch 191/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.3447 - mean_absolute_error: 1.6158 - mean_squared_error: 5.3447 - val_loss: 8.2692 - val_mean_absolute_error: 2.1942 - val_mean_squared_error: 8.2692\n",
      "Epoch 192/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 5.2443 - mean_absolute_error: 1.5614 - mean_squared_error: 5.2443 - val_loss: 8.4570 - val_mean_absolute_error: 2.2249 - val_mean_squared_error: 8.4570\n",
      "Epoch 193/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.1853 - mean_absolute_error: 1.5774 - mean_squared_error: 5.1853 - val_loss: 8.3280 - val_mean_absolute_error: 2.1514 - val_mean_squared_error: 8.3280\n",
      "Epoch 194/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.2476 - mean_absolute_error: 1.5893 - mean_squared_error: 5.2476 - val_loss: 8.3171 - val_mean_absolute_error: 2.1890 - val_mean_squared_error: 8.3171\n",
      "Epoch 195/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.2815 - mean_absolute_error: 1.5681 - mean_squared_error: 5.2815 - val_loss: 8.2191 - val_mean_absolute_error: 2.1917 - val_mean_squared_error: 8.2191\n",
      "Epoch 196/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.3586 - mean_absolute_error: 1.6142 - mean_squared_error: 5.3586 - val_loss: 8.3192 - val_mean_absolute_error: 2.1347 - val_mean_squared_error: 8.3192\n",
      "Epoch 197/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 5.1123 - mean_absolute_error: 1.5799 - mean_squared_error: 5.1123 - val_loss: 8.3532 - val_mean_absolute_error: 2.2106 - val_mean_squared_error: 8.3532\n",
      "Epoch 198/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.2646 - mean_absolute_error: 1.5619 - mean_squared_error: 5.2646 - val_loss: 8.3894 - val_mean_absolute_error: 2.2071 - val_mean_squared_error: 8.3894\n",
      "Epoch 199/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.2064 - mean_absolute_error: 1.5798 - mean_squared_error: 5.2064 - val_loss: 8.1981 - val_mean_absolute_error: 2.1411 - val_mean_squared_error: 8.1981\n",
      "Epoch 200/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 5.1759 - mean_absolute_error: 1.5809 - mean_squared_error: 5.1759 - val_loss: 8.2631 - val_mean_absolute_error: 2.1816 - val_mean_squared_error: 8.2631\n",
      "Epoch 201/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 5.1659 - mean_absolute_error: 1.5515 - mean_squared_error: 5.1659 - val_loss: 8.3772 - val_mean_absolute_error: 2.2070 - val_mean_squared_error: 8.3772\n",
      "Epoch 202/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.2630 - mean_absolute_error: 1.5634 - mean_squared_error: 5.2630 - val_loss: 8.4079 - val_mean_absolute_error: 2.2059 - val_mean_squared_error: 8.4079\n",
      "Epoch 203/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.1653 - mean_absolute_error: 1.5767 - mean_squared_error: 5.1653 - val_loss: 8.3698 - val_mean_absolute_error: 2.1381 - val_mean_squared_error: 8.3698\n",
      "Epoch 204/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.1604 - mean_absolute_error: 1.5676 - mean_squared_error: 5.1604 - val_loss: 8.3630 - val_mean_absolute_error: 2.2109 - val_mean_squared_error: 8.3630\n",
      "Epoch 205/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 5.1811 - mean_absolute_error: 1.5434 - mean_squared_error: 5.1811 - val_loss: 8.3853 - val_mean_absolute_error: 2.1947 - val_mean_squared_error: 8.3853\n",
      "Epoch 206/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.1638 - mean_absolute_error: 1.5684 - mean_squared_error: 5.1638 - val_loss: 8.2445 - val_mean_absolute_error: 2.1626 - val_mean_squared_error: 8.2445\n",
      "Epoch 207/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.1910 - mean_absolute_error: 1.5846 - mean_squared_error: 5.1910 - val_loss: 8.2861 - val_mean_absolute_error: 2.1655 - val_mean_squared_error: 8.2861\n",
      "Epoch 208/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.3955 - mean_absolute_error: 1.5590 - mean_squared_error: 5.3955 - val_loss: 8.3100 - val_mean_absolute_error: 2.2100 - val_mean_squared_error: 8.3100\n",
      "Epoch 209/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 5.1514 - mean_absolute_error: 1.5787 - mean_squared_error: 5.1514 - val_loss: 8.3242 - val_mean_absolute_error: 2.1407 - val_mean_squared_error: 8.3242\n",
      "Epoch 210/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.1846 - mean_absolute_error: 1.6006 - mean_squared_error: 5.1846 - val_loss: 8.2986 - val_mean_absolute_error: 2.1883 - val_mean_squared_error: 8.2986\n",
      "Epoch 211/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.1756 - mean_absolute_error: 1.5504 - mean_squared_error: 5.1756 - val_loss: 8.4080 - val_mean_absolute_error: 2.2155 - val_mean_squared_error: 8.4080\n",
      "Epoch 212/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 5.1055 - mean_absolute_error: 1.5560 - mean_squared_error: 5.1055 - val_loss: 8.2039 - val_mean_absolute_error: 2.1424 - val_mean_squared_error: 8.2039\n",
      "Epoch 213/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.1239 - mean_absolute_error: 1.5769 - mean_squared_error: 5.1239 - val_loss: 8.2594 - val_mean_absolute_error: 2.1817 - val_mean_squared_error: 8.2594\n",
      "Epoch 214/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.2160 - mean_absolute_error: 1.5531 - mean_squared_error: 5.2160 - val_loss: 8.3123 - val_mean_absolute_error: 2.2110 - val_mean_squared_error: 8.3123\n",
      "Epoch 215/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.0215 - mean_absolute_error: 1.5409 - mean_squared_error: 5.0215 - val_loss: 8.4241 - val_mean_absolute_error: 2.1555 - val_mean_squared_error: 8.4241\n",
      "Epoch 216/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.1096 - mean_absolute_error: 1.5700 - mean_squared_error: 5.1096 - val_loss: 8.2722 - val_mean_absolute_error: 2.1587 - val_mean_squared_error: 8.2722\n",
      "Epoch 217/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.1321 - mean_absolute_error: 1.5414 - mean_squared_error: 5.1321 - val_loss: 8.2873 - val_mean_absolute_error: 2.1909 - val_mean_squared_error: 8.2873\n",
      "Epoch 218/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.1599 - mean_absolute_error: 1.5614 - mean_squared_error: 5.1599 - val_loss: 8.3048 - val_mean_absolute_error: 2.1646 - val_mean_squared_error: 8.3048\n",
      "Epoch 219/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.1042 - mean_absolute_error: 1.5421 - mean_squared_error: 5.1042 - val_loss: 8.3292 - val_mean_absolute_error: 2.1923 - val_mean_squared_error: 8.3292\n",
      "Epoch 220/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.0688 - mean_absolute_error: 1.5461 - mean_squared_error: 5.0688 - val_loss: 8.3307 - val_mean_absolute_error: 2.1800 - val_mean_squared_error: 8.3307\n",
      "Epoch 221/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.0689 - mean_absolute_error: 1.5425 - mean_squared_error: 5.0689 - val_loss: 8.2562 - val_mean_absolute_error: 2.1699 - val_mean_squared_error: 8.2562\n",
      "Epoch 222/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.0475 - mean_absolute_error: 1.5536 - mean_squared_error: 5.0475 - val_loss: 8.2250 - val_mean_absolute_error: 2.1648 - val_mean_squared_error: 8.2250\n",
      "Epoch 223/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.0298 - mean_absolute_error: 1.5370 - mean_squared_error: 5.0298 - val_loss: 8.1856 - val_mean_absolute_error: 2.1663 - val_mean_squared_error: 8.1856\n",
      "Epoch 224/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.0273 - mean_absolute_error: 1.5396 - mean_squared_error: 5.0273 - val_loss: 8.1616 - val_mean_absolute_error: 2.1627 - val_mean_squared_error: 8.1616\n",
      "Epoch 225/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.2720 - mean_absolute_error: 1.6051 - mean_squared_error: 5.2720 - val_loss: 8.1083 - val_mean_absolute_error: 2.1403 - val_mean_squared_error: 8.1083\n",
      "Epoch 226/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.1121 - mean_absolute_error: 1.5404 - mean_squared_error: 5.1121 - val_loss: 8.4086 - val_mean_absolute_error: 2.2171 - val_mean_squared_error: 8.4086\n",
      "Epoch 227/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.0493 - mean_absolute_error: 1.5410 - mean_squared_error: 5.0493 - val_loss: 8.3218 - val_mean_absolute_error: 2.1565 - val_mean_squared_error: 8.3218\n",
      "Epoch 228/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.0770 - mean_absolute_error: 1.5643 - mean_squared_error: 5.0770 - val_loss: 8.1796 - val_mean_absolute_error: 2.1625 - val_mean_squared_error: 8.1796\n",
      "Epoch 229/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.0670 - mean_absolute_error: 1.5276 - mean_squared_error: 5.0670 - val_loss: 8.2684 - val_mean_absolute_error: 2.1795 - val_mean_squared_error: 8.2684\n",
      "Epoch 230/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.1616 - mean_absolute_error: 1.5740 - mean_squared_error: 5.1616 - val_loss: 8.1740 - val_mean_absolute_error: 2.1510 - val_mean_squared_error: 8.1740\n",
      "Epoch 231/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.9738 - mean_absolute_error: 1.5403 - mean_squared_error: 4.9738 - val_loss: 8.3474 - val_mean_absolute_error: 2.1920 - val_mean_squared_error: 8.3474\n",
      "Epoch 232/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 5.0630 - mean_absolute_error: 1.5316 - mean_squared_error: 5.0630 - val_loss: 8.3999 - val_mean_absolute_error: 2.1870 - val_mean_squared_error: 8.3999\n",
      "Epoch 233/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 5.0523 - mean_absolute_error: 1.5283 - mean_squared_error: 5.0523 - val_loss: 8.1095 - val_mean_absolute_error: 2.1667 - val_mean_squared_error: 8.1095\n",
      "Epoch 234/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 5.1468 - mean_absolute_error: 1.5754 - mean_squared_error: 5.1468 - val_loss: 8.3284 - val_mean_absolute_error: 2.1746 - val_mean_squared_error: 8.3284\n",
      "Epoch 235/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.9564 - mean_absolute_error: 1.5145 - mean_squared_error: 4.9564 - val_loss: 8.4036 - val_mean_absolute_error: 2.2159 - val_mean_squared_error: 8.4036\n",
      "Epoch 236/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 5.0640 - mean_absolute_error: 1.5522 - mean_squared_error: 5.0640 - val_loss: 8.3518 - val_mean_absolute_error: 2.1730 - val_mean_squared_error: 8.3518\n",
      "Epoch 237/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.9568 - mean_absolute_error: 1.5399 - mean_squared_error: 4.9568 - val_loss: 8.3640 - val_mean_absolute_error: 2.1996 - val_mean_squared_error: 8.3640\n",
      "Epoch 238/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 5.0024 - mean_absolute_error: 1.5263 - mean_squared_error: 5.0024 - val_loss: 8.1883 - val_mean_absolute_error: 2.1574 - val_mean_squared_error: 8.1883\n",
      "Epoch 239/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.9407 - mean_absolute_error: 1.5286 - mean_squared_error: 4.9407 - val_loss: 8.2194 - val_mean_absolute_error: 2.1766 - val_mean_squared_error: 8.2194\n",
      "Epoch 240/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.0280 - mean_absolute_error: 1.5356 - mean_squared_error: 5.0280 - val_loss: 8.2608 - val_mean_absolute_error: 2.1772 - val_mean_squared_error: 8.2608\n",
      "Epoch 241/400\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 4.9910 - mean_absolute_error: 1.5469 - mean_squared_error: 4.9910 - val_loss: 8.3561 - val_mean_absolute_error: 2.1763 - val_mean_squared_error: 8.3561\n",
      "Epoch 242/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.0106 - mean_absolute_error: 1.5271 - mean_squared_error: 5.0106 - val_loss: 8.3082 - val_mean_absolute_error: 2.1974 - val_mean_squared_error: 8.3082\n",
      "Epoch 243/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.9685 - mean_absolute_error: 1.5038 - mean_squared_error: 4.9685 - val_loss: 8.3430 - val_mean_absolute_error: 2.1760 - val_mean_squared_error: 8.3430\n",
      "Epoch 244/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 5.1542 - mean_absolute_error: 1.6047 - mean_squared_error: 5.1542 - val_loss: 8.4215 - val_mean_absolute_error: 2.1675 - val_mean_squared_error: 8.4215\n",
      "Epoch 245/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 5.0451 - mean_absolute_error: 1.5355 - mean_squared_error: 5.0451 - val_loss: 8.4557 - val_mean_absolute_error: 2.2201 - val_mean_squared_error: 8.4557\n",
      "Epoch 246/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 41us/sample - loss: 4.9471 - mean_absolute_error: 1.5167 - mean_squared_error: 4.9471 - val_loss: 8.2095 - val_mean_absolute_error: 2.1550 - val_mean_squared_error: 8.2095\n",
      "Epoch 247/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.9452 - mean_absolute_error: 1.5199 - mean_squared_error: 4.9452 - val_loss: 8.2574 - val_mean_absolute_error: 2.1733 - val_mean_squared_error: 8.2574\n",
      "Epoch 248/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.9263 - mean_absolute_error: 1.5038 - mean_squared_error: 4.9263 - val_loss: 8.3305 - val_mean_absolute_error: 2.1904 - val_mean_squared_error: 8.3305\n",
      "Epoch 249/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.9735 - mean_absolute_error: 1.5319 - mean_squared_error: 4.9735 - val_loss: 8.2449 - val_mean_absolute_error: 2.1586 - val_mean_squared_error: 8.2449\n",
      "Epoch 250/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.9412 - mean_absolute_error: 1.5176 - mean_squared_error: 4.9412 - val_loss: 8.3200 - val_mean_absolute_error: 2.2053 - val_mean_squared_error: 8.3200\n",
      "Epoch 251/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.9065 - mean_absolute_error: 1.5052 - mean_squared_error: 4.9065 - val_loss: 8.3603 - val_mean_absolute_error: 2.1957 - val_mean_squared_error: 8.3603\n",
      "Epoch 252/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.8968 - mean_absolute_error: 1.5064 - mean_squared_error: 4.8968 - val_loss: 8.3351 - val_mean_absolute_error: 2.1731 - val_mean_squared_error: 8.3351\n",
      "Epoch 253/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.9831 - mean_absolute_error: 1.5120 - mean_squared_error: 4.9831 - val_loss: 8.3309 - val_mean_absolute_error: 2.1956 - val_mean_squared_error: 8.3309\n",
      "Epoch 254/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 5.0357 - mean_absolute_error: 1.5460 - mean_squared_error: 5.0357 - val_loss: 8.3770 - val_mean_absolute_error: 2.1722 - val_mean_squared_error: 8.3770\n",
      "Epoch 255/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.8083 - mean_absolute_error: 1.4994 - mean_squared_error: 4.8083 - val_loss: 8.4866 - val_mean_absolute_error: 2.2337 - val_mean_squared_error: 8.4866\n",
      "Epoch 256/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.8887 - mean_absolute_error: 1.4985 - mean_squared_error: 4.8887 - val_loss: 8.2843 - val_mean_absolute_error: 2.1741 - val_mean_squared_error: 8.2843\n",
      "Epoch 257/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.8946 - mean_absolute_error: 1.5237 - mean_squared_error: 4.8946 - val_loss: 8.2509 - val_mean_absolute_error: 2.1605 - val_mean_squared_error: 8.2509\n",
      "Epoch 258/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.8824 - mean_absolute_error: 1.5080 - mean_squared_error: 4.8824 - val_loss: 8.3400 - val_mean_absolute_error: 2.1916 - val_mean_squared_error: 8.3400\n",
      "Epoch 259/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.8669 - mean_absolute_error: 1.4938 - mean_squared_error: 4.8669 - val_loss: 8.3117 - val_mean_absolute_error: 2.1827 - val_mean_squared_error: 8.3117\n",
      "Epoch 260/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.8187 - mean_absolute_error: 1.5030 - mean_squared_error: 4.8187 - val_loss: 8.3843 - val_mean_absolute_error: 2.1812 - val_mean_squared_error: 8.3843\n",
      "Epoch 261/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.8490 - mean_absolute_error: 1.5117 - mean_squared_error: 4.8490 - val_loss: 8.3337 - val_mean_absolute_error: 2.1795 - val_mean_squared_error: 8.3337\n",
      "Epoch 262/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.8515 - mean_absolute_error: 1.4843 - mean_squared_error: 4.8515 - val_loss: 8.4198 - val_mean_absolute_error: 2.2150 - val_mean_squared_error: 8.4198\n",
      "Epoch 263/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.8171 - mean_absolute_error: 1.4873 - mean_squared_error: 4.8171 - val_loss: 8.2440 - val_mean_absolute_error: 2.1836 - val_mean_squared_error: 8.2440\n",
      "Epoch 264/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.8105 - mean_absolute_error: 1.5095 - mean_squared_error: 4.8105 - val_loss: 8.2649 - val_mean_absolute_error: 2.1635 - val_mean_squared_error: 8.2649\n",
      "Epoch 265/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.8439 - mean_absolute_error: 1.5073 - mean_squared_error: 4.8439 - val_loss: 8.4383 - val_mean_absolute_error: 2.2209 - val_mean_squared_error: 8.4383\n",
      "Epoch 266/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.8307 - mean_absolute_error: 1.4987 - mean_squared_error: 4.8307 - val_loss: 8.3730 - val_mean_absolute_error: 2.1824 - val_mean_squared_error: 8.3730\n",
      "Epoch 267/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.7533 - mean_absolute_error: 1.4871 - mean_squared_error: 4.7533 - val_loss: 8.2487 - val_mean_absolute_error: 2.1783 - val_mean_squared_error: 8.2487\n",
      "Epoch 268/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.7901 - mean_absolute_error: 1.4791 - mean_squared_error: 4.7901 - val_loss: 8.2539 - val_mean_absolute_error: 2.1967 - val_mean_squared_error: 8.2539\n",
      "Epoch 269/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.8783 - mean_absolute_error: 1.5249 - mean_squared_error: 4.8783 - val_loss: 8.2633 - val_mean_absolute_error: 2.1656 - val_mean_squared_error: 8.2633\n",
      "Epoch 270/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.7649 - mean_absolute_error: 1.4732 - mean_squared_error: 4.7649 - val_loss: 8.4861 - val_mean_absolute_error: 2.2267 - val_mean_squared_error: 8.4861\n",
      "Epoch 271/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.9233 - mean_absolute_error: 1.5059 - mean_squared_error: 4.9233 - val_loss: 8.3400 - val_mean_absolute_error: 2.1707 - val_mean_squared_error: 8.3400\n",
      "Epoch 272/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.7865 - mean_absolute_error: 1.4724 - mean_squared_error: 4.7865 - val_loss: 8.2171 - val_mean_absolute_error: 2.1885 - val_mean_squared_error: 8.2171\n",
      "Epoch 273/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.7757 - mean_absolute_error: 1.4897 - mean_squared_error: 4.7757 - val_loss: 8.3507 - val_mean_absolute_error: 2.1849 - val_mean_squared_error: 8.3507\n",
      "Epoch 274/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.6902 - mean_absolute_error: 1.4778 - mean_squared_error: 4.6902 - val_loss: 8.3885 - val_mean_absolute_error: 2.2016 - val_mean_squared_error: 8.3885\n",
      "Epoch 275/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.7588 - mean_absolute_error: 1.4748 - mean_squared_error: 4.7588 - val_loss: 8.3296 - val_mean_absolute_error: 2.1834 - val_mean_squared_error: 8.3296\n",
      "Epoch 276/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.7039 - mean_absolute_error: 1.4763 - mean_squared_error: 4.7039 - val_loss: 8.2951 - val_mean_absolute_error: 2.1810 - val_mean_squared_error: 8.2951\n",
      "Epoch 277/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.7219 - mean_absolute_error: 1.4875 - mean_squared_error: 4.7219 - val_loss: 8.3990 - val_mean_absolute_error: 2.1859 - val_mean_squared_error: 8.3990\n",
      "Epoch 278/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.7467 - mean_absolute_error: 1.4690 - mean_squared_error: 4.7467 - val_loss: 8.5260 - val_mean_absolute_error: 2.2021 - val_mean_squared_error: 8.5260\n",
      "Epoch 279/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.7458 - mean_absolute_error: 1.4649 - mean_squared_error: 4.7458 - val_loss: 8.3347 - val_mean_absolute_error: 2.2116 - val_mean_squared_error: 8.3347\n",
      "Epoch 280/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.6647 - mean_absolute_error: 1.4687 - mean_squared_error: 4.6647 - val_loss: 8.3981 - val_mean_absolute_error: 2.1890 - val_mean_squared_error: 8.3981\n",
      "Epoch 281/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 4.8089 - mean_absolute_error: 1.4728 - mean_squared_error: 4.8089 - val_loss: 8.4992 - val_mean_absolute_error: 2.1915 - val_mean_squared_error: 8.4992\n",
      "Epoch 282/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.7186 - mean_absolute_error: 1.4839 - mean_squared_error: 4.7186 - val_loss: 8.3009 - val_mean_absolute_error: 2.1736 - val_mean_squared_error: 8.3009\n",
      "Epoch 283/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.7502 - mean_absolute_error: 1.5043 - mean_squared_error: 4.7502 - val_loss: 8.3228 - val_mean_absolute_error: 2.1827 - val_mean_squared_error: 8.3228\n",
      "Epoch 284/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.7001 - mean_absolute_error: 1.4661 - mean_squared_error: 4.7001 - val_loss: 8.5348 - val_mean_absolute_error: 2.2283 - val_mean_squared_error: 8.5348\n",
      "Epoch 285/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.7507 - mean_absolute_error: 1.4802 - mean_squared_error: 4.7507 - val_loss: 8.3036 - val_mean_absolute_error: 2.1801 - val_mean_squared_error: 8.3036\n",
      "Epoch 286/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 4.7185 - mean_absolute_error: 1.4616 - mean_squared_error: 4.7185 - val_loss: 8.5004 - val_mean_absolute_error: 2.2181 - val_mean_squared_error: 8.5004\n",
      "Epoch 287/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.6310 - mean_absolute_error: 1.4465 - mean_squared_error: 4.6310 - val_loss: 8.5471 - val_mean_absolute_error: 2.2239 - val_mean_squared_error: 8.5471\n",
      "Epoch 288/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.8438 - mean_absolute_error: 1.5046 - mean_squared_error: 4.8438 - val_loss: 8.3511 - val_mean_absolute_error: 2.1863 - val_mean_squared_error: 8.3511\n",
      "Epoch 289/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.6059 - mean_absolute_error: 1.4357 - mean_squared_error: 4.6059 - val_loss: 8.4167 - val_mean_absolute_error: 2.2211 - val_mean_squared_error: 8.4167\n",
      "Epoch 290/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 4.6347 - mean_absolute_error: 1.4513 - mean_squared_error: 4.6347 - val_loss: 8.3918 - val_mean_absolute_error: 2.1981 - val_mean_squared_error: 8.3918\n",
      "Epoch 291/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.6078 - mean_absolute_error: 1.4585 - mean_squared_error: 4.6078 - val_loss: 8.4536 - val_mean_absolute_error: 2.1919 - val_mean_squared_error: 8.4536\n",
      "Epoch 292/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.7711 - mean_absolute_error: 1.4991 - mean_squared_error: 4.7711 - val_loss: 8.3195 - val_mean_absolute_error: 2.1816 - val_mean_squared_error: 8.3195\n",
      "Epoch 293/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.6554 - mean_absolute_error: 1.4464 - mean_squared_error: 4.6554 - val_loss: 8.5715 - val_mean_absolute_error: 2.2342 - val_mean_squared_error: 8.5715\n",
      "Epoch 294/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.5687 - mean_absolute_error: 1.4500 - mean_squared_error: 4.5687 - val_loss: 8.4956 - val_mean_absolute_error: 2.1994 - val_mean_squared_error: 8.4956\n",
      "Epoch 295/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.6372 - mean_absolute_error: 1.4647 - mean_squared_error: 4.6372 - val_loss: 8.4655 - val_mean_absolute_error: 2.2145 - val_mean_squared_error: 8.4655\n",
      "Epoch 296/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.5801 - mean_absolute_error: 1.4264 - mean_squared_error: 4.5801 - val_loss: 8.3830 - val_mean_absolute_error: 2.1966 - val_mean_squared_error: 8.3830\n",
      "Epoch 297/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.6468 - mean_absolute_error: 1.4781 - mean_squared_error: 4.6468 - val_loss: 8.4455 - val_mean_absolute_error: 2.1879 - val_mean_squared_error: 8.4455\n",
      "Epoch 298/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.6003 - mean_absolute_error: 1.4416 - mean_squared_error: 4.6003 - val_loss: 8.4310 - val_mean_absolute_error: 2.2229 - val_mean_squared_error: 8.4310\n",
      "Epoch 299/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.5862 - mean_absolute_error: 1.4371 - mean_squared_error: 4.5862 - val_loss: 8.4062 - val_mean_absolute_error: 2.1825 - val_mean_squared_error: 8.4062\n",
      "Epoch 300/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.5005 - mean_absolute_error: 1.4434 - mean_squared_error: 4.5005 - val_loss: 8.4945 - val_mean_absolute_error: 2.2087 - val_mean_squared_error: 8.4945\n",
      "Epoch 301/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.5371 - mean_absolute_error: 1.4362 - mean_squared_error: 4.5371 - val_loss: 8.4527 - val_mean_absolute_error: 2.2041 - val_mean_squared_error: 8.4527\n",
      "Epoch 302/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.5991 - mean_absolute_error: 1.4365 - mean_squared_error: 4.5991 - val_loss: 8.3775 - val_mean_absolute_error: 2.2026 - val_mean_squared_error: 8.3775\n",
      "Epoch 303/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.5733 - mean_absolute_error: 1.4716 - mean_squared_error: 4.5733 - val_loss: 8.5941 - val_mean_absolute_error: 2.2096 - val_mean_squared_error: 8.5941\n",
      "Epoch 304/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.5806 - mean_absolute_error: 1.4383 - mean_squared_error: 4.5806 - val_loss: 8.4873 - val_mean_absolute_error: 2.2038 - val_mean_squared_error: 8.4873\n",
      "Epoch 305/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.7148 - mean_absolute_error: 1.4751 - mean_squared_error: 4.7148 - val_loss: 8.5326 - val_mean_absolute_error: 2.2052 - val_mean_squared_error: 8.5326\n",
      "Epoch 306/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.5071 - mean_absolute_error: 1.4172 - mean_squared_error: 4.5071 - val_loss: 8.5765 - val_mean_absolute_error: 2.2255 - val_mean_squared_error: 8.5765\n",
      "Epoch 307/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.5469 - mean_absolute_error: 1.4221 - mean_squared_error: 4.5469 - val_loss: 8.3754 - val_mean_absolute_error: 2.2136 - val_mean_squared_error: 8.3754\n",
      "Epoch 308/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.5842 - mean_absolute_error: 1.4345 - mean_squared_error: 4.5842 - val_loss: 8.5477 - val_mean_absolute_error: 2.2058 - val_mean_squared_error: 8.5477\n",
      "Epoch 309/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.4415 - mean_absolute_error: 1.4278 - mean_squared_error: 4.4415 - val_loss: 8.5957 - val_mean_absolute_error: 2.2176 - val_mean_squared_error: 8.5957\n",
      "Epoch 310/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.4669 - mean_absolute_error: 1.4286 - mean_squared_error: 4.4669 - val_loss: 8.3780 - val_mean_absolute_error: 2.2001 - val_mean_squared_error: 8.3780\n",
      "Epoch 311/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.4580 - mean_absolute_error: 1.4298 - mean_squared_error: 4.4580 - val_loss: 8.4761 - val_mean_absolute_error: 2.1919 - val_mean_squared_error: 8.4761\n",
      "Epoch 312/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.4512 - mean_absolute_error: 1.4196 - mean_squared_error: 4.4512 - val_loss: 8.4617 - val_mean_absolute_error: 2.2077 - val_mean_squared_error: 8.4617\n",
      "Epoch 313/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.4594 - mean_absolute_error: 1.4210 - mean_squared_error: 4.4594 - val_loss: 8.4524 - val_mean_absolute_error: 2.1988 - val_mean_squared_error: 8.4524\n",
      "Epoch 314/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.4640 - mean_absolute_error: 1.4121 - mean_squared_error: 4.4640 - val_loss: 8.5996 - val_mean_absolute_error: 2.2235 - val_mean_squared_error: 8.5996\n",
      "Epoch 315/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.4220 - mean_absolute_error: 1.4200 - mean_squared_error: 4.4220 - val_loss: 8.6573 - val_mean_absolute_error: 2.2140 - val_mean_squared_error: 8.6573\n",
      "Epoch 316/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 39us/sample - loss: 4.6294 - mean_absolute_error: 1.4749 - mean_squared_error: 4.6294 - val_loss: 8.4442 - val_mean_absolute_error: 2.2088 - val_mean_squared_error: 8.4442\n",
      "Epoch 317/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.8812 - mean_absolute_error: 1.4500 - mean_squared_error: 4.8812 - val_loss: 8.5975 - val_mean_absolute_error: 2.2374 - val_mean_squared_error: 8.5975\n",
      "Epoch 318/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.4990 - mean_absolute_error: 1.4660 - mean_squared_error: 4.4990 - val_loss: 8.6145 - val_mean_absolute_error: 2.1859 - val_mean_squared_error: 8.6145\n",
      "Epoch 319/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.6658 - mean_absolute_error: 1.4847 - mean_squared_error: 4.6658 - val_loss: 8.4968 - val_mean_absolute_error: 2.2405 - val_mean_squared_error: 8.4968\n",
      "Epoch 320/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.5659 - mean_absolute_error: 1.4423 - mean_squared_error: 4.5659 - val_loss: 8.5023 - val_mean_absolute_error: 2.1964 - val_mean_squared_error: 8.5023\n",
      "Epoch 321/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.6125 - mean_absolute_error: 1.4810 - mean_squared_error: 4.6125 - val_loss: 8.5681 - val_mean_absolute_error: 2.2124 - val_mean_squared_error: 8.5681\n",
      "Epoch 322/400\n",
      "251/251 [==============================] - 0s 52us/sample - loss: 4.4824 - mean_absolute_error: 1.4486 - mean_squared_error: 4.4824 - val_loss: 8.3551 - val_mean_absolute_error: 2.2066 - val_mean_squared_error: 8.3551\n",
      "Epoch 323/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.4933 - mean_absolute_error: 1.4061 - mean_squared_error: 4.4933 - val_loss: 8.4893 - val_mean_absolute_error: 2.2095 - val_mean_squared_error: 8.4893\n",
      "Epoch 324/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.3565 - mean_absolute_error: 1.4107 - mean_squared_error: 4.3565 - val_loss: 8.4896 - val_mean_absolute_error: 2.1904 - val_mean_squared_error: 8.4896\n",
      "Epoch 325/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.4637 - mean_absolute_error: 1.4493 - mean_squared_error: 4.4637 - val_loss: 8.6351 - val_mean_absolute_error: 2.2238 - val_mean_squared_error: 8.6351\n",
      "Epoch 326/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 4.5225 - mean_absolute_error: 1.4057 - mean_squared_error: 4.5225 - val_loss: 8.5230 - val_mean_absolute_error: 2.2173 - val_mean_squared_error: 8.5230\n",
      "Epoch 327/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 4.7037 - mean_absolute_error: 1.4846 - mean_squared_error: 4.7037 - val_loss: 8.3799 - val_mean_absolute_error: 2.1909 - val_mean_squared_error: 8.3799\n",
      "Epoch 328/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.5169 - mean_absolute_error: 1.4208 - mean_squared_error: 4.5169 - val_loss: 8.5856 - val_mean_absolute_error: 2.2399 - val_mean_squared_error: 8.5856\n",
      "Epoch 329/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.3830 - mean_absolute_error: 1.4182 - mean_squared_error: 4.3830 - val_loss: 8.5513 - val_mean_absolute_error: 2.2001 - val_mean_squared_error: 8.5513\n",
      "Epoch 330/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.3887 - mean_absolute_error: 1.4184 - mean_squared_error: 4.3887 - val_loss: 8.5908 - val_mean_absolute_error: 2.2431 - val_mean_squared_error: 8.5908\n",
      "Epoch 331/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.5393 - mean_absolute_error: 1.4213 - mean_squared_error: 4.5393 - val_loss: 8.5901 - val_mean_absolute_error: 2.1952 - val_mean_squared_error: 8.5901\n",
      "Epoch 332/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.3330 - mean_absolute_error: 1.4078 - mean_squared_error: 4.3330 - val_loss: 8.6567 - val_mean_absolute_error: 2.2341 - val_mean_squared_error: 8.6567\n",
      "Epoch 333/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.3990 - mean_absolute_error: 1.4047 - mean_squared_error: 4.3990 - val_loss: 8.3781 - val_mean_absolute_error: 2.2059 - val_mean_squared_error: 8.3781\n",
      "Epoch 334/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.3406 - mean_absolute_error: 1.4099 - mean_squared_error: 4.3406 - val_loss: 8.6143 - val_mean_absolute_error: 2.2162 - val_mean_squared_error: 8.6143\n",
      "Epoch 335/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.3442 - mean_absolute_error: 1.3928 - mean_squared_error: 4.3442 - val_loss: 8.5766 - val_mean_absolute_error: 2.2203 - val_mean_squared_error: 8.5766\n",
      "Epoch 336/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.4047 - mean_absolute_error: 1.4147 - mean_squared_error: 4.4047 - val_loss: 8.4415 - val_mean_absolute_error: 2.1979 - val_mean_squared_error: 8.4415\n",
      "Epoch 337/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.3189 - mean_absolute_error: 1.3985 - mean_squared_error: 4.3189 - val_loss: 8.4492 - val_mean_absolute_error: 2.1958 - val_mean_squared_error: 8.4492\n",
      "Epoch 338/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.4236 - mean_absolute_error: 1.4087 - mean_squared_error: 4.4236 - val_loss: 8.6052 - val_mean_absolute_error: 2.2153 - val_mean_squared_error: 8.6052\n",
      "Epoch 339/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.3271 - mean_absolute_error: 1.4010 - mean_squared_error: 4.3271 - val_loss: 8.4410 - val_mean_absolute_error: 2.2006 - val_mean_squared_error: 8.4410\n",
      "Epoch 340/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.2965 - mean_absolute_error: 1.4099 - mean_squared_error: 4.2965 - val_loss: 8.6255 - val_mean_absolute_error: 2.2287 - val_mean_squared_error: 8.6255\n",
      "Epoch 341/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.3001 - mean_absolute_error: 1.3959 - mean_squared_error: 4.3001 - val_loss: 8.5081 - val_mean_absolute_error: 2.2071 - val_mean_squared_error: 8.5081\n",
      "Epoch 342/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.2923 - mean_absolute_error: 1.4036 - mean_squared_error: 4.2923 - val_loss: 8.6353 - val_mean_absolute_error: 2.2079 - val_mean_squared_error: 8.6353\n",
      "Epoch 343/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.3206 - mean_absolute_error: 1.4012 - mean_squared_error: 4.3206 - val_loss: 8.6588 - val_mean_absolute_error: 2.2193 - val_mean_squared_error: 8.6588\n",
      "Epoch 344/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.3657 - mean_absolute_error: 1.4194 - mean_squared_error: 4.3657 - val_loss: 8.4012 - val_mean_absolute_error: 2.2052 - val_mean_squared_error: 8.4012\n",
      "Epoch 345/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.3499 - mean_absolute_error: 1.3865 - mean_squared_error: 4.3499 - val_loss: 8.7279 - val_mean_absolute_error: 2.2527 - val_mean_squared_error: 8.7279\n",
      "Epoch 346/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.7918 - mean_absolute_error: 1.5440 - mean_squared_error: 4.7918 - val_loss: 8.6613 - val_mean_absolute_error: 2.2380 - val_mean_squared_error: 8.6613\n",
      "Epoch 347/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 4.6800 - mean_absolute_error: 1.4628 - mean_squared_error: 4.6800 - val_loss: 8.7315 - val_mean_absolute_error: 2.2731 - val_mean_squared_error: 8.7315\n",
      "Epoch 348/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.3509 - mean_absolute_error: 1.4339 - mean_squared_error: 4.3509 - val_loss: 8.6068 - val_mean_absolute_error: 2.2184 - val_mean_squared_error: 8.6068\n",
      "Epoch 349/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.5487 - mean_absolute_error: 1.4650 - mean_squared_error: 4.5487 - val_loss: 8.7130 - val_mean_absolute_error: 2.2563 - val_mean_squared_error: 8.7130\n",
      "Epoch 350/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.3827 - mean_absolute_error: 1.4214 - mean_squared_error: 4.3827 - val_loss: 8.4582 - val_mean_absolute_error: 2.1932 - val_mean_squared_error: 8.4582\n",
      "Epoch 351/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.3530 - mean_absolute_error: 1.4303 - mean_squared_error: 4.3530 - val_loss: 8.6941 - val_mean_absolute_error: 2.2267 - val_mean_squared_error: 8.6941\n",
      "Epoch 352/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.3465 - mean_absolute_error: 1.4018 - mean_squared_error: 4.3465 - val_loss: 8.5502 - val_mean_absolute_error: 2.2172 - val_mean_squared_error: 8.5502\n",
      "Epoch 353/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.3013 - mean_absolute_error: 1.4091 - mean_squared_error: 4.3013 - val_loss: 8.5959 - val_mean_absolute_error: 2.2118 - val_mean_squared_error: 8.5959\n",
      "Epoch 354/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.2570 - mean_absolute_error: 1.3788 - mean_squared_error: 4.2570 - val_loss: 8.5156 - val_mean_absolute_error: 2.2013 - val_mean_squared_error: 8.5156\n",
      "Epoch 355/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.2675 - mean_absolute_error: 1.3929 - mean_squared_error: 4.2675 - val_loss: 8.4056 - val_mean_absolute_error: 2.2013 - val_mean_squared_error: 8.4056\n",
      "Epoch 356/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.2474 - mean_absolute_error: 1.3728 - mean_squared_error: 4.2474 - val_loss: 8.6323 - val_mean_absolute_error: 2.2339 - val_mean_squared_error: 8.6323\n",
      "Epoch 357/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.2184 - mean_absolute_error: 1.3810 - mean_squared_error: 4.2184 - val_loss: 8.7007 - val_mean_absolute_error: 2.2184 - val_mean_squared_error: 8.7007\n",
      "Epoch 358/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.3508 - mean_absolute_error: 1.3674 - mean_squared_error: 4.3508 - val_loss: 8.6241 - val_mean_absolute_error: 2.2264 - val_mean_squared_error: 8.6241\n",
      "Epoch 359/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.1899 - mean_absolute_error: 1.3858 - mean_squared_error: 4.1899 - val_loss: 8.6207 - val_mean_absolute_error: 2.2151 - val_mean_squared_error: 8.6207\n",
      "Epoch 360/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.2316 - mean_absolute_error: 1.3975 - mean_squared_error: 4.2316 - val_loss: 8.7096 - val_mean_absolute_error: 2.2359 - val_mean_squared_error: 8.7096\n",
      "Epoch 361/400\n",
      "251/251 [==============================] - 0s 54us/sample - loss: 4.3517 - mean_absolute_error: 1.4145 - mean_squared_error: 4.3517 - val_loss: 8.5787 - val_mean_absolute_error: 2.2069 - val_mean_squared_error: 8.5787\n",
      "Epoch 362/400\n",
      "251/251 [==============================] - 0s 57us/sample - loss: 4.3876 - mean_absolute_error: 1.4069 - mean_squared_error: 4.3876 - val_loss: 8.6102 - val_mean_absolute_error: 2.2552 - val_mean_squared_error: 8.6102\n",
      "Epoch 363/400\n",
      "251/251 [==============================] - 0s 51us/sample - loss: 4.6245 - mean_absolute_error: 1.4883 - mean_squared_error: 4.6245 - val_loss: 8.5653 - val_mean_absolute_error: 2.2069 - val_mean_squared_error: 8.5653\n",
      "Epoch 364/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 4.3071 - mean_absolute_error: 1.3754 - mean_squared_error: 4.3071 - val_loss: 8.6739 - val_mean_absolute_error: 2.2547 - val_mean_squared_error: 8.6739\n",
      "Epoch 365/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.6675 - mean_absolute_error: 1.4541 - mean_squared_error: 4.6675 - val_loss: 8.6371 - val_mean_absolute_error: 2.2091 - val_mean_squared_error: 8.6371\n",
      "Epoch 366/400\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 4.4585 - mean_absolute_error: 1.4029 - mean_squared_error: 4.4585 - val_loss: 8.7691 - val_mean_absolute_error: 2.2646 - val_mean_squared_error: 8.7691\n",
      "Epoch 367/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.2609 - mean_absolute_error: 1.3979 - mean_squared_error: 4.2609 - val_loss: 8.6697 - val_mean_absolute_error: 2.2209 - val_mean_squared_error: 8.6697\n",
      "Epoch 368/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.2546 - mean_absolute_error: 1.3890 - mean_squared_error: 4.2546 - val_loss: 8.7474 - val_mean_absolute_error: 2.2593 - val_mean_squared_error: 8.7474\n",
      "Epoch 369/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.3895 - mean_absolute_error: 1.4086 - mean_squared_error: 4.3895 - val_loss: 8.6449 - val_mean_absolute_error: 2.2202 - val_mean_squared_error: 8.6449\n",
      "Epoch 370/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.1108 - mean_absolute_error: 1.3680 - mean_squared_error: 4.1108 - val_loss: 8.8939 - val_mean_absolute_error: 2.2545 - val_mean_squared_error: 8.8939\n",
      "Epoch 371/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.2841 - mean_absolute_error: 1.3797 - mean_squared_error: 4.2841 - val_loss: 8.7189 - val_mean_absolute_error: 2.2549 - val_mean_squared_error: 8.7189\n",
      "Epoch 372/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.2640 - mean_absolute_error: 1.4089 - mean_squared_error: 4.2640 - val_loss: 8.5795 - val_mean_absolute_error: 2.2164 - val_mean_squared_error: 8.5795\n",
      "Epoch 373/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.1127 - mean_absolute_error: 1.3696 - mean_squared_error: 4.1127 - val_loss: 8.7735 - val_mean_absolute_error: 2.2427 - val_mean_squared_error: 8.7735\n",
      "Epoch 374/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.1245 - mean_absolute_error: 1.3496 - mean_squared_error: 4.1245 - val_loss: 8.7119 - val_mean_absolute_error: 2.2338 - val_mean_squared_error: 8.7119\n",
      "Epoch 375/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.1296 - mean_absolute_error: 1.3731 - mean_squared_error: 4.1296 - val_loss: 8.6608 - val_mean_absolute_error: 2.2384 - val_mean_squared_error: 8.6608\n",
      "Epoch 376/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.3784 - mean_absolute_error: 1.3716 - mean_squared_error: 4.3784 - val_loss: 8.7506 - val_mean_absolute_error: 2.2433 - val_mean_squared_error: 8.7506\n",
      "Epoch 377/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.3053 - mean_absolute_error: 1.4113 - mean_squared_error: 4.3053 - val_loss: 8.7954 - val_mean_absolute_error: 2.2230 - val_mean_squared_error: 8.7954\n",
      "Epoch 378/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.2652 - mean_absolute_error: 1.4168 - mean_squared_error: 4.2652 - val_loss: 8.8893 - val_mean_absolute_error: 2.2719 - val_mean_squared_error: 8.8893\n",
      "Epoch 379/400\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 4.3181 - mean_absolute_error: 1.3868 - mean_squared_error: 4.3181 - val_loss: 8.7399 - val_mean_absolute_error: 2.2490 - val_mean_squared_error: 8.7399\n",
      "Epoch 380/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.1273 - mean_absolute_error: 1.3546 - mean_squared_error: 4.1273 - val_loss: 8.6345 - val_mean_absolute_error: 2.2511 - val_mean_squared_error: 8.6345\n",
      "Epoch 381/400\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 4.0935 - mean_absolute_error: 1.3469 - mean_squared_error: 4.0935 - val_loss: 8.5571 - val_mean_absolute_error: 2.2192 - val_mean_squared_error: 8.5571\n",
      "Epoch 382/400\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 4.1401 - mean_absolute_error: 1.3623 - mean_squared_error: 4.1401 - val_loss: 8.8098 - val_mean_absolute_error: 2.2387 - val_mean_squared_error: 8.8098\n",
      "Epoch 383/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.1327 - mean_absolute_error: 1.3737 - mean_squared_error: 4.1327 - val_loss: 8.6478 - val_mean_absolute_error: 2.2305 - val_mean_squared_error: 8.6478\n",
      "Epoch 384/400\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 4.0686 - mean_absolute_error: 1.3467 - mean_squared_error: 4.0686 - val_loss: 8.6178 - val_mean_absolute_error: 2.2110 - val_mean_squared_error: 8.6178\n",
      "Epoch 385/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.1777 - mean_absolute_error: 1.3908 - mean_squared_error: 4.1777 - val_loss: 8.7061 - val_mean_absolute_error: 2.2347 - val_mean_squared_error: 8.7061\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 41us/sample - loss: 4.5930 - mean_absolute_error: 1.4216 - mean_squared_error: 4.5930 - val_loss: 8.7677 - val_mean_absolute_error: 2.2570 - val_mean_squared_error: 8.7677\n",
      "Epoch 387/400\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 4.4034 - mean_absolute_error: 1.4540 - mean_squared_error: 4.4034 - val_loss: 8.7852 - val_mean_absolute_error: 2.2270 - val_mean_squared_error: 8.7852\n",
      "Epoch 388/400\n",
      "251/251 [==============================] - 0s 50us/sample - loss: 3.9593 - mean_absolute_error: 1.3443 - mean_squared_error: 3.9593 - val_loss: 8.8127 - val_mean_absolute_error: 2.2605 - val_mean_squared_error: 8.8127\n",
      "Epoch 389/400\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 4.1527 - mean_absolute_error: 1.3349 - mean_squared_error: 4.1527 - val_loss: 8.6685 - val_mean_absolute_error: 2.2228 - val_mean_squared_error: 8.6685\n",
      "Epoch 390/400\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 4.0860 - mean_absolute_error: 1.3739 - mean_squared_error: 4.0860 - val_loss: 8.7272 - val_mean_absolute_error: 2.2394 - val_mean_squared_error: 8.7272\n",
      "Epoch 391/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.0961 - mean_absolute_error: 1.3658 - mean_squared_error: 4.0961 - val_loss: 8.9673 - val_mean_absolute_error: 2.2517 - val_mean_squared_error: 8.9673\n",
      "Epoch 392/400\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 4.0403 - mean_absolute_error: 1.3620 - mean_squared_error: 4.0403 - val_loss: 8.7906 - val_mean_absolute_error: 2.2478 - val_mean_squared_error: 8.7906\n",
      "Epoch 393/400\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 4.0566 - mean_absolute_error: 1.3515 - mean_squared_error: 4.0566 - val_loss: 8.6528 - val_mean_absolute_error: 2.2221 - val_mean_squared_error: 8.6528\n",
      "Epoch 394/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.0862 - mean_absolute_error: 1.3458 - mean_squared_error: 4.0862 - val_loss: 8.9529 - val_mean_absolute_error: 2.2410 - val_mean_squared_error: 8.9529\n",
      "Epoch 395/400\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 4.0034 - mean_absolute_error: 1.3449 - mean_squared_error: 4.0034 - val_loss: 8.5833 - val_mean_absolute_error: 2.2074 - val_mean_squared_error: 8.5833\n",
      "Epoch 396/400\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 4.0430 - mean_absolute_error: 1.3318 - mean_squared_error: 4.0430 - val_loss: 8.7308 - val_mean_absolute_error: 2.2457 - val_mean_squared_error: 8.7308\n",
      "Epoch 397/400\n",
      "251/251 [==============================] - 0s 49us/sample - loss: 4.0864 - mean_absolute_error: 1.3571 - mean_squared_error: 4.0864 - val_loss: 8.9764 - val_mean_absolute_error: 2.2568 - val_mean_squared_error: 8.9764\n",
      "Epoch 398/400\n",
      "251/251 [==============================] - 0s 52us/sample - loss: 4.1128 - mean_absolute_error: 1.3755 - mean_squared_error: 4.1128 - val_loss: 8.6995 - val_mean_absolute_error: 2.2459 - val_mean_squared_error: 8.6995\n",
      "Epoch 399/400\n",
      "251/251 [==============================] - 0s 52us/sample - loss: 4.0347 - mean_absolute_error: 1.3467 - mean_squared_error: 4.0347 - val_loss: 8.8760 - val_mean_absolute_error: 2.2458 - val_mean_squared_error: 8.8760\n",
      "Epoch 400/400\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 4.0467 - mean_absolute_error: 1.3491 - mean_squared_error: 4.0467 - val_loss: 8.6159 - val_mean_absolute_error: 2.2289 - val_mean_squared_error: 8.6159\n"
     ]
    }
   ],
   "source": [
    "history=model2.fit(\n",
    "  normed_train_data, train_labels,\n",
    "  epochs=400, validation_split = 0.2, verbose=1, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 31971), started 0:02:23 ago. (Use '!kill 31971' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6009\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a43ae7ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir my_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "model2.save('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ELU=tf.keras.layers.ELU(alpha=1.0)\n",
    "inputs = tf.keras.Input(shape=len(train_dataset.keys()))\n",
    "d0=layers.Dropout(0.1)(inputs,training=True)\n",
    "c1= layers.Dense(64)(d0)\n",
    "d1=layers.Dropout(0.5)(c1,training=True)\n",
    "a1=tf.keras.layers.ELU(alpha=1.0)(d1)\n",
    "c2=layers.Dense(2)(a1)\n",
    "#d2=layers.Dropout(0.00)(c2,training=True)\n",
    "#a2=tf.keras.layers.ELU(alpha=1.0)(d2)\n",
    "c3=layers.Dense(1)(c2)\n",
    "#outputs=layers.Activation('softmax')(c2)\n",
    "model_dropout = tf.keras.Model(inputs, c3)\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(\n",
    "    loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251 samples, validate on 63 samples\n",
      "Epoch 1/500\n",
      "251/251 [==============================] - 0s 854us/sample - loss: 603.0176 - accuracy: 0.0000e+00 - val_loss: 616.3539 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "251/251 [==============================] - 0s 58us/sample - loss: 588.9214 - accuracy: 0.0000e+00 - val_loss: 595.7719 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "251/251 [==============================] - 0s 57us/sample - loss: 565.2058 - accuracy: 0.0000e+00 - val_loss: 579.6893 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "251/251 [==============================] - 0s 71us/sample - loss: 551.9305 - accuracy: 0.0000e+00 - val_loss: 554.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "251/251 [==============================] - 0s 74us/sample - loss: 533.5253 - accuracy: 0.0000e+00 - val_loss: 550.3639 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "251/251 [==============================] - 0s 53us/sample - loss: 528.7013 - accuracy: 0.0000e+00 - val_loss: 517.5444 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 510.7511 - accuracy: 0.0000e+00 - val_loss: 512.3077 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "251/251 [==============================] - 0s 47us/sample - loss: 489.4799 - accuracy: 0.0000e+00 - val_loss: 490.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "251/251 [==============================] - 0s 48us/sample - loss: 463.0163 - accuracy: 0.0000e+00 - val_loss: 455.2849 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 439.3760 - accuracy: 0.0000e+00 - val_loss: 433.0796 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 431.3899 - accuracy: 0.0000e+00 - val_loss: 432.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 411.6241 - accuracy: 0.0000e+00 - val_loss: 399.0813 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 387.3356 - accuracy: 0.0000e+00 - val_loss: 387.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 356.3257 - accuracy: 0.0000e+00 - val_loss: 339.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 332.0263 - accuracy: 0.0000e+00 - val_loss: 340.1537 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 291.8322 - accuracy: 0.0000e+00 - val_loss: 287.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 281.2580 - accuracy: 0.0000e+00 - val_loss: 261.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 256.9303 - accuracy: 0.0000e+00 - val_loss: 245.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 236.0916 - accuracy: 0.0000e+00 - val_loss: 193.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 214.0076 - accuracy: 0.0000e+00 - val_loss: 179.6239 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "251/251 [==============================] - 0s 44us/sample - loss: 197.6741 - accuracy: 0.0000e+00 - val_loss: 180.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 188.8456 - accuracy: 0.0000e+00 - val_loss: 149.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 151.6509 - accuracy: 0.0000e+00 - val_loss: 138.2361 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 138.3064 - accuracy: 0.0000e+00 - val_loss: 134.0669 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 123.5387 - accuracy: 0.0000e+00 - val_loss: 93.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 105.0606 - accuracy: 0.0000e+00 - val_loss: 85.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 102.2553 - accuracy: 0.0000e+00 - val_loss: 100.1850 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 89.0833 - accuracy: 0.0000e+00 - val_loss: 83.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 89.7164 - accuracy: 0.0000e+00 - val_loss: 93.6667 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 73.4131 - accuracy: 0.0000e+00 - val_loss: 78.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 75.3013 - accuracy: 0.0000e+00 - val_loss: 92.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 69.5112 - accuracy: 0.0000e+00 - val_loss: 63.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 71.4807 - accuracy: 0.0000e+00 - val_loss: 72.2318 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 69.3494 - accuracy: 0.0000e+00 - val_loss: 81.4906 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 62.2961 - accuracy: 0.0000e+00 - val_loss: 57.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 68.3478 - accuracy: 0.0000e+00 - val_loss: 66.2496 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 58.9961 - accuracy: 0.0000e+00 - val_loss: 54.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 72.7099 - accuracy: 0.0000e+00 - val_loss: 53.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 60.2113 - accuracy: 0.0000e+00 - val_loss: 54.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 55.8820 - accuracy: 0.0000e+00 - val_loss: 69.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 43.2370 - accuracy: 0.0000e+00 - val_loss: 70.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 61.1017 - accuracy: 0.0000e+00 - val_loss: 65.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 53.1093 - accuracy: 0.0000e+00 - val_loss: 48.0542 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 48.6804 - accuracy: 0.0000e+00 - val_loss: 76.7808 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 46.7051 - accuracy: 0.0000e+00 - val_loss: 58.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 54.1612 - accuracy: 0.0000e+00 - val_loss: 53.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 55.2356 - accuracy: 0.0000e+00 - val_loss: 54.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 52.6360 - accuracy: 0.0000e+00 - val_loss: 42.6619 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 45.9378 - accuracy: 0.0000e+00 - val_loss: 51.0387 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 54.1663 - accuracy: 0.0000e+00 - val_loss: 66.1850 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 47.0781 - accuracy: 0.0000e+00 - val_loss: 48.1606 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 46.5394 - accuracy: 0.0000e+00 - val_loss: 51.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "251/251 [==============================] - 0s 46us/sample - loss: 40.2184 - accuracy: 0.0000e+00 - val_loss: 47.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 45.7435 - accuracy: 0.0000e+00 - val_loss: 51.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 38.4259 - accuracy: 0.0000e+00 - val_loss: 47.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 46.4841 - accuracy: 0.0000e+00 - val_loss: 51.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 46.5824 - accuracy: 0.0000e+00 - val_loss: 39.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 46.7978 - accuracy: 0.0000e+00 - val_loss: 45.6720 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 42.4630 - accuracy: 0.0000e+00 - val_loss: 43.5695 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 40.4793 - accuracy: 0.0000e+00 - val_loss: 49.6945 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 35.2305 - accuracy: 0.0000e+00 - val_loss: 37.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 46.1041 - accuracy: 0.0000e+00 - val_loss: 29.7263 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 39.8884 - accuracy: 0.0000e+00 - val_loss: 51.4617 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "251/251 [==============================] - 0s 31us/sample - loss: 38.4777 - accuracy: 0.0000e+00 - val_loss: 42.7015 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 41.3686 - accuracy: 0.0000e+00 - val_loss: 55.0207 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 37.5705 - accuracy: 0.0000e+00 - val_loss: 46.1593 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 34.5459 - accuracy: 0.0000e+00 - val_loss: 52.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 36.1724 - accuracy: 0.0000e+00 - val_loss: 48.8839 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 38.6437 - accuracy: 0.0000e+00 - val_loss: 24.9031 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 34.4479 - accuracy: 0.0000e+00 - val_loss: 33.2870 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 40.4897 - accuracy: 0.0000e+00 - val_loss: 41.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 46.1410 - accuracy: 0.0000e+00 - val_loss: 35.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 39.3181 - accuracy: 0.0000e+00 - val_loss: 45.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 40.2704 - accuracy: 0.0000e+00 - val_loss: 53.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 35.5637 - accuracy: 0.0000e+00 - val_loss: 45.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 36.8065 - accuracy: 0.0000e+00 - val_loss: 27.2440 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 40.4950 - accuracy: 0.0000e+00 - val_loss: 36.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 33.7058 - accuracy: 0.0000e+00 - val_loss: 57.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 33.5859 - accuracy: 0.0000e+00 - val_loss: 43.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 32.4729 - accuracy: 0.0000e+00 - val_loss: 37.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 37.2784 - accuracy: 0.0000e+00 - val_loss: 33.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 32.9783 - accuracy: 0.0000e+00 - val_loss: 36.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 32.3357 - accuracy: 0.0000e+00 - val_loss: 37.7575 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 37.9461 - accuracy: 0.0000e+00 - val_loss: 29.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 31.4000 - accuracy: 0.0000e+00 - val_loss: 41.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 32.8380 - accuracy: 0.0000e+00 - val_loss: 28.2867 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 36.7705 - accuracy: 0.0000e+00 - val_loss: 35.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 34.9445 - accuracy: 0.0000e+00 - val_loss: 30.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 31.2650 - accuracy: 0.0000e+00 - val_loss: 38.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 34.0151 - accuracy: 0.0000e+00 - val_loss: 31.9593 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 31.7308 - accuracy: 0.0000e+00 - val_loss: 48.1445 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 33.3332 - accuracy: 0.0000e+00 - val_loss: 40.7314 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 36.3761 - accuracy: 0.0000e+00 - val_loss: 52.2525 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 28.4354 - accuracy: 0.0000e+00 - val_loss: 29.8348 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 26.3201 - accuracy: 0.0000e+00 - val_loss: 40.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 33.3661 - accuracy: 0.0000e+00 - val_loss: 37.9835 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 31.9822 - accuracy: 0.0000e+00 - val_loss: 32.6577 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 34.6965 - accuracy: 0.0000e+00 - val_loss: 34.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 34.8692 - accuracy: 0.0000e+00 - val_loss: 37.8420 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.8074 - accuracy: 0.0000e+00 - val_loss: 34.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 29.6224 - accuracy: 0.0000e+00 - val_loss: 28.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 32.3189 - accuracy: 0.0000e+00 - val_loss: 38.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 32.7704 - accuracy: 0.0000e+00 - val_loss: 36.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 36us/sample - loss: 26.9422 - accuracy: 0.0000e+00 - val_loss: 29.7432 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 30.2547 - accuracy: 0.0000e+00 - val_loss: 31.4638 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 28.5923 - accuracy: 0.0000e+00 - val_loss: 29.6004 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 28.1567 - accuracy: 0.0000e+00 - val_loss: 37.6082 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.1542 - accuracy: 0.0000e+00 - val_loss: 30.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 22.6076 - accuracy: 0.0000e+00 - val_loss: 23.3600 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 27.8814 - accuracy: 0.0000e+00 - val_loss: 26.8627 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.8981 - accuracy: 0.0000e+00 - val_loss: 44.9836 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 32.2769 - accuracy: 0.0000e+00 - val_loss: 27.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 29.6932 - accuracy: 0.0000e+00 - val_loss: 40.6565 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 29.4239 - accuracy: 0.0000e+00 - val_loss: 20.6575 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 24.2199 - accuracy: 0.0000e+00 - val_loss: 30.9530 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 30.6584 - accuracy: 0.0000e+00 - val_loss: 30.5728 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 28.3837 - accuracy: 0.0000e+00 - val_loss: 19.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 27.5441 - accuracy: 0.0000e+00 - val_loss: 30.8128 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 30.0148 - accuracy: 0.0000e+00 - val_loss: 25.8394 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 25.8054 - accuracy: 0.0000e+00 - val_loss: 23.7752 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.7657 - accuracy: 0.0000e+00 - val_loss: 37.7211 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.3188 - accuracy: 0.0000e+00 - val_loss: 33.5735 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 33.3726 - accuracy: 0.0000e+00 - val_loss: 29.3059 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 29.2936 - accuracy: 0.0000e+00 - val_loss: 46.7419 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 27.1299 - accuracy: 0.0000e+00 - val_loss: 20.9578 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.7754 - accuracy: 0.0000e+00 - val_loss: 25.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 25.9754 - accuracy: 0.0000e+00 - val_loss: 35.2762 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 27.0655 - accuracy: 0.0000e+00 - val_loss: 35.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 27.6606 - accuracy: 0.0000e+00 - val_loss: 23.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 36.1558 - accuracy: 0.0000e+00 - val_loss: 26.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.1852 - accuracy: 0.0000e+00 - val_loss: 30.5363 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 31.5019 - accuracy: 0.0000e+00 - val_loss: 31.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 27.9033 - accuracy: 0.0000e+00 - val_loss: 26.2095 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.7382 - accuracy: 0.0000e+00 - val_loss: 21.2079 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 24.4210 - accuracy: 0.0000e+00 - val_loss: 23.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 26.9061 - accuracy: 0.0000e+00 - val_loss: 34.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 26.9989 - accuracy: 0.0000e+00 - val_loss: 18.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 26.4935 - accuracy: 0.0000e+00 - val_loss: 25.9390 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 28.2573 - accuracy: 0.0000e+00 - val_loss: 27.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.9592 - accuracy: 0.0000e+00 - val_loss: 33.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 25.7174 - accuracy: 0.0000e+00 - val_loss: 34.4923 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.8307 - accuracy: 0.0000e+00 - val_loss: 26.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 29.5775 - accuracy: 0.0000e+00 - val_loss: 30.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 26.7355 - accuracy: 0.0000e+00 - val_loss: 19.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 23.5721 - accuracy: 0.0000e+00 - val_loss: 28.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.8527 - accuracy: 0.0000e+00 - val_loss: 22.1392 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 26.8815 - accuracy: 0.0000e+00 - val_loss: 33.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 25.3445 - accuracy: 0.0000e+00 - val_loss: 39.4789 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 23.8791 - accuracy: 0.0000e+00 - val_loss: 20.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 25.2340 - accuracy: 0.0000e+00 - val_loss: 28.1634 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 27.4735 - accuracy: 0.0000e+00 - val_loss: 27.5927 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 27.8233 - accuracy: 0.0000e+00 - val_loss: 26.4435 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 25.3646 - accuracy: 0.0000e+00 - val_loss: 32.1203 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 26.8134 - accuracy: 0.0000e+00 - val_loss: 24.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 31.2612 - accuracy: 0.0000e+00 - val_loss: 22.0743 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 28.7780 - accuracy: 0.0000e+00 - val_loss: 23.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 22.0748 - accuracy: 0.0000e+00 - val_loss: 30.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 23.7459 - accuracy: 0.0000e+00 - val_loss: 23.3402 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 27.0034 - accuracy: 0.0000e+00 - val_loss: 30.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 24.6388 - accuracy: 0.0000e+00 - val_loss: 23.3439 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 23.5183 - accuracy: 0.0000e+00 - val_loss: 27.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 25.2149 - accuracy: 0.0000e+00 - val_loss: 23.3985 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.5267 - accuracy: 0.0000e+00 - val_loss: 21.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 24.0590 - accuracy: 0.0000e+00 - val_loss: 26.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 22.5791 - accuracy: 0.0000e+00 - val_loss: 26.2896 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 26.3492 - accuracy: 0.0000e+00 - val_loss: 32.4853 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 22.9979 - accuracy: 0.0000e+00 - val_loss: 29.2418 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 25.0540 - accuracy: 0.0000e+00 - val_loss: 35.5013 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 26.6335 - accuracy: 0.0000e+00 - val_loss: 14.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.5075 - accuracy: 0.0000e+00 - val_loss: 27.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 23.4156 - accuracy: 0.0000e+00 - val_loss: 27.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 22.4843 - accuracy: 0.0000e+00 - val_loss: 18.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "251/251 [==============================] - 0s 31us/sample - loss: 28.9091 - accuracy: 0.0000e+00 - val_loss: 21.6096 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 24.6073 - accuracy: 0.0000e+00 - val_loss: 19.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 24.6479 - accuracy: 0.0000e+00 - val_loss: 19.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 26.7936 - accuracy: 0.0000e+00 - val_loss: 24.3831 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 21.5113 - accuracy: 0.0000e+00 - val_loss: 26.5108 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 22.9024 - accuracy: 0.0000e+00 - val_loss: 26.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.7351 - accuracy: 0.0000e+00 - val_loss: 21.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 27.0211 - accuracy: 0.0000e+00 - val_loss: 28.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 18.9242 - accuracy: 0.0000e+00 - val_loss: 23.2772 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 24.3121 - accuracy: 0.0000e+00 - val_loss: 23.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 24.1476 - accuracy: 0.0000e+00 - val_loss: 33.2809 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 24.4598 - accuracy: 0.0000e+00 - val_loss: 25.2993 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 24.4448 - accuracy: 0.0000e+00 - val_loss: 21.6643 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.6010 - accuracy: 0.0000e+00 - val_loss: 22.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.0746 - accuracy: 0.0000e+00 - val_loss: 25.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 25.5458 - accuracy: 0.0000e+00 - val_loss: 29.3676 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 24.3891 - accuracy: 0.0000e+00 - val_loss: 21.3330 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 23.0447 - accuracy: 0.0000e+00 - val_loss: 28.3213 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 18.9364 - accuracy: 0.0000e+00 - val_loss: 24.5857 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 21.6275 - accuracy: 0.0000e+00 - val_loss: 23.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.5875 - accuracy: 0.0000e+00 - val_loss: 21.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 27.8959 - accuracy: 0.0000e+00 - val_loss: 30.9897 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.0216 - accuracy: 0.0000e+00 - val_loss: 25.4362 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 26.9939 - accuracy: 0.0000e+00 - val_loss: 17.9347 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.8191 - accuracy: 0.0000e+00 - val_loss: 18.5691 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 24.3130 - accuracy: 0.0000e+00 - val_loss: 26.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 25.2756 - accuracy: 0.0000e+00 - val_loss: 17.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 21.5452 - accuracy: 0.0000e+00 - val_loss: 16.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 25.4707 - accuracy: 0.0000e+00 - val_loss: 18.0542 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 22.4068 - accuracy: 0.0000e+00 - val_loss: 28.3503 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 23.9101 - accuracy: 0.0000e+00 - val_loss: 15.7069 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 20.6444 - accuracy: 0.0000e+00 - val_loss: 20.3768 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.2244 - accuracy: 0.0000e+00 - val_loss: 17.5477 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.2891 - accuracy: 0.0000e+00 - val_loss: 25.1656 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 23.1198 - accuracy: 0.0000e+00 - val_loss: 22.2309 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.0888 - accuracy: 0.0000e+00 - val_loss: 21.7518 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 23.3195 - accuracy: 0.0000e+00 - val_loss: 27.1977 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.2892 - accuracy: 0.0000e+00 - val_loss: 24.6704 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 23.4944 - accuracy: 0.0000e+00 - val_loss: 24.3305 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 23.1655 - accuracy: 0.0000e+00 - val_loss: 31.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.5055 - accuracy: 0.0000e+00 - val_loss: 31.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 26.7063 - accuracy: 0.0000e+00 - val_loss: 21.8380 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 24.9301 - accuracy: 0.0000e+00 - val_loss: 27.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.8564 - accuracy: 0.0000e+00 - val_loss: 31.5978 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 25.1127 - accuracy: 0.0000e+00 - val_loss: 26.2730 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.6222 - accuracy: 0.0000e+00 - val_loss: 22.3994 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 24.0372 - accuracy: 0.0000e+00 - val_loss: 28.3189 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.6404 - accuracy: 0.0000e+00 - val_loss: 22.9963 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.9724 - accuracy: 0.0000e+00 - val_loss: 23.0907 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 17.4758 - accuracy: 0.0000e+00 - val_loss: 23.8757 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.0533 - accuracy: 0.0000e+00 - val_loss: 14.9718 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 26.6476 - accuracy: 0.0000e+00 - val_loss: 26.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.6667 - accuracy: 0.0000e+00 - val_loss: 20.2533 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.0328 - accuracy: 0.0000e+00 - val_loss: 21.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 22.4483 - accuracy: 0.0000e+00 - val_loss: 21.1638 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 24.4142 - accuracy: 0.0000e+00 - val_loss: 26.6794 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 24.0866 - accuracy: 0.0000e+00 - val_loss: 22.5862 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 23.9198 - accuracy: 0.0000e+00 - val_loss: 21.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 22.5489 - accuracy: 0.0000e+00 - val_loss: 17.7449 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 21.5323 - accuracy: 0.0000e+00 - val_loss: 20.9123 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 24.7733 - accuracy: 0.0000e+00 - val_loss: 23.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.6993 - accuracy: 0.0000e+00 - val_loss: 20.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 22.3344 - accuracy: 0.0000e+00 - val_loss: 16.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 21.5042 - accuracy: 0.0000e+00 - val_loss: 28.5116 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 23.9891 - accuracy: 0.0000e+00 - val_loss: 23.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.7427 - accuracy: 0.0000e+00 - val_loss: 22.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 22.1916 - accuracy: 0.0000e+00 - val_loss: 33.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 24.3060 - accuracy: 0.0000e+00 - val_loss: 17.3227 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.8841 - accuracy: 0.0000e+00 - val_loss: 24.7999 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.4755 - accuracy: 0.0000e+00 - val_loss: 23.1288 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 23.5862 - accuracy: 0.0000e+00 - val_loss: 28.5717 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 22.6362 - accuracy: 0.0000e+00 - val_loss: 23.9004 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 22.3575 - accuracy: 0.0000e+00 - val_loss: 18.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.7868 - accuracy: 0.0000e+00 - val_loss: 22.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.0229 - accuracy: 0.0000e+00 - val_loss: 26.1732 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.2563 - accuracy: 0.0000e+00 - val_loss: 23.7693 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 18.1390 - accuracy: 0.0000e+00 - val_loss: 20.6804 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.4329 - accuracy: 0.0000e+00 - val_loss: 14.4815 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.9952 - accuracy: 0.0000e+00 - val_loss: 27.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 18.1999 - accuracy: 0.0000e+00 - val_loss: 18.2501 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.1599 - accuracy: 0.0000e+00 - val_loss: 26.3129 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 22.4170 - accuracy: 0.0000e+00 - val_loss: 21.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 19.0511 - accuracy: 0.0000e+00 - val_loss: 21.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 23.8257 - accuracy: 0.0000e+00 - val_loss: 32.1563 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.2085 - accuracy: 0.0000e+00 - val_loss: 15.9924 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.9618 - accuracy: 0.0000e+00 - val_loss: 20.3614 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 22.6819 - accuracy: 0.0000e+00 - val_loss: 21.6775 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.4527 - accuracy: 0.0000e+00 - val_loss: 20.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.5025 - accuracy: 0.0000e+00 - val_loss: 22.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 22.6147 - accuracy: 0.0000e+00 - val_loss: 19.8620 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 16.7639 - accuracy: 0.0000e+00 - val_loss: 17.2647 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.5973 - accuracy: 0.0000e+00 - val_loss: 17.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.6432 - accuracy: 0.0000e+00 - val_loss: 23.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 18.9599 - accuracy: 0.0000e+00 - val_loss: 25.4109 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 22.0434 - accuracy: 0.0000e+00 - val_loss: 21.7131 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 20.5949 - accuracy: 0.0000e+00 - val_loss: 24.4001 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.9946 - accuracy: 0.0000e+00 - val_loss: 27.7635 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 20.3192 - accuracy: 0.0000e+00 - val_loss: 22.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.9187 - accuracy: 0.0000e+00 - val_loss: 17.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.4760 - accuracy: 0.0000e+00 - val_loss: 18.3201 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 23.4461 - accuracy: 0.0000e+00 - val_loss: 20.8337 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.7341 - accuracy: 0.0000e+00 - val_loss: 23.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 21.6324 - accuracy: 0.0000e+00 - val_loss: 28.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.4329 - accuracy: 0.0000e+00 - val_loss: 25.2483 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 25.0292 - accuracy: 0.0000e+00 - val_loss: 23.8306 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 24.0860 - accuracy: 0.0000e+00 - val_loss: 16.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 18.8659 - accuracy: 0.0000e+00 - val_loss: 23.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.9372 - accuracy: 0.0000e+00 - val_loss: 19.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.4293 - accuracy: 0.0000e+00 - val_loss: 21.7419 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.8693 - accuracy: 0.0000e+00 - val_loss: 25.1264 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.7881 - accuracy: 0.0000e+00 - val_loss: 14.3338 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.5353 - accuracy: 0.0000e+00 - val_loss: 24.3099 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 19.7515 - accuracy: 0.0000e+00 - val_loss: 20.3305 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 24.7805 - accuracy: 0.0000e+00 - val_loss: 19.3679 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 22.3807 - accuracy: 0.0000e+00 - val_loss: 21.8026 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 23.0915 - accuracy: 0.0000e+00 - val_loss: 16.0540 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 24.7232 - accuracy: 0.0000e+00 - val_loss: 27.4001 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 23.1028 - accuracy: 0.0000e+00 - val_loss: 19.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 21.9292 - accuracy: 0.0000e+00 - val_loss: 26.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 18.4994 - accuracy: 0.0000e+00 - val_loss: 17.6026 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 18.7496 - accuracy: 0.0000e+00 - val_loss: 28.4117 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 23.1301 - accuracy: 0.0000e+00 - val_loss: 19.6753 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 19.0560 - accuracy: 0.0000e+00 - val_loss: 22.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.8359 - accuracy: 0.0000e+00 - val_loss: 21.7157 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 17.0548 - accuracy: 0.0000e+00 - val_loss: 22.5819 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.1881 - accuracy: 0.0000e+00 - val_loss: 16.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.7679 - accuracy: 0.0000e+00 - val_loss: 16.2876 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 19.7251 - accuracy: 0.0000e+00 - val_loss: 31.1802 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.9019 - accuracy: 0.0000e+00 - val_loss: 24.5127 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.6745 - accuracy: 0.0000e+00 - val_loss: 22.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.8899 - accuracy: 0.0000e+00 - val_loss: 19.2808 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 16.9592 - accuracy: 0.0000e+00 - val_loss: 26.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.5853 - accuracy: 0.0000e+00 - val_loss: 23.1654 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.7524 - accuracy: 0.0000e+00 - val_loss: 16.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.8713 - accuracy: 0.0000e+00 - val_loss: 31.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.4297 - accuracy: 0.0000e+00 - val_loss: 28.1443 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.8739 - accuracy: 0.0000e+00 - val_loss: 17.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.0090 - accuracy: 0.0000e+00 - val_loss: 22.3292 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.3410 - accuracy: 0.0000e+00 - val_loss: 20.6471 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.8193 - accuracy: 0.0000e+00 - val_loss: 29.6803 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 18.6268 - accuracy: 0.0000e+00 - val_loss: 17.5348 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 19.1967 - accuracy: 0.0000e+00 - val_loss: 18.9268 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 26.8336 - accuracy: 0.0000e+00 - val_loss: 21.3053 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 22.6408 - accuracy: 0.0000e+00 - val_loss: 20.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.7104 - accuracy: 0.0000e+00 - val_loss: 20.9381 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 21.8285 - accuracy: 0.0000e+00 - val_loss: 21.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.3795 - accuracy: 0.0000e+00 - val_loss: 17.6352 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.9680 - accuracy: 0.0000e+00 - val_loss: 28.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 22.7847 - accuracy: 0.0000e+00 - val_loss: 35.9634 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 21.9388 - accuracy: 0.0000e+00 - val_loss: 22.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.6060 - accuracy: 0.0000e+00 - val_loss: 29.4342 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 22.9274 - accuracy: 0.0000e+00 - val_loss: 14.2690 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 23.0246 - accuracy: 0.0000e+00 - val_loss: 21.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 19.8202 - accuracy: 0.0000e+00 - val_loss: 17.4000 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 23.5559 - accuracy: 0.0000e+00 - val_loss: 32.7929 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.7088 - accuracy: 0.0000e+00 - val_loss: 21.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 18.5093 - accuracy: 0.0000e+00 - val_loss: 26.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 22.6613 - accuracy: 0.0000e+00 - val_loss: 21.1785 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.6783 - accuracy: 0.0000e+00 - val_loss: 20.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 23.9747 - accuracy: 0.0000e+00 - val_loss: 16.9397 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 26.0480 - accuracy: 0.0000e+00 - val_loss: 21.4362 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 22.5119 - accuracy: 0.0000e+00 - val_loss: 26.0005 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.9578 - accuracy: 0.0000e+00 - val_loss: 16.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.0277 - accuracy: 0.0000e+00 - val_loss: 17.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 18.1071 - accuracy: 0.0000e+00 - val_loss: 23.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 20.0261 - accuracy: 0.0000e+00 - val_loss: 15.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 17.5035 - accuracy: 0.0000e+00 - val_loss: 18.6948 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.2828 - accuracy: 0.0000e+00 - val_loss: 20.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 17.7193 - accuracy: 0.0000e+00 - val_loss: 20.8181 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 21.9983 - accuracy: 0.0000e+00 - val_loss: 20.5485 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 22.3946 - accuracy: 0.0000e+00 - val_loss: 22.2517 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 24.7328 - accuracy: 0.0000e+00 - val_loss: 20.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 17.6043 - accuracy: 0.0000e+00 - val_loss: 22.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.4610 - accuracy: 0.0000e+00 - val_loss: 22.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.8332 - accuracy: 0.0000e+00 - val_loss: 14.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.1112 - accuracy: 0.0000e+00 - val_loss: 18.3515 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 21.5728 - accuracy: 0.0000e+00 - val_loss: 19.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.6341 - accuracy: 0.0000e+00 - val_loss: 32.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 18.4588 - accuracy: 0.0000e+00 - val_loss: 27.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 16.1721 - accuracy: 0.0000e+00 - val_loss: 23.9837 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 22.1525 - accuracy: 0.0000e+00 - val_loss: 16.8787 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 22.7411 - accuracy: 0.0000e+00 - val_loss: 24.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.5968 - accuracy: 0.0000e+00 - val_loss: 18.3488 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.8314 - accuracy: 0.0000e+00 - val_loss: 19.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 21.2340 - accuracy: 0.0000e+00 - val_loss: 29.5606 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.0255 - accuracy: 0.0000e+00 - val_loss: 20.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 19.9792 - accuracy: 0.0000e+00 - val_loss: 20.7328 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 21.1770 - accuracy: 0.0000e+00 - val_loss: 20.5686 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 21.1984 - accuracy: 0.0000e+00 - val_loss: 27.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 21.6365 - accuracy: 0.0000e+00 - val_loss: 17.3278 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 19.4796 - accuracy: 0.0000e+00 - val_loss: 28.1792 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.6280 - accuracy: 0.0000e+00 - val_loss: 20.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 20.6701 - accuracy: 0.0000e+00 - val_loss: 17.8915 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 22.8590 - accuracy: 0.0000e+00 - val_loss: 27.4990 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.3705 - accuracy: 0.0000e+00 - val_loss: 21.2589 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 19.5461 - accuracy: 0.0000e+00 - val_loss: 13.9950 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 23.0879 - accuracy: 0.0000e+00 - val_loss: 13.0425 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.5989 - accuracy: 0.0000e+00 - val_loss: 20.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 24.0165 - accuracy: 0.0000e+00 - val_loss: 17.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.3004 - accuracy: 0.0000e+00 - val_loss: 22.6565 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.6937 - accuracy: 0.0000e+00 - val_loss: 18.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.0205 - accuracy: 0.0000e+00 - val_loss: 22.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 19.0844 - accuracy: 0.0000e+00 - val_loss: 18.0951 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.8724 - accuracy: 0.0000e+00 - val_loss: 22.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 16.7375 - accuracy: 0.0000e+00 - val_loss: 31.5626 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 20.5502 - accuracy: 0.0000e+00 - val_loss: 19.3191 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.8488 - accuracy: 0.0000e+00 - val_loss: 14.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 21.9750 - accuracy: 0.0000e+00 - val_loss: 21.7489 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.8851 - accuracy: 0.0000e+00 - val_loss: 17.3885 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 17.4872 - accuracy: 0.0000e+00 - val_loss: 15.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.4545 - accuracy: 0.0000e+00 - val_loss: 24.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.7424 - accuracy: 0.0000e+00 - val_loss: 16.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 22.4476 - accuracy: 0.0000e+00 - val_loss: 14.3094 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.7320 - accuracy: 0.0000e+00 - val_loss: 18.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 19.2307 - accuracy: 0.0000e+00 - val_loss: 19.9454 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 19.6157 - accuracy: 0.0000e+00 - val_loss: 23.0511 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.8626 - accuracy: 0.0000e+00 - val_loss: 15.6151 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 19.6611 - accuracy: 0.0000e+00 - val_loss: 21.9708 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.5669 - accuracy: 0.0000e+00 - val_loss: 20.2457 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.9837 - accuracy: 0.0000e+00 - val_loss: 23.5095 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.7398 - accuracy: 0.0000e+00 - val_loss: 17.9522 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 18.8271 - accuracy: 0.0000e+00 - val_loss: 24.2478 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 18.6334 - accuracy: 0.0000e+00 - val_loss: 14.5350 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.6592 - accuracy: 0.0000e+00 - val_loss: 20.5683 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 21.5990 - accuracy: 0.0000e+00 - val_loss: 26.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.9568 - accuracy: 0.0000e+00 - val_loss: 27.2545 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 18.1537 - accuracy: 0.0000e+00 - val_loss: 17.0369 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 18.6024 - accuracy: 0.0000e+00 - val_loss: 17.6425 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 17.8429 - accuracy: 0.0000e+00 - val_loss: 16.5427 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 16.9151 - accuracy: 0.0000e+00 - val_loss: 20.1012 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 23.0803 - accuracy: 0.0000e+00 - val_loss: 15.3040 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 19.2981 - accuracy: 0.0000e+00 - val_loss: 22.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.1677 - accuracy: 0.0000e+00 - val_loss: 19.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 19.3605 - accuracy: 0.0000e+00 - val_loss: 21.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.7054 - accuracy: 0.0000e+00 - val_loss: 22.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.7541 - accuracy: 0.0000e+00 - val_loss: 16.3319 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.8972 - accuracy: 0.0000e+00 - val_loss: 22.9564 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 19.6340 - accuracy: 0.0000e+00 - val_loss: 15.2515 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 22.3999 - accuracy: 0.0000e+00 - val_loss: 16.4812 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 24.9980 - accuracy: 0.0000e+00 - val_loss: 18.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.9951 - accuracy: 0.0000e+00 - val_loss: 19.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 23.8776 - accuracy: 0.0000e+00 - val_loss: 20.5963 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.1623 - accuracy: 0.0000e+00 - val_loss: 23.7127 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 21.5980 - accuracy: 0.0000e+00 - val_loss: 19.2632 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 18.7231 - accuracy: 0.0000e+00 - val_loss: 21.4731 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.1707 - accuracy: 0.0000e+00 - val_loss: 21.0451 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.5952 - accuracy: 0.0000e+00 - val_loss: 20.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 21.2112 - accuracy: 0.0000e+00 - val_loss: 20.6511 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 22.7999 - accuracy: 0.0000e+00 - val_loss: 18.9837 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 17.4347 - accuracy: 0.0000e+00 - val_loss: 17.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 17.2544 - accuracy: 0.0000e+00 - val_loss: 20.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 17.7419 - accuracy: 0.0000e+00 - val_loss: 20.3173 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 20.1654 - accuracy: 0.0000e+00 - val_loss: 20.1596 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 23.5228 - accuracy: 0.0000e+00 - val_loss: 20.9389 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 17.6203 - accuracy: 0.0000e+00 - val_loss: 19.7228 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 24.0075 - accuracy: 0.0000e+00 - val_loss: 14.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.3345 - accuracy: 0.0000e+00 - val_loss: 13.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 19.6006 - accuracy: 0.0000e+00 - val_loss: 17.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 19.4875 - accuracy: 0.0000e+00 - val_loss: 18.8031 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.3004 - accuracy: 0.0000e+00 - val_loss: 23.3801 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 17.9935 - accuracy: 0.0000e+00 - val_loss: 24.3334 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.7285 - accuracy: 0.0000e+00 - val_loss: 20.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 19.9445 - accuracy: 0.0000e+00 - val_loss: 17.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "251/251 [==============================] - 0s 32us/sample - loss: 20.7970 - accuracy: 0.0000e+00 - val_loss: 22.4063 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 17.6835 - accuracy: 0.0000e+00 - val_loss: 18.3032 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.6077 - accuracy: 0.0000e+00 - val_loss: 19.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 21.5937 - accuracy: 0.0000e+00 - val_loss: 21.8102 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 17.0563 - accuracy: 0.0000e+00 - val_loss: 15.8177 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 25.7444 - accuracy: 0.0000e+00 - val_loss: 19.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.5470 - accuracy: 0.0000e+00 - val_loss: 22.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.2541 - accuracy: 0.0000e+00 - val_loss: 20.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "251/251 [==============================] - 0s 33us/sample - loss: 20.9068 - accuracy: 0.0000e+00 - val_loss: 25.2088 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.4011 - accuracy: 0.0000e+00 - val_loss: 23.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 19.4833 - accuracy: 0.0000e+00 - val_loss: 26.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 18.6503 - accuracy: 0.0000e+00 - val_loss: 17.9537 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "251/251 [==============================] - 0s 43us/sample - loss: 19.4151 - accuracy: 0.0000e+00 - val_loss: 17.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 19.3621 - accuracy: 0.0000e+00 - val_loss: 26.5205 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 19.4981 - accuracy: 0.0000e+00 - val_loss: 21.2102 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 19.4855 - accuracy: 0.0000e+00 - val_loss: 23.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 19.5128 - accuracy: 0.0000e+00 - val_loss: 24.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 22.9488 - accuracy: 0.0000e+00 - val_loss: 21.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.8580 - accuracy: 0.0000e+00 - val_loss: 23.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 21.6645 - accuracy: 0.0000e+00 - val_loss: 17.9265 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 17.8870 - accuracy: 0.0000e+00 - val_loss: 23.0340 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.8249 - accuracy: 0.0000e+00 - val_loss: 17.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.8047 - accuracy: 0.0000e+00 - val_loss: 17.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 20.9194 - accuracy: 0.0000e+00 - val_loss: 22.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 22.1618 - accuracy: 0.0000e+00 - val_loss: 17.4746 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.7124 - accuracy: 0.0000e+00 - val_loss: 18.5079 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 21.6252 - accuracy: 0.0000e+00 - val_loss: 20.8552 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 21.8465 - accuracy: 0.0000e+00 - val_loss: 20.0888 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.4630 - accuracy: 0.0000e+00 - val_loss: 19.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 16.6670 - accuracy: 0.0000e+00 - val_loss: 21.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 18.9862 - accuracy: 0.0000e+00 - val_loss: 22.2510 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.1814 - accuracy: 0.0000e+00 - val_loss: 19.9200 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 19.7554 - accuracy: 0.0000e+00 - val_loss: 17.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 21.3976 - accuracy: 0.0000e+00 - val_loss: 19.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 19.4583 - accuracy: 0.0000e+00 - val_loss: 17.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 20.3723 - accuracy: 0.0000e+00 - val_loss: 17.8487 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 17.8865 - accuracy: 0.0000e+00 - val_loss: 17.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 17.4441 - accuracy: 0.0000e+00 - val_loss: 22.7277 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 17.1422 - accuracy: 0.0000e+00 - val_loss: 18.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 18.0093 - accuracy: 0.0000e+00 - val_loss: 21.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 18.3873 - accuracy: 0.0000e+00 - val_loss: 15.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 18.9856 - accuracy: 0.0000e+00 - val_loss: 23.3512 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.4677 - accuracy: 0.0000e+00 - val_loss: 17.0790 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 19.0775 - accuracy: 0.0000e+00 - val_loss: 16.0416 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "251/251 [==============================] - 0s 34us/sample - loss: 22.1977 - accuracy: 0.0000e+00 - val_loss: 14.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 19.4330 - accuracy: 0.0000e+00 - val_loss: 25.9446 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.7798 - accuracy: 0.0000e+00 - val_loss: 25.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "251/251 [==============================] - 0s 35us/sample - loss: 21.3014 - accuracy: 0.0000e+00 - val_loss: 21.9408 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 18.2928 - accuracy: 0.0000e+00 - val_loss: 21.2172 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 17.6881 - accuracy: 0.0000e+00 - val_loss: 24.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 18.8256 - accuracy: 0.0000e+00 - val_loss: 30.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.3089 - accuracy: 0.0000e+00 - val_loss: 23.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "251/251 [==============================] - 0s 37us/sample - loss: 17.6174 - accuracy: 0.0000e+00 - val_loss: 22.3961 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.2645 - accuracy: 0.0000e+00 - val_loss: 16.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "251/251 [==============================] - 0s 40us/sample - loss: 20.5375 - accuracy: 0.0000e+00 - val_loss: 17.2922 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 25.7605 - accuracy: 0.0000e+00 - val_loss: 19.7818 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 16.6067 - accuracy: 0.0000e+00 - val_loss: 20.8057 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 20.0369 - accuracy: 0.0000e+00 - val_loss: 15.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "251/251 [==============================] - 0s 36us/sample - loss: 20.1190 - accuracy: 0.0000e+00 - val_loss: 23.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "251/251 [==============================] - 0s 41us/sample - loss: 20.6237 - accuracy: 0.0000e+00 - val_loss: 21.7023 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 16.7547 - accuracy: 0.0000e+00 - val_loss: 15.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "251/251 [==============================] - 0s 39us/sample - loss: 18.5086 - accuracy: 0.0000e+00 - val_loss: 17.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "251/251 [==============================] - 0s 45us/sample - loss: 18.3673 - accuracy: 0.0000e+00 - val_loss: 20.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "251/251 [==============================] - 0s 42us/sample - loss: 20.8719 - accuracy: 0.0000e+00 - val_loss: 16.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "251/251 [==============================] - 0s 38us/sample - loss: 20.0001 - accuracy: 0.0000e+00 - val_loss: 18.3607 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_dropout = model_dropout.fit(\n",
    "    normed_train_data, train_labels,\n",
    "    epochs=500,\n",
    "    validation_split=0.2,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dropout.save(\"model_dropout.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RBFKernelFn(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(RBFKernelFn, self).__init__(**kwargs)\n",
    "    dtype = kwargs.get('dtype', None)\n",
    "\n",
    "    self._amplitude = self.add_variable(\n",
    "            initializer=tf.constant_initializer(0),\n",
    "            dtype=dtype,\n",
    "            name='amplitude')\n",
    "    \n",
    "    self._length_scale = self.add_variable(\n",
    "            initializer=tf.constant_initializer(0),\n",
    "            dtype=dtype,\n",
    "            name='length_scale')\n",
    "\n",
    "  def call(self, x):\n",
    "    # Never called -- this is just a layer so it can hold variables\n",
    "    # in a way Keras understands.\n",
    "    return x\n",
    "\n",
    "  @property\n",
    "  def kernel(self):\n",
    "    return tfp.positive_semidefinite_kernels.ExponentiatedQuadratic(\n",
    "      amplitude=tf.nn.softplus(0.1 * self._amplitude),\n",
    "      length_scale=tf.nn.softplus(5. * self._length_scale)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_inducing_points = 100\n",
    "model4 = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(2),\n",
    "    layers.Dense(1),\n",
    "    tfp.layers.VariationalGaussianProcess(\n",
    "        num_inducing_points=num_inducing_points,\n",
    "        kernel_provider=RBFKernelFn(),\n",
    "        event_shape=[1],\n",
    "        inducing_index_points_initializer=tf.constant_initializer(\n",
    "            np.linspace(*[-1,1], num=num_inducing_points)[..., np.newaxis]),\n",
    "        unconstrained_observation_noise_variance_initializer=(\n",
    "            tf.constant_initializer(np.array(0.54)))),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8462a684cc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m loss = lambda y, rv_y: rv_y.variational_loss(\n\u001b[1;32m      2\u001b[0m     y, kl_weight=np.array(10, x.dtype) / 50)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1556\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-8462a684cc6d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(y, rv_y)\u001b[0m\n\u001b[1;32m      1\u001b[0m loss = lambda y, rv_y: rv_y.variational_loss(\n\u001b[0;32m----> 2\u001b[0;31m     y, kl_weight=np.array(10, x.dtype) / 50)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "loss = lambda y, rv_y: rv_y.variational_loss(\n",
    "    y, kl_weight=np.array(10, x.dtype) / 50)\n",
    "model4.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=loss)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314 samples\n",
      "Epoch 1/50\n",
      "314/314 [==============================] - 1s 3ms/sample - loss: 2692.0180\n",
      "Epoch 2/50\n",
      "314/314 [==============================] - 0s 268us/sample - loss: 2613.9858\n",
      "Epoch 3/50\n",
      "314/314 [==============================] - 0s 239us/sample - loss: 2559.2309\n",
      "Epoch 4/50\n",
      "314/314 [==============================] - 0s 216us/sample - loss: 2495.5114\n",
      "Epoch 5/50\n",
      "314/314 [==============================] - 0s 212us/sample - loss: 2448.1461\n",
      "Epoch 6/50\n",
      "314/314 [==============================] - 0s 211us/sample - loss: 2393.6799\n",
      "Epoch 7/50\n",
      "314/314 [==============================] - 0s 213us/sample - loss: 2328.5791\n",
      "Epoch 8/50\n",
      "314/314 [==============================] - 0s 209us/sample - loss: 2271.9944\n",
      "Epoch 9/50\n",
      "314/314 [==============================] - 0s 215us/sample - loss: 2237.8525\n",
      "Epoch 10/50\n",
      "314/314 [==============================] - 0s 216us/sample - loss: 2186.9750\n",
      "Epoch 11/50\n",
      "314/314 [==============================] - 0s 233us/sample - loss: 2122.0425\n",
      "Epoch 12/50\n",
      "314/314 [==============================] - 0s 220us/sample - loss: 2074.7833\n",
      "Epoch 13/50\n",
      "314/314 [==============================] - 0s 216us/sample - loss: 2020.9754\n",
      "Epoch 14/50\n",
      "314/314 [==============================] - 0s 213us/sample - loss: 1961.1571\n",
      "Epoch 15/50\n",
      "314/314 [==============================] - 0s 220us/sample - loss: 1884.1971\n",
      "Epoch 16/50\n",
      "314/314 [==============================] - 0s 222us/sample - loss: 1804.9367\n",
      "Epoch 17/50\n",
      "314/314 [==============================] - 0s 226us/sample - loss: 1692.5959\n",
      "Epoch 18/50\n",
      "314/314 [==============================] - 0s 226us/sample - loss: 1524.9583\n",
      "Epoch 19/50\n",
      "314/314 [==============================] - 0s 231us/sample - loss: 1194.3218\n",
      "Epoch 20/50\n",
      "314/314 [==============================] - 0s 245us/sample - loss: 399.1617\n",
      "Epoch 21/50\n",
      "314/314 [==============================] - 0s 253us/sample - loss: 155.7854\n",
      "Epoch 22/50\n",
      "314/314 [==============================] - 0s 250us/sample - loss: 80.6584\n",
      "Epoch 23/50\n",
      "314/314 [==============================] - 0s 261us/sample - loss: 57.7284\n",
      "Epoch 24/50\n",
      "314/314 [==============================] - 0s 279us/sample - loss: 52.3525\n",
      "Epoch 25/50\n",
      "314/314 [==============================] - 0s 248us/sample - loss: 47.9300\n",
      "Epoch 26/50\n",
      "314/314 [==============================] - 0s 225us/sample - loss: 45.7902\n",
      "Epoch 27/50\n",
      "314/314 [==============================] - 0s 240us/sample - loss: 45.5244\n",
      "Epoch 28/50\n",
      "314/314 [==============================] - 0s 229us/sample - loss: 41.3754\n",
      "Epoch 29/50\n",
      "314/314 [==============================] - 0s 224us/sample - loss: 44.9197\n",
      "Epoch 30/50\n",
      "314/314 [==============================] - 0s 228us/sample - loss: 43.5751\n",
      "Epoch 31/50\n",
      "314/314 [==============================] - 0s 233us/sample - loss: 40.5421\n",
      "Epoch 32/50\n",
      "314/314 [==============================] - 0s 230us/sample - loss: 39.2102\n",
      "Epoch 33/50\n",
      "314/314 [==============================] - 0s 225us/sample - loss: 40.2027\n",
      "Epoch 34/50\n",
      "314/314 [==============================] - 0s 226us/sample - loss: 39.8686\n",
      "Epoch 35/50\n",
      "314/314 [==============================] - 0s 244us/sample - loss: 37.8870\n",
      "Epoch 36/50\n",
      "314/314 [==============================] - 0s 250us/sample - loss: 38.8769\n",
      "Epoch 37/50\n",
      "314/314 [==============================] - 0s 263us/sample - loss: 39.4928\n",
      "Epoch 38/50\n",
      "314/314 [==============================] - 0s 228us/sample - loss: 38.0845\n",
      "Epoch 39/50\n",
      "314/314 [==============================] - 0s 232us/sample - loss: 39.9484\n",
      "Epoch 40/50\n",
      "314/314 [==============================] - 0s 221us/sample - loss: 38.4481\n",
      "Epoch 41/50\n",
      "314/314 [==============================] - 0s 241us/sample - loss: 39.9891\n",
      "Epoch 42/50\n",
      "314/314 [==============================] - 0s 239us/sample - loss: 41.4660\n",
      "Epoch 43/50\n",
      "314/314 [==============================] - 0s 227us/sample - loss: 37.4485\n",
      "Epoch 44/50\n",
      "314/314 [==============================] - 0s 224us/sample - loss: 37.5807\n",
      "Epoch 45/50\n",
      "314/314 [==============================] - 0s 220us/sample - loss: 39.7128\n",
      "Epoch 46/50\n",
      "314/314 [==============================] - 0s 227us/sample - loss: 41.8359\n",
      "Epoch 47/50\n",
      "314/314 [==============================] - 0s 245us/sample - loss: 36.7782\n",
      "Epoch 48/50\n",
      "314/314 [==============================] - 0s 242us/sample - loss: 35.6045\n",
      "Epoch 49/50\n",
      "314/314 [==============================] - 0s 228us/sample - loss: 35.7002\n",
      "Epoch 50/50\n",
      "314/314 [==============================] - 0s 224us/sample - loss: 38.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4831b860>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(normed_train_data.to_numpy(), train_labels, batch_size=10, epochs=50, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tn=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_batch = normed_test_data[:tn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "me=model(example_batch.to_numpy()).mean().numpy()\n",
    "std=model(example_batch.to_numpy()).stddev().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "me2=model4(example_batch.to_numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vrb=[]\n",
    "for i in range(0,200):\n",
    "    l=model4(np.asmatrix(example_batch.to_numpy()[1])).sample().numpy().tolist()[0][0]\n",
    "    vrb.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(vrb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.TransformedDistribution 'transposeIndependentsequential_30/variational_gaussian_process_22/VariataionalGaussianProcess/' batch_shape=[] event_shape=[40, 1] dtype=float32>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std2=model4(example_batch.to_numpy())\n",
    "std2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gauspred(x):\n",
    "    B=100\n",
    "    d=[]\n",
    "    a=model4(x).sample()\n",
    "    for i in range(1,B):\n",
    "        l=model4(x).sample()\n",
    "        a=np.hstack((a,l))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gp=gauspred(example_batch.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def droppredict(x):\n",
    "    B=100\n",
    "    d=[]\n",
    "    a=model_dropout.predict(x)\n",
    "    for i in range(1,B):\n",
    "        l=model_dropout.predict(x)\n",
    "        a=np.hstack((a,l))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md=droppredict(example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfp mean</th>\n",
       "      <th>tfp std</th>\n",
       "      <th>dropout mean</th>\n",
       "      <th>dropout stdev</th>\n",
       "      <th>Gaus Mean</th>\n",
       "      <th>Gaus std</th>\n",
       "      <th>classic</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.615889</td>\n",
       "      <td>1.211003</td>\n",
       "      <td>14.346698</td>\n",
       "      <td>2.551111</td>\n",
       "      <td>15.104478</td>\n",
       "      <td>2.999994</td>\n",
       "      <td>16.782129</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.190832</td>\n",
       "      <td>0.967606</td>\n",
       "      <td>10.723137</td>\n",
       "      <td>2.257241</td>\n",
       "      <td>11.668277</td>\n",
       "      <td>2.257604</td>\n",
       "      <td>11.244649</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.999650</td>\n",
       "      <td>1.035679</td>\n",
       "      <td>9.619412</td>\n",
       "      <td>2.634160</td>\n",
       "      <td>8.760547</td>\n",
       "      <td>1.765841</td>\n",
       "      <td>12.211715</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.240805</td>\n",
       "      <td>2.469728</td>\n",
       "      <td>23.231640</td>\n",
       "      <td>3.791487</td>\n",
       "      <td>25.854607</td>\n",
       "      <td>4.843260</td>\n",
       "      <td>23.046797</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.633820</td>\n",
       "      <td>1.664374</td>\n",
       "      <td>19.912867</td>\n",
       "      <td>2.584640</td>\n",
       "      <td>20.844883</td>\n",
       "      <td>3.934191</td>\n",
       "      <td>22.428860</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.381469</td>\n",
       "      <td>1.079394</td>\n",
       "      <td>12.989202</td>\n",
       "      <td>2.099322</td>\n",
       "      <td>14.118375</td>\n",
       "      <td>2.699134</td>\n",
       "      <td>13.210623</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.612966</td>\n",
       "      <td>1.111978</td>\n",
       "      <td>13.582804</td>\n",
       "      <td>2.282643</td>\n",
       "      <td>14.069480</td>\n",
       "      <td>2.752482</td>\n",
       "      <td>12.993000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.175472</td>\n",
       "      <td>1.070575</td>\n",
       "      <td>12.333518</td>\n",
       "      <td>2.446663</td>\n",
       "      <td>13.379936</td>\n",
       "      <td>2.665951</td>\n",
       "      <td>12.950930</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.181692</td>\n",
       "      <td>1.575255</td>\n",
       "      <td>17.736345</td>\n",
       "      <td>2.834049</td>\n",
       "      <td>19.511934</td>\n",
       "      <td>3.619054</td>\n",
       "      <td>20.369175</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.840733</td>\n",
       "      <td>3.046373</td>\n",
       "      <td>28.371742</td>\n",
       "      <td>4.078119</td>\n",
       "      <td>31.548779</td>\n",
       "      <td>5.874182</td>\n",
       "      <td>29.525169</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.518835</td>\n",
       "      <td>2.097578</td>\n",
       "      <td>24.868694</td>\n",
       "      <td>2.876042</td>\n",
       "      <td>24.669365</td>\n",
       "      <td>4.751507</td>\n",
       "      <td>25.446714</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.366350</td>\n",
       "      <td>2.546513</td>\n",
       "      <td>23.602270</td>\n",
       "      <td>3.173626</td>\n",
       "      <td>22.013321</td>\n",
       "      <td>4.245092</td>\n",
       "      <td>24.906088</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.271628</td>\n",
       "      <td>1.219776</td>\n",
       "      <td>14.560425</td>\n",
       "      <td>2.458941</td>\n",
       "      <td>14.888473</td>\n",
       "      <td>2.910088</td>\n",
       "      <td>14.428247</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27.605410</td>\n",
       "      <td>2.223387</td>\n",
       "      <td>24.728741</td>\n",
       "      <td>3.065435</td>\n",
       "      <td>24.883600</td>\n",
       "      <td>4.730296</td>\n",
       "      <td>27.427414</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.176885</td>\n",
       "      <td>1.092969</td>\n",
       "      <td>13.519825</td>\n",
       "      <td>1.979923</td>\n",
       "      <td>14.292911</td>\n",
       "      <td>2.770976</td>\n",
       "      <td>12.450420</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.877229</td>\n",
       "      <td>1.215116</td>\n",
       "      <td>14.563886</td>\n",
       "      <td>2.294423</td>\n",
       "      <td>14.694912</td>\n",
       "      <td>2.864871</td>\n",
       "      <td>13.928451</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.144507</td>\n",
       "      <td>1.212267</td>\n",
       "      <td>15.319899</td>\n",
       "      <td>2.103106</td>\n",
       "      <td>15.277013</td>\n",
       "      <td>2.860298</td>\n",
       "      <td>14.431067</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.871758</td>\n",
       "      <td>1.131791</td>\n",
       "      <td>13.243106</td>\n",
       "      <td>2.328317</td>\n",
       "      <td>14.083487</td>\n",
       "      <td>2.761171</td>\n",
       "      <td>13.323143</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.555353</td>\n",
       "      <td>1.541611</td>\n",
       "      <td>18.663416</td>\n",
       "      <td>2.448956</td>\n",
       "      <td>18.815035</td>\n",
       "      <td>3.533648</td>\n",
       "      <td>18.650631</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.336943</td>\n",
       "      <td>1.087754</td>\n",
       "      <td>13.037799</td>\n",
       "      <td>2.308058</td>\n",
       "      <td>13.450006</td>\n",
       "      <td>2.621567</td>\n",
       "      <td>12.689337</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.722486</td>\n",
       "      <td>1.125061</td>\n",
       "      <td>12.951853</td>\n",
       "      <td>2.210042</td>\n",
       "      <td>13.325038</td>\n",
       "      <td>2.506989</td>\n",
       "      <td>14.125639</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25.974564</td>\n",
       "      <td>2.413169</td>\n",
       "      <td>25.813322</td>\n",
       "      <td>3.279015</td>\n",
       "      <td>28.115429</td>\n",
       "      <td>5.306005</td>\n",
       "      <td>25.901497</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.121023</td>\n",
       "      <td>1.825520</td>\n",
       "      <td>20.407671</td>\n",
       "      <td>2.856780</td>\n",
       "      <td>21.895157</td>\n",
       "      <td>4.171959</td>\n",
       "      <td>19.904713</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.532988</td>\n",
       "      <td>1.947748</td>\n",
       "      <td>21.259409</td>\n",
       "      <td>2.998312</td>\n",
       "      <td>23.683474</td>\n",
       "      <td>4.445355</td>\n",
       "      <td>21.242979</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28.776726</td>\n",
       "      <td>3.080768</td>\n",
       "      <td>29.205582</td>\n",
       "      <td>3.691816</td>\n",
       "      <td>31.643431</td>\n",
       "      <td>5.814766</td>\n",
       "      <td>30.293423</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.310343</td>\n",
       "      <td>2.034568</td>\n",
       "      <td>24.581179</td>\n",
       "      <td>3.067280</td>\n",
       "      <td>24.299746</td>\n",
       "      <td>4.599916</td>\n",
       "      <td>24.154863</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.121086</td>\n",
       "      <td>1.437472</td>\n",
       "      <td>16.392420</td>\n",
       "      <td>2.212903</td>\n",
       "      <td>17.149855</td>\n",
       "      <td>3.224460</td>\n",
       "      <td>16.903467</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22.106449</td>\n",
       "      <td>2.481197</td>\n",
       "      <td>24.467440</td>\n",
       "      <td>2.787463</td>\n",
       "      <td>23.954933</td>\n",
       "      <td>4.512056</td>\n",
       "      <td>22.784607</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.105209</td>\n",
       "      <td>1.520890</td>\n",
       "      <td>18.185347</td>\n",
       "      <td>2.172737</td>\n",
       "      <td>19.416777</td>\n",
       "      <td>3.628742</td>\n",
       "      <td>17.444992</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.317913</td>\n",
       "      <td>1.550177</td>\n",
       "      <td>18.979124</td>\n",
       "      <td>2.545594</td>\n",
       "      <td>16.967615</td>\n",
       "      <td>3.291289</td>\n",
       "      <td>18.863323</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27.260780</td>\n",
       "      <td>3.011315</td>\n",
       "      <td>28.155081</td>\n",
       "      <td>3.764215</td>\n",
       "      <td>28.971714</td>\n",
       "      <td>5.410928</td>\n",
       "      <td>28.076235</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.959845</td>\n",
       "      <td>1.764523</td>\n",
       "      <td>21.432650</td>\n",
       "      <td>2.561945</td>\n",
       "      <td>22.031382</td>\n",
       "      <td>4.116272</td>\n",
       "      <td>22.101240</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>19.134163</td>\n",
       "      <td>1.622596</td>\n",
       "      <td>19.550200</td>\n",
       "      <td>2.539730</td>\n",
       "      <td>19.039490</td>\n",
       "      <td>3.576967</td>\n",
       "      <td>18.559704</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20.323608</td>\n",
       "      <td>1.997996</td>\n",
       "      <td>22.322319</td>\n",
       "      <td>2.991125</td>\n",
       "      <td>22.902702</td>\n",
       "      <td>4.319448</td>\n",
       "      <td>21.528851</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>26.407911</td>\n",
       "      <td>2.322076</td>\n",
       "      <td>27.007551</td>\n",
       "      <td>3.568923</td>\n",
       "      <td>27.306213</td>\n",
       "      <td>5.090726</td>\n",
       "      <td>26.297281</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.729700</td>\n",
       "      <td>1.364649</td>\n",
       "      <td>15.808519</td>\n",
       "      <td>2.573004</td>\n",
       "      <td>15.129665</td>\n",
       "      <td>2.886639</td>\n",
       "      <td>16.052647</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19.341505</td>\n",
       "      <td>1.683394</td>\n",
       "      <td>20.748291</td>\n",
       "      <td>2.504143</td>\n",
       "      <td>19.151112</td>\n",
       "      <td>3.667709</td>\n",
       "      <td>18.704750</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>29.895155</td>\n",
       "      <td>2.683341</td>\n",
       "      <td>28.183649</td>\n",
       "      <td>4.003903</td>\n",
       "      <td>27.959990</td>\n",
       "      <td>5.263822</td>\n",
       "      <td>31.225971</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>29.471746</td>\n",
       "      <td>2.855070</td>\n",
       "      <td>29.078974</td>\n",
       "      <td>3.879847</td>\n",
       "      <td>30.902718</td>\n",
       "      <td>5.791155</td>\n",
       "      <td>30.572865</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>18.237385</td>\n",
       "      <td>1.572291</td>\n",
       "      <td>18.640991</td>\n",
       "      <td>2.491615</td>\n",
       "      <td>18.713318</td>\n",
       "      <td>3.542408</td>\n",
       "      <td>17.644503</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tfp mean   tfp std  dropout mean  dropout stdev  Gaus Mean  Gaus std  \\\n",
       "0   16.615889  1.211003     14.346698       2.551111  15.104478  2.999994   \n",
       "1   11.190832  0.967606     10.723137       2.257241  11.668277  2.257604   \n",
       "2   11.999650  1.035679      9.619412       2.634160   8.760547  1.765841   \n",
       "3   24.240805  2.469728     23.231640       3.791487  25.854607  4.843260   \n",
       "4   21.633820  1.664374     19.912867       2.584640  20.844883  3.934191   \n",
       "5   13.381469  1.079394     12.989202       2.099322  14.118375  2.699134   \n",
       "6   13.612966  1.111978     13.582804       2.282643  14.069480  2.752482   \n",
       "7   13.175472  1.070575     12.333518       2.446663  13.379936  2.665951   \n",
       "8   20.181692  1.575255     17.736345       2.834049  19.511934  3.619054   \n",
       "9   29.840733  3.046373     28.371742       4.078119  31.548779  5.874182   \n",
       "10  25.518835  2.097578     24.868694       2.876042  24.669365  4.751507   \n",
       "11  24.366350  2.546513     23.602270       3.173626  22.013321  4.245092   \n",
       "12  15.271628  1.219776     14.560425       2.458941  14.888473  2.910088   \n",
       "13  27.605410  2.223387     24.728741       3.065435  24.883600  4.730296   \n",
       "14  13.176885  1.092969     13.519825       1.979923  14.292911  2.770976   \n",
       "15  14.877229  1.215116     14.563886       2.294423  14.694912  2.864871   \n",
       "16  15.144507  1.212267     15.319899       2.103106  15.277013  2.860298   \n",
       "17  13.871758  1.131791     13.243106       2.328317  14.083487  2.761171   \n",
       "18  18.555353  1.541611     18.663416       2.448956  18.815035  3.533648   \n",
       "19  13.336943  1.087754     13.037799       2.308058  13.450006  2.621567   \n",
       "20  14.722486  1.125061     12.951853       2.210042  13.325038  2.506989   \n",
       "21  25.974564  2.413169     25.813322       3.279015  28.115429  5.306005   \n",
       "22  19.121023  1.825520     20.407671       2.856780  21.895157  4.171959   \n",
       "23  20.532988  1.947748     21.259409       2.998312  23.683474  4.445355   \n",
       "24  28.776726  3.080768     29.205582       3.691816  31.643431  5.814766   \n",
       "25  24.310343  2.034568     24.581179       3.067280  24.299746  4.599916   \n",
       "26  17.121086  1.437472     16.392420       2.212903  17.149855  3.224460   \n",
       "27  22.106449  2.481197     24.467440       2.787463  23.954933  4.512056   \n",
       "28  18.105209  1.520890     18.185347       2.172737  19.416777  3.628742   \n",
       "29  19.317913  1.550177     18.979124       2.545594  16.967615  3.291289   \n",
       "30  27.260780  3.011315     28.155081       3.764215  28.971714  5.410928   \n",
       "31  21.959845  1.764523     21.432650       2.561945  22.031382  4.116272   \n",
       "32  19.134163  1.622596     19.550200       2.539730  19.039490  3.576967   \n",
       "33  20.323608  1.997996     22.322319       2.991125  22.902702  4.319448   \n",
       "34  26.407911  2.322076     27.007551       3.568923  27.306213  5.090726   \n",
       "35  16.729700  1.364649     15.808519       2.573004  15.129665  2.886639   \n",
       "36  19.341505  1.683394     20.748291       2.504143  19.151112  3.667709   \n",
       "37  29.895155  2.683341     28.183649       4.003903  27.959990  5.263822   \n",
       "38  29.471746  2.855070     29.078974       3.879847  30.902718  5.791155   \n",
       "39  18.237385  1.572291     18.640991       2.491615  18.713318  3.542408   \n",
       "\n",
       "      classic  true  \n",
       "0   16.782129  15.0  \n",
       "1   11.244649  10.0  \n",
       "2   12.211715   9.0  \n",
       "3   23.046797  25.0  \n",
       "4   22.428860  19.0  \n",
       "5   13.210623  14.0  \n",
       "6   12.993000  14.0  \n",
       "7   12.950930  13.0  \n",
       "8   20.369175  18.0  \n",
       "9   29.525169  35.0  \n",
       "10  25.446714  25.0  \n",
       "11  24.906088  19.0  \n",
       "12  14.428247  13.0  \n",
       "13  27.427414  28.0  \n",
       "14  12.450420  13.0  \n",
       "15  13.928451  14.0  \n",
       "16  14.431067  15.0  \n",
       "17  13.323143  13.0  \n",
       "18  18.650631  18.0  \n",
       "19  12.689337  12.0  \n",
       "20  14.125639  16.0  \n",
       "21  25.901497  24.0  \n",
       "22  19.904713  19.0  \n",
       "23  21.242979  24.0  \n",
       "24  30.293423  31.0  \n",
       "25  24.154863  26.0  \n",
       "26  16.903467  16.0  \n",
       "27  22.784607  24.0  \n",
       "28  17.444992  18.0  \n",
       "29  18.863323  20.0  \n",
       "30  28.076235  29.0  \n",
       "31  22.101240  18.0  \n",
       "32  18.559704  19.0  \n",
       "33  21.528851  22.0  \n",
       "34  26.297281  26.0  \n",
       "35  16.052647  17.5  \n",
       "36  18.704750  22.5  \n",
       "37  31.225971  29.0  \n",
       "38  30.572865  29.0  \n",
       "39  17.644503  20.0  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=np.column_stack((me,std,md.mean(axis=1),np.sqrt(md.var(axis=1)),gp.mean(axis=1),np.sqrt(gp.var(axis=1))\n",
    "                                        ,model2.predict(example_batch),test_labels[:tn])),\n",
    "                  columns=['tfp mean','tfp std','dropout mean','dropout stdev','Gaus Mean','Gaus std','classic','true'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining aleatoric and epistemic uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach is as follows: to deal with aleatoric uncertainty I output the mean and variance of a normal distribution and I use the negative log likelihood as the loss function. In order to deal with epistemic uncertainty I let the network learn a distribution over the weights instead of point estimates. This means that everytime I put some datapoint through my trained network it will output a different (!) distribution. I can then do this a number of times and look at the mean of means of the distributions. I can also look at the variance of the means of distributions. This will tell me how certain my model is of the mean (epistemic uncertainty in this case). I can also look at the mean of the variances of the distribution (this tells me how certain my model is about the aleatoric uncertainty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Posteriors and prios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "\n",
    "def posterior_mean_field2(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "\n",
    "def posterior_mean_field3(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t, scale=1),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "\n",
    "def prior_trainable2(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t, scale=1),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "\n",
    "def prior_trainable3(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t, scale=1),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 (epistemic and aleatoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = tf.keras.Sequential([\n",
    "  tfp.layers.DenseVariational(10, posterior_mean_field, prior_trainable, kl_weight=1/normed_train_data.shape[0],input_shape=[len(train_dataset.keys())]),\n",
    "  tfp.layers.DistributionLambda(\n",
    "      lambda t: tfd.Normal(loc=t[..., :1],\n",
    "                           scale=1e-3 + tf.math.softplus(0.05*t[...,1:]))),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314 samples\n",
      "Epoch 1/800\n",
      "314/314 [==============================] - 0s 554us/sample - loss: 5.4495\n",
      "Epoch 2/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 5.2964\n",
      "Epoch 3/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 5.2340\n",
      "Epoch 4/800\n",
      "314/314 [==============================] - 0s 39us/sample - loss: 5.2027\n",
      "Epoch 5/800\n",
      "314/314 [==============================] - 0s 30us/sample - loss: 5.1728\n",
      "Epoch 6/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 5.1089\n",
      "Epoch 7/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 5.0818\n",
      "Epoch 8/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 5.0600\n",
      "Epoch 9/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 5.0528\n",
      "Epoch 10/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.9261\n",
      "Epoch 11/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.9739\n",
      "Epoch 12/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.9497\n",
      "Epoch 13/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.8963\n",
      "Epoch 14/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.8030\n",
      "Epoch 15/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.8504\n",
      "Epoch 16/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.8074\n",
      "Epoch 17/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.7476\n",
      "Epoch 18/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.6904\n",
      "Epoch 19/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.7246\n",
      "Epoch 20/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.6728\n",
      "Epoch 21/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 4.5790\n",
      "Epoch 22/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.6452\n",
      "Epoch 23/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.6151\n",
      "Epoch 24/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.6079\n",
      "Epoch 25/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.5737\n",
      "Epoch 26/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.5899\n",
      "Epoch 27/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.5164\n",
      "Epoch 28/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.5417\n",
      "Epoch 29/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.5112\n",
      "Epoch 30/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.4949\n",
      "Epoch 31/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.5083\n",
      "Epoch 32/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.4804\n",
      "Epoch 33/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.5108\n",
      "Epoch 34/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.4520\n",
      "Epoch 35/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.4896\n",
      "Epoch 36/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.4793\n",
      "Epoch 37/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.4125\n",
      "Epoch 38/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.3932\n",
      "Epoch 39/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.3792\n",
      "Epoch 40/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.3598\n",
      "Epoch 41/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.3731\n",
      "Epoch 42/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.3580\n",
      "Epoch 43/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.3285\n",
      "Epoch 44/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.3497\n",
      "Epoch 45/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.2808\n",
      "Epoch 46/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.3254\n",
      "Epoch 47/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.3014\n",
      "Epoch 48/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.3324\n",
      "Epoch 49/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.2318\n",
      "Epoch 50/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.2537\n",
      "Epoch 51/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.2389\n",
      "Epoch 52/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 4.2931\n",
      "Epoch 53/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.2260\n",
      "Epoch 54/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 4.2097\n",
      "Epoch 55/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.2333\n",
      "Epoch 56/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.2011\n",
      "Epoch 57/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.1723\n",
      "Epoch 58/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.1728\n",
      "Epoch 59/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.2370\n",
      "Epoch 60/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.1199\n",
      "Epoch 61/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.1894\n",
      "Epoch 62/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.1713\n",
      "Epoch 63/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.1925\n",
      "Epoch 64/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.1722\n",
      "Epoch 65/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.1250\n",
      "Epoch 66/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 4.1297\n",
      "Epoch 67/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 4.1079\n",
      "Epoch 68/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 4.1171\n",
      "Epoch 69/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.0389\n",
      "Epoch 70/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 4.1170\n",
      "Epoch 71/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.1135\n",
      "Epoch 72/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.0681\n",
      "Epoch 73/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.1089\n",
      "Epoch 74/800\n",
      "314/314 [==============================] - 0s 28us/sample - loss: 4.1022\n",
      "Epoch 75/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0640\n",
      "Epoch 76/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 4.0256\n",
      "Epoch 77/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0914\n",
      "Epoch 78/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 4.0408\n",
      "Epoch 79/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 4.0180\n",
      "Epoch 80/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0275\n",
      "Epoch 81/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 4.0320\n",
      "Epoch 82/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 4.0027\n",
      "Epoch 83/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0230\n",
      "Epoch 84/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0105\n",
      "Epoch 85/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 3.9990\n",
      "Epoch 86/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.9933\n",
      "Epoch 87/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0355\n",
      "Epoch 88/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.9766\n",
      "Epoch 89/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 4.0049\n",
      "Epoch 90/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.9687\n",
      "Epoch 91/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 4.0072\n",
      "Epoch 92/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.9903\n",
      "Epoch 93/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.9756\n",
      "Epoch 94/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.9213\n",
      "Epoch 95/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.9231\n",
      "Epoch 96/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 24us/sample - loss: 3.9591\n",
      "Epoch 97/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.9491\n",
      "Epoch 98/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.9362\n",
      "Epoch 99/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.9316\n",
      "Epoch 100/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.8974\n",
      "Epoch 101/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.9385\n",
      "Epoch 102/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.8926\n",
      "Epoch 103/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8707\n",
      "Epoch 104/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.8850\n",
      "Epoch 105/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8403\n",
      "Epoch 106/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8570\n",
      "Epoch 107/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.8870\n",
      "Epoch 108/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.8102\n",
      "Epoch 109/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8892\n",
      "Epoch 110/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.8351\n",
      "Epoch 111/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8204\n",
      "Epoch 112/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.8165\n",
      "Epoch 113/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.8326\n",
      "Epoch 114/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8253\n",
      "Epoch 115/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.8379\n",
      "Epoch 116/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.8344\n",
      "Epoch 117/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.7746\n",
      "Epoch 118/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.8157\n",
      "Epoch 119/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.8048\n",
      "Epoch 120/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.8305\n",
      "Epoch 121/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.7924\n",
      "Epoch 122/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.7636\n",
      "Epoch 123/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.7569\n",
      "Epoch 124/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.7779\n",
      "Epoch 125/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.7330\n",
      "Epoch 126/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.7618\n",
      "Epoch 127/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.7635\n",
      "Epoch 128/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.7200\n",
      "Epoch 129/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.7322\n",
      "Epoch 130/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.6896\n",
      "Epoch 131/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.7913\n",
      "Epoch 132/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.7319\n",
      "Epoch 133/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.7647\n",
      "Epoch 134/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.7410\n",
      "Epoch 135/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.7129\n",
      "Epoch 136/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.7481\n",
      "Epoch 137/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.7102\n",
      "Epoch 138/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6957\n",
      "Epoch 139/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6613\n",
      "Epoch 140/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.7123\n",
      "Epoch 141/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6776\n",
      "Epoch 142/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.7077\n",
      "Epoch 143/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.6296\n",
      "Epoch 144/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6820\n",
      "Epoch 145/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6599\n",
      "Epoch 146/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6301\n",
      "Epoch 147/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6967\n",
      "Epoch 148/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6725\n",
      "Epoch 149/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6738\n",
      "Epoch 150/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6824\n",
      "Epoch 151/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6411\n",
      "Epoch 152/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6757\n",
      "Epoch 153/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6077\n",
      "Epoch 154/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6296\n",
      "Epoch 155/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6041\n",
      "Epoch 156/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6012\n",
      "Epoch 157/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.6480\n",
      "Epoch 158/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.6011\n",
      "Epoch 159/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.6253\n",
      "Epoch 160/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.6138\n",
      "Epoch 161/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5530\n",
      "Epoch 162/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.5748\n",
      "Epoch 163/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6099\n",
      "Epoch 164/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5653\n",
      "Epoch 165/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5892\n",
      "Epoch 166/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.5671\n",
      "Epoch 167/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6025\n",
      "Epoch 168/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5841\n",
      "Epoch 169/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.6108\n",
      "Epoch 170/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5921\n",
      "Epoch 171/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.5689\n",
      "Epoch 172/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.5207\n",
      "Epoch 173/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5437\n",
      "Epoch 174/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5608\n",
      "Epoch 175/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5177\n",
      "Epoch 176/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5659\n",
      "Epoch 177/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5343\n",
      "Epoch 178/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5551\n",
      "Epoch 179/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.5420\n",
      "Epoch 180/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5510\n",
      "Epoch 181/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.5216\n",
      "Epoch 182/800\n",
      "314/314 [==============================] - 0s 35us/sample - loss: 3.5341\n",
      "Epoch 183/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 3.4620\n",
      "Epoch 184/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 3.5269\n",
      "Epoch 185/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.5159\n",
      "Epoch 186/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.4971\n",
      "Epoch 187/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.4563\n",
      "Epoch 188/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5032\n",
      "Epoch 189/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.5228\n",
      "Epoch 190/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4813\n",
      "Epoch 191/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.4888\n",
      "Epoch 192/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.5312\n",
      "Epoch 193/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4581\n",
      "Epoch 194/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.4569\n",
      "Epoch 195/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.5084\n",
      "Epoch 196/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.5141\n",
      "Epoch 197/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.4960\n",
      "Epoch 198/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.4599\n",
      "Epoch 199/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4563\n",
      "Epoch 200/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4345\n",
      "Epoch 201/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.5016\n",
      "Epoch 202/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.5220\n",
      "Epoch 203/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.4596\n",
      "Epoch 204/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4300\n",
      "Epoch 205/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.4757\n",
      "Epoch 206/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.4125\n",
      "Epoch 207/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4394\n",
      "Epoch 208/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.4295\n",
      "Epoch 209/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.4650\n",
      "Epoch 210/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.4597\n",
      "Epoch 211/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3970\n",
      "Epoch 212/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.4309\n",
      "Epoch 213/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3776\n",
      "Epoch 214/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.4190\n",
      "Epoch 215/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4248\n",
      "Epoch 216/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3949\n",
      "Epoch 217/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.4513\n",
      "Epoch 218/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3802\n",
      "Epoch 219/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3869\n",
      "Epoch 220/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.4155\n",
      "Epoch 221/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3923\n",
      "Epoch 222/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3794\n",
      "Epoch 223/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.3936\n",
      "Epoch 224/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3786\n",
      "Epoch 225/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.4037\n",
      "Epoch 226/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.4012\n",
      "Epoch 227/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.3672\n",
      "Epoch 228/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3547\n",
      "Epoch 229/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4054\n",
      "Epoch 230/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.4040\n",
      "Epoch 231/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3689\n",
      "Epoch 232/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3292\n",
      "Epoch 233/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.3499\n",
      "Epoch 234/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3387\n",
      "Epoch 235/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3150\n",
      "Epoch 236/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3481\n",
      "Epoch 237/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3343\n",
      "Epoch 238/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3489\n",
      "Epoch 239/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3583\n",
      "Epoch 240/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3168\n",
      "Epoch 241/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3291\n",
      "Epoch 242/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3136\n",
      "Epoch 243/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3257\n",
      "Epoch 244/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.3256\n",
      "Epoch 245/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3101\n",
      "Epoch 246/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.3171\n",
      "Epoch 247/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.2873\n",
      "Epoch 248/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3026\n",
      "Epoch 249/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.3134\n",
      "Epoch 250/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2981\n",
      "Epoch 251/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2859\n",
      "Epoch 252/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3010\n",
      "Epoch 253/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3263\n",
      "Epoch 254/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3021\n",
      "Epoch 255/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3173\n",
      "Epoch 256/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2948\n",
      "Epoch 257/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.3098\n",
      "Epoch 258/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2717\n",
      "Epoch 259/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 3.2854\n",
      "Epoch 260/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2544\n",
      "Epoch 261/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3010\n",
      "Epoch 262/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2484\n",
      "Epoch 263/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.3337\n",
      "Epoch 264/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.3236\n",
      "Epoch 265/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.2763\n",
      "Epoch 266/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2806\n",
      "Epoch 267/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2892\n",
      "Epoch 268/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.2784\n",
      "Epoch 269/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2642\n",
      "Epoch 270/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2664\n",
      "Epoch 271/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2569\n",
      "Epoch 272/800\n",
      "314/314 [==============================] - 0s 38us/sample - loss: 3.3243\n",
      "Epoch 273/800\n",
      "314/314 [==============================] - 0s 31us/sample - loss: 3.2629\n",
      "Epoch 274/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 3.2441\n",
      "Epoch 275/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2419\n",
      "Epoch 276/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2676\n",
      "Epoch 277/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2545\n",
      "Epoch 278/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.2389\n",
      "Epoch 279/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2464\n",
      "Epoch 280/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2427\n",
      "Epoch 281/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.2140\n",
      "Epoch 282/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2390\n",
      "Epoch 283/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2106\n",
      "Epoch 284/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1960\n",
      "Epoch 285/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.2463\n",
      "Epoch 286/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.1941\n",
      "Epoch 287/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2322\n",
      "Epoch 288/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.2024\n",
      "Epoch 289/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.2128\n",
      "Epoch 290/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.2519\n",
      "Epoch 291/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.2119\n",
      "Epoch 292/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2192\n",
      "Epoch 293/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1970\n",
      "Epoch 294/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1778\n",
      "Epoch 295/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.2246\n",
      "Epoch 296/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1983\n",
      "Epoch 297/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1932\n",
      "Epoch 298/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2031\n",
      "Epoch 299/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2014\n",
      "Epoch 300/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2194\n",
      "Epoch 301/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1956\n",
      "Epoch 302/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1815\n",
      "Epoch 303/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1967\n",
      "Epoch 304/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1994\n",
      "Epoch 305/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1673\n",
      "Epoch 306/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1633\n",
      "Epoch 307/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2052\n",
      "Epoch 308/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.2226\n",
      "Epoch 309/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1594\n",
      "Epoch 310/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1584\n",
      "Epoch 311/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.2015\n",
      "Epoch 312/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1604\n",
      "Epoch 313/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1638\n",
      "Epoch 314/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1690\n",
      "Epoch 315/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1832\n",
      "Epoch 316/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1476\n",
      "Epoch 317/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1468\n",
      "Epoch 318/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1731\n",
      "Epoch 319/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1799\n",
      "Epoch 320/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1569\n",
      "Epoch 321/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1625\n",
      "Epoch 322/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1656\n",
      "Epoch 323/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1305\n",
      "Epoch 324/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1975\n",
      "Epoch 325/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1351\n",
      "Epoch 326/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1300\n",
      "Epoch 327/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.1340\n",
      "Epoch 328/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1393\n",
      "Epoch 329/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1370\n",
      "Epoch 330/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1459\n",
      "Epoch 331/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.1019\n",
      "Epoch 332/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.1391\n",
      "Epoch 333/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1429\n",
      "Epoch 334/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1289\n",
      "Epoch 335/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.1329\n",
      "Epoch 336/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1298\n",
      "Epoch 337/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.1180\n",
      "Epoch 338/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0932\n",
      "Epoch 339/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1499\n",
      "Epoch 340/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0985\n",
      "Epoch 341/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1330\n",
      "Epoch 342/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1232\n",
      "Epoch 343/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.1383\n",
      "Epoch 344/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.1064\n",
      "Epoch 345/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0704\n",
      "Epoch 346/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1141\n",
      "Epoch 347/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0878\n",
      "Epoch 348/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.1332\n",
      "Epoch 349/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0873\n",
      "Epoch 350/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.1059\n",
      "Epoch 351/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0937\n",
      "Epoch 352/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0839\n",
      "Epoch 353/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0746\n",
      "Epoch 354/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0694\n",
      "Epoch 355/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0698\n",
      "Epoch 356/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0587\n",
      "Epoch 357/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0724\n",
      "Epoch 358/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0799\n",
      "Epoch 359/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0785\n",
      "Epoch 360/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0776\n",
      "Epoch 361/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0913\n",
      "Epoch 362/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0734\n",
      "Epoch 363/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0559\n",
      "Epoch 364/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0736\n",
      "Epoch 365/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0850\n",
      "Epoch 366/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0592\n",
      "Epoch 367/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0717\n",
      "Epoch 368/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0634\n",
      "Epoch 369/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0530\n",
      "Epoch 370/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0612\n",
      "Epoch 371/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0518\n",
      "Epoch 372/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0426\n",
      "Epoch 373/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0588\n",
      "Epoch 374/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0673\n",
      "Epoch 375/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.0333\n",
      "Epoch 376/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0919\n",
      "Epoch 377/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0631\n",
      "Epoch 378/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0871\n",
      "Epoch 379/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0565\n",
      "Epoch 380/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0663\n",
      "Epoch 381/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0419\n",
      "Epoch 382/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0557\n",
      "Epoch 383/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0506\n",
      "Epoch 384/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.0436\n",
      "Epoch 385/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0340\n",
      "Epoch 386/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0331\n",
      "Epoch 387/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0249\n",
      "Epoch 388/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.0497\n",
      "Epoch 389/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0327\n",
      "Epoch 390/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0191\n",
      "Epoch 391/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0206\n",
      "Epoch 392/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0036\n",
      "Epoch 393/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.0388\n",
      "Epoch 394/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0605\n",
      "Epoch 395/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 3.0439\n",
      "Epoch 396/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 3.0338\n",
      "Epoch 397/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0365\n",
      "Epoch 398/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0452\n",
      "Epoch 399/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0134\n",
      "Epoch 400/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 3.0050\n",
      "Epoch 401/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0101\n",
      "Epoch 402/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0052\n",
      "Epoch 403/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0192\n",
      "Epoch 404/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.0155\n",
      "Epoch 405/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9918\n",
      "Epoch 406/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9764\n",
      "Epoch 407/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9976\n",
      "Epoch 408/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0257\n",
      "Epoch 409/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.0150\n",
      "Epoch 410/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0086\n",
      "Epoch 411/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0186\n",
      "Epoch 412/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9962\n",
      "Epoch 413/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 3.0142\n",
      "Epoch 414/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9896\n",
      "Epoch 415/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 3.0058\n",
      "Epoch 416/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.0032\n",
      "Epoch 417/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 3.0247\n",
      "Epoch 418/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9994\n",
      "Epoch 419/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.9837\n",
      "Epoch 420/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9977\n",
      "Epoch 421/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9851\n",
      "Epoch 422/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9916\n",
      "Epoch 423/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 3.0201\n",
      "Epoch 424/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.9845\n",
      "Epoch 425/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9982\n",
      "Epoch 426/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9592\n",
      "Epoch 427/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9712\n",
      "Epoch 428/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9678\n",
      "Epoch 429/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 3.0251\n",
      "Epoch 430/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9826\n",
      "Epoch 431/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9649\n",
      "Epoch 432/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9957\n",
      "Epoch 433/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9673\n",
      "Epoch 434/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9763\n",
      "Epoch 435/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9407\n",
      "Epoch 436/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9524\n",
      "Epoch 437/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9672\n",
      "Epoch 438/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9396\n",
      "Epoch 439/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9357\n",
      "Epoch 440/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9525\n",
      "Epoch 441/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9237\n",
      "Epoch 442/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9554\n",
      "Epoch 443/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9616\n",
      "Epoch 444/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9637\n",
      "Epoch 445/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 2.9673\n",
      "Epoch 446/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9473\n",
      "Epoch 447/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9715\n",
      "Epoch 448/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9891\n",
      "Epoch 449/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9843\n",
      "Epoch 450/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9363\n",
      "Epoch 451/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9459\n",
      "Epoch 452/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9590\n",
      "Epoch 453/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9500\n",
      "Epoch 454/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.9444\n",
      "Epoch 455/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9762\n",
      "Epoch 456/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.9019\n",
      "Epoch 457/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9433\n",
      "Epoch 458/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9488\n",
      "Epoch 459/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9561\n",
      "Epoch 460/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9451\n",
      "Epoch 461/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9299\n",
      "Epoch 462/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9298\n",
      "Epoch 463/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9231\n",
      "Epoch 464/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9355\n",
      "Epoch 465/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9283\n",
      "Epoch 466/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9406\n",
      "Epoch 467/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9206\n",
      "Epoch 468/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9332\n",
      "Epoch 469/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9063\n",
      "Epoch 470/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9684\n",
      "Epoch 471/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9707\n",
      "Epoch 472/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9278\n",
      "Epoch 473/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9427\n",
      "Epoch 474/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9341\n",
      "Epoch 475/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.9331\n",
      "Epoch 476/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9187\n",
      "Epoch 477/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9078\n",
      "Epoch 478/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9214\n",
      "Epoch 479/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.9049\n",
      "Epoch 480/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9410\n",
      "Epoch 481/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.9020\n",
      "Epoch 482/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8839\n",
      "Epoch 483/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.9147\n",
      "Epoch 484/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9391\n",
      "Epoch 485/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9000\n",
      "Epoch 486/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.9120\n",
      "Epoch 487/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8940\n",
      "Epoch 488/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9291\n",
      "Epoch 489/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9052\n",
      "Epoch 490/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8786\n",
      "Epoch 491/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9059\n",
      "Epoch 492/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.9084\n",
      "Epoch 493/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9168\n",
      "Epoch 494/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9061\n",
      "Epoch 495/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8941\n",
      "Epoch 496/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8616\n",
      "Epoch 497/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.9102\n",
      "Epoch 498/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9092\n",
      "Epoch 499/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.9068\n",
      "Epoch 500/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9014\n",
      "Epoch 501/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.9139\n",
      "Epoch 502/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8912\n",
      "Epoch 503/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.9050\n",
      "Epoch 504/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8899\n",
      "Epoch 505/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9125\n",
      "Epoch 506/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8838\n",
      "Epoch 507/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9255\n",
      "Epoch 508/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8931\n",
      "Epoch 509/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8789\n",
      "Epoch 510/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8944\n",
      "Epoch 511/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8856\n",
      "Epoch 512/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 2.8993\n",
      "Epoch 513/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8735\n",
      "Epoch 514/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8737\n",
      "Epoch 515/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8751\n",
      "Epoch 516/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8860\n",
      "Epoch 517/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.9032\n",
      "Epoch 518/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.9021\n",
      "Epoch 519/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.9464\n",
      "Epoch 520/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8714\n",
      "Epoch 521/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.9143\n",
      "Epoch 522/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8862\n",
      "Epoch 523/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8801\n",
      "Epoch 524/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8714\n",
      "Epoch 525/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8918\n",
      "Epoch 526/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8731\n",
      "Epoch 527/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8722\n",
      "Epoch 528/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8673\n",
      "Epoch 529/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8674\n",
      "Epoch 530/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8784\n",
      "Epoch 531/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8514\n",
      "Epoch 532/800\n",
      "314/314 [==============================] - 0s 28us/sample - loss: 2.8726\n",
      "Epoch 533/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.8603\n",
      "Epoch 534/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8616\n",
      "Epoch 535/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8767\n",
      "Epoch 536/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8643\n",
      "Epoch 537/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8568\n",
      "Epoch 538/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8711\n",
      "Epoch 539/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8578\n",
      "Epoch 540/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8593\n",
      "Epoch 541/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8735\n",
      "Epoch 542/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8653\n",
      "Epoch 543/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8714\n",
      "Epoch 544/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8510\n",
      "Epoch 545/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.8460\n",
      "Epoch 546/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8765\n",
      "Epoch 547/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8512\n",
      "Epoch 548/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8648\n",
      "Epoch 549/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8459\n",
      "Epoch 550/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8618\n",
      "Epoch 551/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8314\n",
      "Epoch 552/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8459\n",
      "Epoch 553/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8594\n",
      "Epoch 554/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8379\n",
      "Epoch 555/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8560\n",
      "Epoch 556/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8413\n",
      "Epoch 557/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.8321\n",
      "Epoch 558/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8611\n",
      "Epoch 559/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8438\n",
      "Epoch 560/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8629\n",
      "Epoch 561/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8518\n",
      "Epoch 562/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8603\n",
      "Epoch 563/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8397\n",
      "Epoch 564/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8258\n",
      "Epoch 565/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8502\n",
      "Epoch 566/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8349\n",
      "Epoch 567/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8409\n",
      "Epoch 568/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8307\n",
      "Epoch 569/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8475\n",
      "Epoch 570/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8161\n",
      "Epoch 571/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8528\n",
      "Epoch 572/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8292\n",
      "Epoch 573/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8245\n",
      "Epoch 574/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 2.8551\n",
      "Epoch 575/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8588\n",
      "Epoch 576/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8525\n",
      "Epoch 577/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8262\n",
      "Epoch 578/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8522\n",
      "Epoch 579/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8018\n",
      "Epoch 580/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8323\n",
      "Epoch 581/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8381\n",
      "Epoch 582/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8291\n",
      "Epoch 583/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8334\n",
      "Epoch 584/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8282\n",
      "Epoch 585/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8473\n",
      "Epoch 586/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.8226\n",
      "Epoch 587/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8439\n",
      "Epoch 588/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8264\n",
      "Epoch 589/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8489\n",
      "Epoch 590/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.8303\n",
      "Epoch 591/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8404\n",
      "Epoch 592/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8051\n",
      "Epoch 593/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8317\n",
      "Epoch 594/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8433\n",
      "Epoch 595/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 2.8559\n",
      "Epoch 596/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8302\n",
      "Epoch 597/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 2.8711\n",
      "Epoch 598/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8307\n",
      "Epoch 599/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8061\n",
      "Epoch 600/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8217\n",
      "Epoch 601/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8179\n",
      "Epoch 602/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8147\n",
      "Epoch 603/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.8312\n",
      "Epoch 604/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 2.8528\n",
      "Epoch 605/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.8037\n",
      "Epoch 606/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8063\n",
      "Epoch 607/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8173\n",
      "Epoch 608/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8240\n",
      "Epoch 609/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7934\n",
      "Epoch 610/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8018\n",
      "Epoch 611/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8382\n",
      "Epoch 612/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.8048\n",
      "Epoch 613/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8117\n",
      "Epoch 614/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.8138\n",
      "Epoch 615/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.8000\n",
      "Epoch 616/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7747\n",
      "Epoch 617/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7965\n",
      "Epoch 618/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7933\n",
      "Epoch 619/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8061\n",
      "Epoch 620/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8277\n",
      "Epoch 621/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8065\n",
      "Epoch 622/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7997\n",
      "Epoch 623/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7953\n",
      "Epoch 624/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7855\n",
      "Epoch 625/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8127\n",
      "Epoch 626/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7998\n",
      "Epoch 627/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8128\n",
      "Epoch 628/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7904\n",
      "Epoch 629/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8010\n",
      "Epoch 630/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7750\n",
      "Epoch 631/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7915\n",
      "Epoch 632/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8024\n",
      "Epoch 633/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8072\n",
      "Epoch 634/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7903\n",
      "Epoch 635/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7925\n",
      "Epoch 636/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.8139\n",
      "Epoch 637/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7840\n",
      "Epoch 638/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7874\n",
      "Epoch 639/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.8089\n",
      "Epoch 640/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7891\n",
      "Epoch 641/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7916\n",
      "Epoch 642/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7940\n",
      "Epoch 643/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7651\n",
      "Epoch 644/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7943\n",
      "Epoch 645/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7974\n",
      "Epoch 646/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7981\n",
      "Epoch 647/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8058\n",
      "Epoch 648/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7695\n",
      "Epoch 649/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.8135\n",
      "Epoch 650/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7489\n",
      "Epoch 651/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7937\n",
      "Epoch 652/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7939\n",
      "Epoch 653/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7729\n",
      "Epoch 654/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7577\n",
      "Epoch 655/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7779\n",
      "Epoch 656/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7729\n",
      "Epoch 657/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7809\n",
      "Epoch 658/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7879\n",
      "Epoch 659/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7534\n",
      "Epoch 660/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7698\n",
      "Epoch 661/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7816\n",
      "Epoch 662/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7870\n",
      "Epoch 663/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7966\n",
      "Epoch 664/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7726\n",
      "Epoch 665/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8009\n",
      "Epoch 666/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7853\n",
      "Epoch 667/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7765\n",
      "Epoch 668/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7638\n",
      "Epoch 669/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7736\n",
      "Epoch 670/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7870\n",
      "Epoch 671/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7707\n",
      "Epoch 672/800\n",
      "314/314 [==============================] - 0s 17us/sample - loss: 2.7729\n",
      "Epoch 673/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7608\n",
      "Epoch 674/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.8260\n",
      "Epoch 675/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7640\n",
      "Epoch 676/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7485\n",
      "Epoch 677/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7863\n",
      "Epoch 678/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7751\n",
      "Epoch 679/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7678\n",
      "Epoch 680/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7832\n",
      "Epoch 681/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7364\n",
      "Epoch 682/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7455\n",
      "Epoch 683/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7353\n",
      "Epoch 684/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7709\n",
      "Epoch 685/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7714\n",
      "Epoch 686/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7720\n",
      "Epoch 687/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7708\n",
      "Epoch 688/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7968\n",
      "Epoch 689/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7982\n",
      "Epoch 690/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7416\n",
      "Epoch 691/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7550\n",
      "Epoch 692/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7589\n",
      "Epoch 693/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7607\n",
      "Epoch 694/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7751\n",
      "Epoch 695/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7678\n",
      "Epoch 696/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7664\n",
      "Epoch 697/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7483\n",
      "Epoch 698/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7504\n",
      "Epoch 699/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7571\n",
      "Epoch 700/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7605\n",
      "Epoch 701/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7432\n",
      "Epoch 702/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7384\n",
      "Epoch 703/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7760\n",
      "Epoch 704/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7377\n",
      "Epoch 705/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7622\n",
      "Epoch 706/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7718\n",
      "Epoch 707/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7534\n",
      "Epoch 708/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7646\n",
      "Epoch 709/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7562\n",
      "Epoch 710/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7498\n",
      "Epoch 711/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.7493\n",
      "Epoch 712/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.7645\n",
      "Epoch 713/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.7732\n",
      "Epoch 714/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7516\n",
      "Epoch 715/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7449\n",
      "Epoch 716/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7537\n",
      "Epoch 717/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7635\n",
      "Epoch 718/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7661\n",
      "Epoch 719/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7609\n",
      "Epoch 720/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7657\n",
      "Epoch 721/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7278\n",
      "Epoch 722/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7317\n",
      "Epoch 723/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7437\n",
      "Epoch 724/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7429\n",
      "Epoch 725/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7259\n",
      "Epoch 726/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7466\n",
      "Epoch 727/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7316\n",
      "Epoch 728/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7427\n",
      "Epoch 729/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7379\n",
      "Epoch 730/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7254\n",
      "Epoch 731/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7573\n",
      "Epoch 732/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7466\n",
      "Epoch 733/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7508\n",
      "Epoch 734/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7368\n",
      "Epoch 735/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7201\n",
      "Epoch 736/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7609\n",
      "Epoch 737/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7222\n",
      "Epoch 738/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7300\n",
      "Epoch 739/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7082\n",
      "Epoch 740/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7258\n",
      "Epoch 741/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 2.7399\n",
      "Epoch 742/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7489\n",
      "Epoch 743/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7565\n",
      "Epoch 744/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7582\n",
      "Epoch 745/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7362\n",
      "Epoch 746/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7436\n",
      "Epoch 747/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7643\n",
      "Epoch 748/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7508\n",
      "Epoch 749/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7575\n",
      "Epoch 750/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7451\n",
      "Epoch 751/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7363\n",
      "Epoch 752/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7277\n",
      "Epoch 753/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7086\n",
      "Epoch 754/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7540\n",
      "Epoch 755/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7365\n",
      "Epoch 756/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7282\n",
      "Epoch 757/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7213\n",
      "Epoch 758/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7319\n",
      "Epoch 759/800\n",
      "314/314 [==============================] - 0s 18us/sample - loss: 2.7090\n",
      "Epoch 760/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7549\n",
      "Epoch 761/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7279\n",
      "Epoch 762/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7059\n",
      "Epoch 763/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7470\n",
      "Epoch 764/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7213\n",
      "Epoch 765/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7366\n",
      "Epoch 766/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7157\n",
      "Epoch 767/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7246\n",
      "Epoch 768/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7126\n",
      "Epoch 769/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7199\n",
      "Epoch 770/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7531\n",
      "Epoch 771/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7325\n",
      "Epoch 772/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7225\n",
      "Epoch 773/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7118\n",
      "Epoch 774/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7139\n",
      "Epoch 775/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.7272\n",
      "Epoch 776/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7303\n",
      "Epoch 777/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7337\n",
      "Epoch 778/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7381\n",
      "Epoch 779/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7141\n",
      "Epoch 780/800\n",
      "314/314 [==============================] - 0s 27us/sample - loss: 2.7089\n",
      "Epoch 781/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7184\n",
      "Epoch 782/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.6980\n",
      "Epoch 783/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7221\n",
      "Epoch 784/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7104\n",
      "Epoch 785/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7054\n",
      "Epoch 786/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.6982\n",
      "Epoch 787/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7341\n",
      "Epoch 788/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7086\n",
      "Epoch 789/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7040\n",
      "Epoch 790/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7331\n",
      "Epoch 791/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7308\n",
      "Epoch 792/800\n",
      "314/314 [==============================] - 0s 23us/sample - loss: 2.7292\n",
      "Epoch 793/800\n",
      "314/314 [==============================] - 0s 19us/sample - loss: 2.7220\n",
      "Epoch 794/800\n",
      "314/314 [==============================] - 0s 25us/sample - loss: 2.7305\n",
      "Epoch 795/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7283\n",
      "Epoch 796/800\n",
      "314/314 [==============================] - 0s 22us/sample - loss: 2.7268\n",
      "Epoch 797/800\n",
      "314/314 [==============================] - 0s 26us/sample - loss: 2.7295\n",
      "Epoch 798/800\n",
      "314/314 [==============================] - 0s 20us/sample - loss: 2.7213\n",
      "Epoch 799/800\n",
      "314/314 [==============================] - 0s 24us/sample - loss: 2.7198\n",
      "Epoch 800/800\n",
      "314/314 [==============================] - 0s 21us/sample - loss: 2.7439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ad7a828>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(normed_train_data, train_labels, batch_size=50, epochs=800, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to create link (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-afaedf6a77ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model5.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \"\"\"\n\u001b[0;32m-> 1213\u001b[0;31m     \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[1;32m    102\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    103\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 104\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0msave_attributes_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m       \u001b[0mparam_dset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHLObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftLink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.link\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to create link (name already exists)"
     ]
    }
   ],
   "source": [
    "model5.save(\"model5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the mean and variance of means and variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: DenseVariational",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b4d807df7c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model5.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    135\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    136\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 162\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             custom_objects=dict(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[0;32m--> 353\u001b[0;31m                                        custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    354\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 181\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: DenseVariational"
     ]
    }
   ],
   "source": [
    "model5 = keras.models.load_model(\"model5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi(x):\n",
    "    B1=4\n",
    "    B=4\n",
    "    de=model5(x)\n",
    "    d=de.sample()\n",
    "    for i in range(1,B):\n",
    "            l=model5(x).sample()\n",
    "            d=np.hstack((d,l))      \n",
    "    return(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi2(x):\n",
    "    B1=100 #The number of distributions I evaluate \n",
    "    B2=100 #The number of points I take from a distribution to determine the variance\n",
    "    de=model5(x)\n",
    "    d=de.sample()\n",
    "    for i in range(1,B2):\n",
    "        l=de.sample()\n",
    "        d=np.hstack((d,l))\n",
    "    e=np.var(d,axis=1)\n",
    "    for b in range(0,B1):\n",
    "        de=model5(x)\n",
    "        d=de.sample()\n",
    "        for c in range(1,B2):\n",
    "            l=de.sample()\n",
    "            d=np.hstack((d,l))\n",
    "        t=np.var(d,axis=1)\n",
    "        e=np.hstack((e,t))\n",
    "    final=e.reshape(len(x),np.int(len(e)/len(x)))\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meane(x):\n",
    "    B=100\n",
    "    d=[]\n",
    "    a=model5(x).mean()\n",
    "    for i in range(1,B):\n",
    "        l=model5(x).mean()\n",
    "        a=np.hstack((a,l))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "epis=epi2(example_batch.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "means=meane(example_batch.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have trained a neural network that outputs a distribution. This distribution has a mean and a variance. Since the weights are not a point estimate but a distribution, I get a different distribution every time I put data trough the network! I did this a number of times in order to get the average of the means of the distribution and the variance of the variances of the distributions. This second quantity can be thought of as the model uncertainty of the aleatoric uncertainty! The first column gives the mean (over all the distribution realisations) of the mean of the distributions. The second column gives the variance of the means (how much do the means change if we pass the same point through the network a number of times?). The third column is the mean of the variances of the distributions. I calculated this by taking B1 different distributions and sampling B2 points from each distribution to get the variance of each distribution. Then I looked at the means of those variances. The variance of the variances is given in column 4 and the true value in column 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>std of means</th>\n",
       "      <th>mean of variances</th>\n",
       "      <th>std of variances</th>\n",
       "      <th>true value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.842220</td>\n",
       "      <td>0.317450</td>\n",
       "      <td>1.825873</td>\n",
       "      <td>0.560079</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.471349</td>\n",
       "      <td>0.444034</td>\n",
       "      <td>1.937971</td>\n",
       "      <td>0.517347</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.740537</td>\n",
       "      <td>0.434117</td>\n",
       "      <td>1.832003</td>\n",
       "      <td>0.554985</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.365894</td>\n",
       "      <td>0.417483</td>\n",
       "      <td>1.919929</td>\n",
       "      <td>0.565277</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.101593</td>\n",
       "      <td>0.256598</td>\n",
       "      <td>1.855694</td>\n",
       "      <td>0.552404</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.562413</td>\n",
       "      <td>0.405179</td>\n",
       "      <td>1.886901</td>\n",
       "      <td>0.550488</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.152119</td>\n",
       "      <td>0.125123</td>\n",
       "      <td>1.877433</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.497302</td>\n",
       "      <td>0.409499</td>\n",
       "      <td>1.895516</td>\n",
       "      <td>0.569522</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.189522</td>\n",
       "      <td>0.241537</td>\n",
       "      <td>1.883236</td>\n",
       "      <td>0.579042</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.618305</td>\n",
       "      <td>0.425895</td>\n",
       "      <td>1.871343</td>\n",
       "      <td>0.562083</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.730772</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>1.887647</td>\n",
       "      <td>0.573568</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.394293</td>\n",
       "      <td>0.428923</td>\n",
       "      <td>1.872826</td>\n",
       "      <td>0.562564</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.080747</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>1.882299</td>\n",
       "      <td>0.551384</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.227160</td>\n",
       "      <td>0.265097</td>\n",
       "      <td>1.891142</td>\n",
       "      <td>0.587897</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.313344</td>\n",
       "      <td>0.352559</td>\n",
       "      <td>1.897890</td>\n",
       "      <td>0.553286</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.560610</td>\n",
       "      <td>0.296453</td>\n",
       "      <td>1.868220</td>\n",
       "      <td>0.593915</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.968544</td>\n",
       "      <td>0.310738</td>\n",
       "      <td>1.895444</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.742651</td>\n",
       "      <td>0.345909</td>\n",
       "      <td>1.854938</td>\n",
       "      <td>0.599012</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.227543</td>\n",
       "      <td>0.220987</td>\n",
       "      <td>1.926716</td>\n",
       "      <td>0.566149</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.923318</td>\n",
       "      <td>0.378178</td>\n",
       "      <td>1.827998</td>\n",
       "      <td>0.576364</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.905942</td>\n",
       "      <td>0.473801</td>\n",
       "      <td>1.915302</td>\n",
       "      <td>0.538385</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.070499</td>\n",
       "      <td>0.404839</td>\n",
       "      <td>1.825623</td>\n",
       "      <td>0.553018</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.736835</td>\n",
       "      <td>0.396463</td>\n",
       "      <td>1.915083</td>\n",
       "      <td>0.575692</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25.002895</td>\n",
       "      <td>0.395762</td>\n",
       "      <td>1.865071</td>\n",
       "      <td>0.541753</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28.042374</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>1.908705</td>\n",
       "      <td>0.565252</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.121708</td>\n",
       "      <td>0.233485</td>\n",
       "      <td>1.861823</td>\n",
       "      <td>0.559234</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.689650</td>\n",
       "      <td>0.228134</td>\n",
       "      <td>1.895171</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26.976702</td>\n",
       "      <td>0.385007</td>\n",
       "      <td>1.868615</td>\n",
       "      <td>0.578409</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19.677824</td>\n",
       "      <td>0.207133</td>\n",
       "      <td>1.879252</td>\n",
       "      <td>0.567598</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.401981</td>\n",
       "      <td>0.246733</td>\n",
       "      <td>1.896066</td>\n",
       "      <td>0.568369</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>28.756887</td>\n",
       "      <td>0.383912</td>\n",
       "      <td>1.882647</td>\n",
       "      <td>0.561303</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.513611</td>\n",
       "      <td>0.193946</td>\n",
       "      <td>1.884598</td>\n",
       "      <td>0.581632</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.464756</td>\n",
       "      <td>0.208370</td>\n",
       "      <td>1.886633</td>\n",
       "      <td>0.576397</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>25.322348</td>\n",
       "      <td>0.395691</td>\n",
       "      <td>1.895451</td>\n",
       "      <td>0.570817</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>25.555664</td>\n",
       "      <td>0.250428</td>\n",
       "      <td>1.868032</td>\n",
       "      <td>0.583440</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.227926</td>\n",
       "      <td>0.303303</td>\n",
       "      <td>1.909548</td>\n",
       "      <td>0.573055</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21.351328</td>\n",
       "      <td>0.214012</td>\n",
       "      <td>1.858944</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25.433947</td>\n",
       "      <td>0.358363</td>\n",
       "      <td>1.921882</td>\n",
       "      <td>0.561726</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30.077509</td>\n",
       "      <td>0.409270</td>\n",
       "      <td>1.867849</td>\n",
       "      <td>0.558826</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.014738</td>\n",
       "      <td>0.225444</td>\n",
       "      <td>1.928108</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean of means  std of means  mean of variances  std of variances  \\\n",
       "0       18.842220      0.317450           1.825873          0.560079   \n",
       "1        9.471349      0.444034           1.937971          0.517347   \n",
       "2        7.740537      0.434117           1.832003          0.554985   \n",
       "3       26.365894      0.417483           1.919929          0.565277   \n",
       "4       21.101593      0.256598           1.855694          0.552404   \n",
       "5       12.562413      0.405179           1.886901          0.550488   \n",
       "6       23.152119      0.125123           1.877433          0.553636   \n",
       "7       11.497302      0.409499           1.895516          0.569522   \n",
       "8       19.189522      0.241537           1.883236          0.579042   \n",
       "9       27.618305      0.425895           1.871343          0.562083   \n",
       "10      23.730772      0.272178           1.887647          0.573568   \n",
       "11      27.394293      0.428923           1.872826          0.562564   \n",
       "12      14.080747      0.303000           1.882299          0.551384   \n",
       "13      24.227160      0.265097           1.891142          0.587897   \n",
       "14      14.313344      0.352559           1.897890          0.553286   \n",
       "15      14.560610      0.296453           1.868220          0.593915   \n",
       "16      15.968544      0.310738           1.895444          0.532400   \n",
       "17      13.742651      0.345909           1.854938          0.599012   \n",
       "18      20.227543      0.220987           1.926716          0.566149   \n",
       "19      12.923318      0.378178           1.827998          0.576364   \n",
       "20      13.905942      0.473801           1.915302          0.538385   \n",
       "21      27.070499      0.404839           1.825623          0.553018   \n",
       "22      23.736835      0.396463           1.915083          0.575692   \n",
       "23      25.002895      0.395762           1.865071          0.541753   \n",
       "24      28.042374      0.397133           1.908705          0.565252   \n",
       "25      24.121708      0.233485           1.861823          0.559234   \n",
       "26      17.689650      0.228134           1.895171          0.568014   \n",
       "27      26.976702      0.385007           1.868615          0.578409   \n",
       "28      19.677824      0.207133           1.879252          0.567598   \n",
       "29      19.401981      0.246733           1.896066          0.568369   \n",
       "30      28.756887      0.383912           1.882647          0.561303   \n",
       "31      21.513611      0.193946           1.884598          0.581632   \n",
       "32      20.464756      0.208370           1.886633          0.576397   \n",
       "33      25.322348      0.395691           1.895451          0.570817   \n",
       "34      25.555664      0.250428           1.868032          0.583440   \n",
       "35      16.227926      0.303303           1.909548          0.573055   \n",
       "36      21.351328      0.214012           1.858944          0.571624   \n",
       "37      25.433947      0.358363           1.921882          0.561726   \n",
       "38      30.077509      0.409270           1.867849          0.558826   \n",
       "39      19.014738      0.225444           1.928108          0.567839   \n",
       "\n",
       "    true value  \n",
       "0         15.0  \n",
       "1         10.0  \n",
       "2          9.0  \n",
       "3         25.0  \n",
       "4         19.0  \n",
       "5         14.0  \n",
       "6         14.0  \n",
       "7         13.0  \n",
       "8         18.0  \n",
       "9         35.0  \n",
       "10        25.0  \n",
       "11        19.0  \n",
       "12        13.0  \n",
       "13        28.0  \n",
       "14        13.0  \n",
       "15        14.0  \n",
       "16        15.0  \n",
       "17        13.0  \n",
       "18        18.0  \n",
       "19        12.0  \n",
       "20        16.0  \n",
       "21        24.0  \n",
       "22        19.0  \n",
       "23        24.0  \n",
       "24        31.0  \n",
       "25        26.0  \n",
       "26        16.0  \n",
       "27        24.0  \n",
       "28        18.0  \n",
       "29        20.0  \n",
       "30        29.0  \n",
       "31        18.0  \n",
       "32        19.0  \n",
       "33        22.0  \n",
       "34        26.0  \n",
       "35        17.5  \n",
       "36        22.5  \n",
       "37        29.0  \n",
       "38        29.0  \n",
       "39        20.0  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data=np.column_stack((np.mean(means,axis=1),(np.sqrt(np.var(means,axis=1))),(np.mean(np.sqrt(epis),axis=1)),np.sqrt(np.var(np.sqrt(epis),axis=1)),test_labels[:tn])),\n",
    "                  columns=['mean of means','std of means','mean of variances','std of variances','true value'])\n",
    "df2 #The covariates of the first point have been deliberately messed up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing could be done by using MCdropout to capture the epistemic uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_batch.loc[9]=[1,1,1,1,1,1,0.8,-0.46,-0.46] #This allows me to deliberately mess up some data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
